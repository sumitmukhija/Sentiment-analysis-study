{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_lex import EmoLex\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.tokenize.casual import TweetTokenizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from twitter_preprocessor import TwitterPreprocessor\n",
    "import os\n",
    "import glob\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon = EmoLex('./NRC-Emotion-Lexicon-Wordlevel-v0.92-headless.csv')\n",
    "lexicon.dump('./lexicon.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anger',\n",
       " 'anticipation',\n",
       " 'disgust',\n",
       " 'fear',\n",
       " 'joy',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'sadness',\n",
       " 'surprise',\n",
       " 'trust'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon = EmoLex()\n",
    "lexicon.load('./lexicon.pickle')\n",
    "\n",
    "lexicon.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where stores the total data\n",
    "soldierEmoDict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file list\n",
    "soldierCSVs = []\n",
    "files = os.listdir(os.getcwd() + \"/data/civilians\")\n",
    "for file in files:\n",
    "     if not os.path.isdir(file) and file.endswith(\".csv\"):\n",
    "            soldierCSVs.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useless columns for analyzing\n",
    "uselessColumns = [\n",
    "    \"id\",\n",
    "    \"conversation_id\",\n",
    "    \"place\",\n",
    "    \"photos\",\n",
    "    \"video\",\n",
    "    \"near\",\n",
    "    \"geo\",\n",
    "    \"source\",\n",
    "    \"user_rt_id\",\n",
    "    \"user_rt\",\n",
    "    \"retweet_id\",\n",
    "    \"reply_to\",\n",
    "    \"retweet_date\",\n",
    "    \"translate\",\n",
    "    \"trans_src\",\n",
    "    \"trans_dest\",\n",
    "    \"link\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calEmoForTweet(tweet):\n",
    "    tempTweet = tweet\n",
    "    tempTweetCleaned = TwitterPreprocessor(tempTweet).remove_urls().remove_mentions().remove_hashtags().remove_twitter_reserved_words().remove_single_letter_words().remove_numbers(preserve_years=True).remove_blank_spaces().text    \n",
    "    \n",
    "#     tempTokens = TweetTokenizer.tokenize(tempTweetCleaned)\n",
    "    tempTokens = nltk.word_tokenize(tempTweetCleaned)\n",
    "#     tempTokens = [tempToken.lower() for tempToken in tempTokens if len(tempToken)>2]\n",
    "#     tempTokens = [tempToken.lower() for tempToken in tempTokens if tempToken.lower() not in stopset and len(tempToken)>2]\n",
    "    \n",
    "    summary = lexicon.summarize_doc(tempTokens)\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating... myrna99.csv\n",
      "0\n",
      "{'anger': 0.01646068814869006, 'joy': 0.03927323016393168, 'disgust': 0.006995547300570491, 'sadness': 0.019048676753082732, 'surprise': 0.01266838473928715, 'anticipation': 0.0343847914196657, 'positive': 0.06855451957336453, 'fear': 0.012767515878170162, 'trust': 0.037501369938581434, 'negative': 0.0271446098488055, 'valid_tweet_count': 940.0}\n",
      ".csvulating... KBDeSalvo\n",
      "0\n",
      "1000\n",
      "{'anger': 0.006907286285178602, 'negative': 0.015300027100348102, 'fear': 0.0117797721269257, 'sadness': 0.006868818318461085, 'positive': 0.10163740665929741, 'joy': 0.04013400062437664, 'disgust': 0.004092648624292317, 'surprise': 0.017768262981770123, 'anticipation': 0.04873649440148813, 'trust': 0.051740775652941794, 'valid_tweet_count': 1659.0}\n",
      "Calculating... HTracyDavido.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "{'anger': 0.012905500054731185, 'joy': 0.05117900329952601, 'disgust': 0.01110506307221153, 'sadness': 0.017859655700781216, 'surprise': 0.025266401350997333, 'anticipation': 0.03718188656535835, 'fear': 0.022819706418970586, 'trust': 0.04461273675080742, 'negative': 0.0346743726601014, 'positive': 0.09258312388536846, 'valid_tweet_count': 2588.0}\n",
      "Calculating... CenterdinOaklnd.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "{'disgust': 0.0012388692170336602, 'sadness': 0.0034190547815815685, 'joy': 0.05861337081606048, 'surprise': 0.03897867501154731, 'anticipation': 0.0443565624477003, 'positive': 0.0866081133803281, 'trust': 0.05157800644322759, 'anger': 0.003442994593060079, 'fear': 0.00330802200696818, 'negative': 0.009227193301161875, 'valid_tweet_count': 5200.0}\n",
      "Calculating... satyanadella.csv\n",
      "0\n",
      "{'anger': 0.00669920217778521, 'joy': 0.03213462538446519, 'disgust': 0.003079993013026125, 'sadness': 0.004041993251177029, 'surprise': 0.013125616598839722, 'anticipation': 0.03467330707788042, 'fear': 0.009186074166332495, 'negative': 0.00999547354875037, 'trust': 0.03853250814904119, 'positive': 0.08608716811585453, 'valid_tweet_count': 692.0}\n",
      "Calculating... jeffrreyford.csv\n",
      "0\n",
      "{'anger': 0.030634060277602477, 'disgust': 0.009903381642512078, 'sadness': 0.025087915601023015, 'surprise': 0.04051316738816738, 'anticipation': 0.07334780486634707, 'fear': 0.027080669224211422, 'trust': 0.056207376560637436, 'negative': 0.04313406027760248, 'positive': 0.08805261465587554, 'joy': 0.04853162839575882, 'valid_tweet_count': 20.0}\n",
      "Calculating... CarolynRife.csv\n",
      "0\n",
      "{'anger': 0.0071187881077413315, 'joy': 0.03382770032654706, 'disgust': 0.0027512567898762092, 'sadness': 0.004942983286349331, 'surprise': 0.00820873518992373, 'anticipation': 0.02059322622107713, 'positive': 0.040584200850504334, 'fear': 0.007809883535669733, 'negative': 0.01353237354450694, 'trust': 0.015079459105449687, 'valid_tweet_count': 737.0}\n",
      "Calculating... bexsmith2303.csv\n",
      "0\n",
      "{'anger': 0.012419471488193511, 'joy': 0.023662479268035733, 'disgust': 0.008982076375289066, 'sadness': 0.02236504199195543, 'surprise': 0.009809063867560057, 'anticipation': 0.03604341977279303, 'positive': 0.049108340210142425, 'fear': 0.01534565199821149, 'trust': 0.03187854606811607, 'negative': 0.03071003035206049, 'valid_tweet_count': 176.0}\n",
      ".csvulating... VivianaLongo\n",
      "0\n",
      "{'anger': 0.004714111922141119, 'joy': 0.01551094890510949, 'disgust': 0.005079075425790754, 'sadness': 0.004592457420924574, 'surprise': 0.004562043795620438, 'anticipation': 0.01551094890510949, 'positive': 0.02162505310315529, 'fear': 0.004714111922141119, 'trust': 0.01676225234619395, 'negative': 0.0049574209245742094, 'valid_tweet_count': 274.0}\n",
      "Calculating... HanninenRaija.csv\n",
      "0\n",
      "{'anger': 0.0016722408026755855, 'joy': 0.0410097149227584, 'disgust': 0.0016722408026755855, 'sadness': 0.0016722408026755855, 'surprise': 0.0018115942028985505, 'anticipation': 0.01927058448797579, 'positive': 0.04616579073100812, 'fear': 0.003344481605351171, 'trust': 0.012267322049930746, 'negative': 0.005156075808249721, 'valid_tweet_count': 92.0}\n",
      "Calculating... JoshPickett22_.csv\n",
      "0\n",
      "{'anger': 0.017948363127074828, 'disgust': 0.021109878228888438, 'sadness': 0.021658605643287494, 'surprise': 0.01963195659189375, 'fear': 0.021585482249268578, 'negative': 0.040426582080156315, 'anticipation': 0.05224830921021023, 'positive': 0.0674957090118127, 'trust': 0.06028846557126211, 'joy': 0.043711054001706, 'valid_tweet_count': 67.0}\n",
      "Calculating... sabema11_.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "{'anger': 0.027698236208446362, 'disgust': 0.02685578961620904, 'sadness': 0.02491888210665367, 'surprise': 0.026227546583434125, 'anticipation': 0.03666129849481046, 'fear': 0.02619664701643918, 'negative': 0.05659109021098937, 'positive': 0.0681608979861284, 'joy': 0.03615727192510149, 'trust': 0.04859698276350654, 'valid_tweet_count': 6403.0}\n",
      "Calculating... msteGeorge_.csv\n",
      "0\n",
      "{'anger': 0.00577904115212475, 'joy': 0.030341809870595333, 'disgust': 0.0043825868837887435, 'sadness': 0.007910013113776536, 'surprise': 0.013884886432083786, 'anticipation': 0.03816460432480714, 'positive': 0.07266897429580114, 'fear': 0.007694105837116592, 'trust': 0.037447427591907494, 'negative': 0.013264017102637514, 'valid_tweet_count': 573.0}\n",
      "Calculating... amandasilveir.csv\n",
      "0\n",
      "{'anger': 0.011632386805868181, 'joy': 0.060124059499359686, 'disgust': 0.010658330743636866, 'sadness': 0.008321757687883447, 'surprise': 0.03133775924056959, 'anticipation': 0.05284101039095293, 'positive': 0.09492915819264293, 'fear': 0.011466416710224766, 'trust': 0.08102229212876959, 'negative': 0.04173866600153695, 'valid_tweet_count': 232.0}\n",
      "Calculating... courageousgirl2_.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "{'anger': 0.03956331169052479, 'joy': 0.023208457815125736, 'disgust': 0.029740142804979715, 'sadness': 0.022919756354114165, 'surprise': 0.02569016178688584, 'positive': 0.05234379894339272, 'fear': 0.061445517550522306, 'negative': 0.08498882639939201, 'anticipation': 0.023278693298759288, 'trust': 0.04614326628539495, 'valid_tweet_count': 6220.0}\n",
      "Calculating... ysik696_yesica.csv\n",
      "0\n",
      "{'anger': 0.02443722587074046, 'joy': 0.060172160870381255, 'disgust': 0.0007002801120448179, 'sadness': 0.0018207282913165266, 'surprise': 0.024997449960376315, 'anticipation': 0.041558013579763436, 'positive': 0.08213761371818704, 'fear': 0.010317460317460319, 'trust': 0.0744228611504933, 'negative': 0.0037687802393684745, 'valid_tweet_count': 119.0}\n",
      "Calculating... TheBagLadyBaySt.csv\n",
      "0\n",
      "{'anger': 0.012026491512244282, 'joy': 0.06805399887904832, 'disgust': 0.007115504673876586, 'sadness': 0.015387845002755947, 'surprise': 0.021676423321154718, 'anticipation': 0.05336096406745032, 'positive': 0.09774122338899474, 'fear': 0.013878216783326238, 'trust': 0.0638919311757316, 'negative': 0.030523414672250074, 'valid_tweet_count': 920.0}\n",
      "Calculating... bootleg55_.csv\n",
      "0\n",
      "{'anger': 0.018658424908424908, 'joy': 0.02798115862631992, 'disgust': 0.008923648036551261, 'sadness': 0.014216100113808096, 'surprise': 0.021903924928118476, 'fear': 0.024750682019357744, 'trust': 0.03424314967714798, 'anticipation': 0.02622715546102643, 'negative': 0.038779939406000524, 'positive': 0.04651379086862957, 'valid_tweet_count': 124.0}\n",
      ".csvulating... sventennis\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "{'anger': 0.008477403761449512, 'joy': 0.03102152964989588, 'disgust': 0.0045673699916403045, 'sadness': 0.007830639412072564, 'surprise': 0.013501984397414095, 'anticipation': 0.03469776821881536, 'fear': 0.009566365419576828, 'trust': 0.0421237551681944, 'negative': 0.019534070593345283, 'positive': 0.06704520126135524, 'valid_tweet_count': 8407.0}\n",
      "Calculating... only1lovelylady_.csv\n",
      "0\n",
      "{'anger': 0.01246026700572155, 'joy': 0.058848287401697036, 'disgust': 0.010599704590597418, 'sadness': 0.01623622389768009, 'surprise': 0.015655720791413277, 'anticipation': 0.03694069732006774, 'positive': 0.08042145652288922, 'fear': 0.026356270184887395, 'trust': 0.06863471573860705, 'negative': 0.023904405527433663, 'valid_tweet_count': 143.0}\n",
      "Calculating... Fold_Alot.csv\n",
      "0\n",
      "{'anger': 0.014403808196911646, 'joy': 0.017350848385331144, 'disgust': 0.013926622547312202, 'surprise': 0.005427841634738187, 'anticipation': 0.04055186512083064, 'fear': 0.01585220016254499, 'trust': 0.029637763258452913, 'negative': 0.05160351781041435, 'positive': 0.052935474487198625, 'sadness': 0.02486901348970315, 'valid_tweet_count': 87.0}\n",
      "Calculating... srininad.csv\n",
      "0\n",
      "{'anger': 0.015086466165413532, 'joy': 0.06693416258663938, 'disgust': 0.0031111111111111114, 'sadness': 0.016542492595124175, 'surprise': 0.026733058135534914, 'anticipation': 0.06021976793416424, 'positive': 0.09393473511352772, 'fear': 0.012930659983291562, 'trust': 0.0697097554148638, 'negative': 0.027730766309713675, 'valid_tweet_count': 50.0}\n",
      "Calculating... dootsonlady.csv\n",
      "0\n",
      "{'anger': 0.0045881805739206374, 'joy': 0.014046044462240516, 'disgust': 0.0018004458194381967, 'sadness': 0.0029966714258306006, 'surprise': 0.00679824811108134, 'anticipation': 0.019189797290324443, 'positive': 0.03300781714769899, 'fear': 0.008514798906460272, 'trust': 0.02960049258464655, 'negative': 0.00915209572061991, 'valid_tweet_count': 906.0}\n",
      "Calculating... winecc.csv\n",
      "0\n",
      "{'anger': 0.0043690608908000216, 'joy': 0.023300309097742188, 'disgust': 0.002258060610463356, 'sadness': 0.0065031237514075035, 'surprise': 0.008512595125867438, 'anticipation': 0.03561849308416815, 'positive': 0.04203290118497562, 'fear': 0.007604050538833148, 'trust': 0.025288161486052247, 'negative': 0.014712145003907018, 'valid_tweet_count': 69.0}\n",
      "Calculating... smodisette.csv\n",
      "0\n",
      "{'anger': 0.014423076923076922, 'joy': 0.008639182168593934, 'disgust': 0.0125, 'sadness': 0.0019230769230769232, 'surprise': 0.0076210826210826215, 'fear': 0.018425738491527965, 'trust': 0.011773299295985322, 'negative': 0.05507478632478633, 'positive': 0.03296897031417155, 'anticipation': 0.025622612967814207, 'valid_tweet_count': 20.0}\n",
      "Calculating... poopthought.csv\n",
      "0\n",
      "{'disgust': 0.009951203228613436, 'surprise': 0.018910637099996366, 'fear': 0.02440532692881742, 'sadness': 0.0156162063840258, 'anticipation': 0.038958165170577444, 'positive': 0.06151240247045755, 'trust': 0.03994772818755068, 'joy': 0.028839124131727446, 'anger': 0.016545965000318387, 'negative': 0.032697778163001116, 'valid_tweet_count': 69.0}\n",
      "Calculating... amityron112.csv\n",
      "0\n",
      "{'anger': 0.015508229969014284, 'joy': 0.0342171980594016, 'disgust': 0.009334389889945446, 'sadness': 0.018582079296365014, 'surprise': 0.018560432029152855, 'anticipation': 0.033009165852303096, 'positive': 0.06562681793774226, 'fear': 0.025388544436163483, 'trust': 0.04888579665657163, 'negative': 0.036384419519340155, 'valid_tweet_count': 189.0}\n",
      "Calculating... ShowalterMG.csv\n",
      "0\n",
      "{'anger': 0.008801588417967729, 'joy': 0.04078353725005818, 'disgust': 0.014724671292368825, 'surprise': 0.022828859867134614, 'anticipation': 0.030660631409067517, 'positive': 0.06752894316817291, 'fear': 0.008636035999398965, 'trust': 0.04272395293529714, 'negative': 0.025477988902826407, 'sadness': 0.01632664890691261, 'valid_tweet_count': 100.0}\n",
      ".csvulating... RobinRoberts\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "{'disgust': 0.005167046634539201, 'anger': 0.009863154154986694, 'negative': 0.01907050465384076, 'joy': 0.06130788166574501, 'surprise': 0.025410912660964912, 'anticipation': 0.061193178762276514, 'positive': 0.09020797353294167, 'trust': 0.052836232975795025, 'sadness': 0.010152259702151254, 'fear': 0.01222416945803406, 'valid_tweet_count': 31687.0}\n",
      "Calculating... eliza_laskowski.csv\n",
      "0\n",
      "{'anger': 0.013302564207393636, 'disgust': 0.01392493789363369, 'sadness': 0.022600628073220042, 'surprise': 0.00967078690228861, 'anticipation': 0.02487896116009029, 'fear': 0.01995865861963472, 'trust': 0.03421744587285419, 'negative': 0.033329429663092554, 'positive': 0.05764431871171015, 'joy': 0.030318199435391383, 'valid_tweet_count': 329.0}\n",
      "Calculating... fly5962_.csv\n",
      "0\n",
      "{'anger': 0.009645387850516055, 'joy': 0.040674862937962145, 'disgust': 0.003513770180436847, 'sadness': 0.007749665483779197, 'surprise': 0.017677880049674924, 'anticipation': 0.03273613737103146, 'positive': 0.05542203945771392, 'fear': 0.011411273911273908, 'trust': 0.043980618250406424, 'negative': 0.018276365754069206, 'valid_tweet_count': 117.0}\n",
      "Calculating... pwslive.csv\n",
      "0\n",
      "{'disgust': 0.006732812036680694, 'anger': 0.012729680167462096, 'fear': 0.01482203164485019, 'sadness': 0.007782577196055503, 'negative': 0.030389805441325964, 'joy': 0.026324316565159142, 'surprise': 0.011327302469889214, 'anticipation': 0.034921407662120145, 'positive': 0.07165290235934194, 'trust': 0.03522737004763471, 'valid_tweet_count': 216.0}\n",
      "Calculating... AroundChiTown.csv\n",
      "0\n",
      "{'valid_tweet_count': 1.0, 'anger': 0.0, 'joy': 0.0, 'disgust': 0.0, 'sadness': 0.0, 'surprise': 0.0, 'anticipation': 0.0, 'positive': 0.0, 'fear': 0.0, 'trust': 0.0, 'negative': 0.0}\n",
      "Calculating... CoachMattBLiTZ.csv\n",
      "0\n",
      "{'anger': 0.00977566772169471, 'joy': 0.04171804483761006, 'disgust': 0.0038980509745127436, 'sadness': 0.01117774446110278, 'surprise': 0.013366995073891625, 'anticipation': 0.018757799671592773, 'positive': 0.09478516933706985, 'fear': 0.029175828752290522, 'negative': 0.02947340813720124, 'trust': 0.03276122477976698, 'valid_tweet_count': 20.0}\n",
      "Calculating... MKBHD.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cary/.local/share/virtualenvs/TextAnalytics-9hFs7Vd6/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (9,21) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "{'anger': 0.011949948497792639, 'joy': 0.025804884081171663, 'disgust': 0.007331906607959193, 'sadness': 0.011426711671736277, 'surprise': 0.013123044607621244, 'anticipation': 0.031001723909784413, 'positive': 0.051892552262271366, 'fear': 0.011884646705962468, 'trust': 0.03381997560348255, 'negative': 0.02306762591297607, 'valid_tweet_count': 44534.0}\n",
      "Calculating... lindseywasson.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "{'anger': 0.012805613542686162, 'joy': 0.02450680439986762, 'disgust': 0.009996540111336162, 'sadness': 0.011853656029819427, 'surprise': 0.014358160589503021, 'anticipation': 0.028129747443135893, 'fear': 0.014624147879575989, 'trust': 0.03229778728808181, 'negative': 0.027801767713843524, 'positive': 0.05225905804790448, 'valid_tweet_count': 13060.0}\n",
      "Calculating... mattdoty.csv\n",
      "0\n",
      "{'anger': 0.016568139564655245, 'joy': 0.017609800756962064, 'disgust': 0.01429805192871395, 'sadness': 0.01633136056173564, 'surprise': 0.011962989186805542, 'anticipation': 0.023178869023304356, 'positive': 0.044790078746832176, 'fear': 0.02768518289116772, 'trust': 0.02588777423528397, 'negative': 0.033295087891316626, 'valid_tweet_count': 41.0}\n",
      "Calculating... blessings4life.csv\n",
      "0\n",
      "{'anger': 0.015089664922768163, 'joy': 0.026913941474800803, 'disgust': 0.010247744493257667, 'sadness': 0.02093092540203983, 'surprise': 0.011205321896406864, 'anticipation': 0.04188986891528248, 'fear': 0.028853236515246794, 'trust': 0.04405227056973505, 'negative': 0.037471392289190865, 'positive': 0.06742739804529149, 'valid_tweet_count': 121.0}\n",
      "Calculating... thedrillsgt_.csv\n",
      "0\n",
      "{'anger': 0.014404176848352074, 'joy': 0.046861072190312464, 'disgust': 0.007962046249014735, 'sadness': 0.010062666045962237, 'surprise': 0.017798470599505574, 'fear': 0.022071025038454966, 'trust': 0.05229868817262813, 'negative': 0.030583881004317897, 'anticipation': 0.041140798495683986, 'positive': 0.0880193811417968, 'valid_tweet_count': 405.0}\n",
      "Calculating... mamalium.csv\n",
      "0\n",
      "{'anger': 0.016024731972524478, 'joy': 0.05335320742453675, 'disgust': 0.008082803640602706, 'sadness': 0.014202192215664933, 'surprise': 0.01808291873864707, 'fear': 0.018037599118931654, 'negative': 0.03129683371442359, 'anticipation': 0.04898148452320706, 'positive': 0.08042865055920181, 'trust': 0.049488251328784275, 'valid_tweet_count': 754.0}\n",
      "Calculating... whatlisacooks.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "{'anger': 0.0040940396504350746, 'joy': 0.02039094143155489, 'disgust': 0.004399875988368705, 'sadness': 0.0035677605119969814, 'surprise': 0.007038185204660533, 'positive': 0.046963959206046055, 'fear': 0.006186541690526481, 'trust': 0.036603323641538475, 'negative': 0.011008337767994893, 'anticipation': 0.020669067110976862, 'valid_tweet_count': 2638.0}\n",
      "Calculating... marissssa_mcbri.csv\n",
      "0\n",
      "{'anger': 0.012410507897903338, 'joy': 0.029499222517610092, 'disgust': 0.010650360527929205, 'sadness': 0.015339762841990678, 'surprise': 0.013070544745911253, 'anticipation': 0.028733812980124656, 'positive': 0.05488613759145746, 'fear': 0.017960041589267367, 'trust': 0.0364085523518329, 'negative': 0.03284026618426651, 'valid_tweet_count': 863.0}\n",
      "Calculating... Forest_Theater_.csv\n",
      "0\n",
      "{'anger': 0.011015800916372642, 'joy': 0.038568636965937785, 'disgust': 0.004381992969847697, 'sadness': 0.008926433313726926, 'surprise': 0.019415492863259713, 'anticipation': 0.038388878292722424, 'positive': 0.06619109413891451, 'fear': 0.008403113504961842, 'trust': 0.04079720152884714, 'negative': 0.01102316608809517, 'valid_tweet_count': 522.0}\n",
      "Calculating... Car_o_lina.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "{'anger': 0.015193880654240944, 'joy': 0.027735981316117937, 'disgust': 0.011721375403110093, 'sadness': 0.014952547403086578, 'surprise': 0.011581484153660941, 'anticipation': 0.026100487674612562, 'positive': 0.04571304646921208, 'fear': 0.015758553255080444, 'trust': 0.029699640826027367, 'negative': 0.03135779230044678, 'valid_tweet_count': 2570.0}\n",
      "Calculating... Blargers.csv\n",
      "0\n",
      "1000\n",
      "{'anger': 0.016907858451383182, 'joy': 0.032412585146772845, 'disgust': 0.014328799455635706, 'sadness': 0.015806135807238803, 'surprise': 0.018094742858118965, 'anticipation': 0.03479961963079418, 'fear': 0.019191606526698973, 'trust': 0.03358424368099297, 'negative': 0.03491381733801039, 'positive': 0.05555689771602839, 'valid_tweet_count': 1336.0}\n",
      "Calculating... ChrisVossPodcas.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "{'anger': 0.012405725436932021, 'joy': 0.031562252022178355, 'disgust': 0.007956711838229186, 'sadness': 0.01359123356908793, 'surprise': 0.01280040417828959, 'anticipation': 0.037276967041410376, 'positive': 0.07211431076070267, 'fear': 0.016642271038701088, 'negative': 0.028762935196764122, 'trust': 0.046169353654387915, 'valid_tweet_count': 13580.0}\n",
      "Calculating... thejoecardamone_.csv\n",
      "0\n",
      "1000\n",
      "{'anger': 0.012693183431314542, 'disgust': 0.011354690789887982, 'sadness': 0.008703347627181316, 'surprise': 0.011918620238215695, 'anticipation': 0.02749407285241533, 'fear': 0.010103027263204013, 'negative': 0.022975911315444273, 'joy': 0.03171292527909415, 'positive': 0.06715805730278114, 'trust': 0.04007436945443575, 'valid_tweet_count': 1140.0}\n",
      "Calculating... AlkieshaK.csv\n",
      "0\n",
      "{'anger': 0.028330265948886154, 'joy': 0.029317987512665473, 'disgust': 0.029786264150303065, 'sadness': 0.0320181429558856, 'surprise': 0.012776544302043238, 'anticipation': 0.02442613623165919, 'positive': 0.04623797645284522, 'fear': 0.02851458098805845, 'trust': 0.02609134990126471, 'negative': 0.06279739018100514, 'valid_tweet_count': 921.0}\n",
      ".csvulating... jsoltero\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "{'disgust': 0.008246383120993092, 'anger': 0.010150948757269303, 'fear': 0.011750114018440404, 'negative': 0.02401648666260383, 'sadness': 0.011004299643135733, 'joy': 0.025873028371237495, 'surprise': 0.013666834440747445, 'anticipation': 0.03395733576834329, 'positive': 0.0580566937876532, 'trust': 0.035714590921440165, 'valid_tweet_count': 4892.0}\n",
      "Calculating... Tarraccas.csv\n",
      "0\n",
      "{'anger': 0.019627413170491027, 'joy': 0.03710800575744428, 'disgust': 0.016145845428526512, 'sadness': 0.022137063480125584, 'surprise': 0.02560886866255453, 'trust': 0.04421478662151065, 'anticipation': 0.040466951000158714, 'positive': 0.06983712279749586, 'fear': 0.02570938312575248, 'negative': 0.04353228387067994, 'valid_tweet_count': 874.0}\n",
      "Calculating... LUVVAJ.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "{'anger': 0.013866434186808661, 'joy': 0.0281721917268389, 'disgust': 0.008021721530356987, 'sadness': 0.013230443362682141, 'surprise': 0.011182910695825067, 'positive': 0.058788185939097126, 'fear': 0.016220529754035748, 'trust': 0.033572410009970174, 'negative': 0.026190055452429587, 'anticipation': 0.026737308878302952, 'valid_tweet_count': 6084.0}\n",
      "Calculating... GerrickB_.csv\n",
      "0\n",
      "{'anger': 0.02050321766663743, 'joy': 0.02630595041109381, 'disgust': 0.013205536062372993, 'surprise': 0.01737722503761351, 'anticipation': 0.042321897243247884, 'positive': 0.06194884180427403, 'trust': 0.053915195316373156, 'sadness': 0.02342429324713563, 'fear': 0.02288394850065679, 'negative': 0.047270830658694606, 'valid_tweet_count': 231.0}\n",
      "Calculating... OldTomYoung_.csv\n",
      "0\n",
      "{'anger': 0.010724385978480916, 'joy': 0.014341848639266817, 'disgust': 0.010245797328340269, 'sadness': 0.011029974551298867, 'surprise': 0.008686362852386352, 'anticipation': 0.01858171184867057, 'positive': 0.05653464082446284, 'fear': 0.021512176553864653, 'trust': 0.041121131474120186, 'negative': 0.028627211357482852, 'valid_tweet_count': 885.0}\n",
      "Calculating... nabe1.csv\n",
      "0\n",
      "{'anger': 0.001949317738791423, 'joy': 0.025945007593207035, 'disgust': 0.003898635477582846, 'sadness': 0.005378944437116182, 'surprise': 0.00765183313659768, 'anticipation': 0.018808196266645018, 'positive': 0.043993601299695484, 'fear': 0.00872063198933005, 'trust': 0.02619728301861266, 'negative': 0.01727737738818071, 'valid_tweet_count': 57.0}\n",
      ".csvulating... HussnainMahroof\n",
      "0\n",
      "{'trust': 0.008771929824561403, 'negative': 0.008771929824561403, 'valid_tweet_count': 12.0, 'anger': 0.0, 'joy': 0.0, 'disgust': 0.0, 'sadness': 0.0, 'surprise': 0.0, 'anticipation': 0.0, 'positive': 0.0, 'fear': 0.0}\n",
      "Calculating... justinbernier_.csv\n",
      "0\n",
      "{'anger': 0.01719298245614035, 'joy': 0.013333333333333332, 'surprise': 0.01719298245614035, 'anticipation': 0.01719298245614035, 'positive': 0.08771929824561404, 'trust': 0.04105263157894737, 'negative': 0.006666666666666666, 'valid_tweet_count': 5.0, 'disgust': 0.0, 'sadness': 0.0, 'fear': 0.0}\n",
      "Calculating... tomglanz.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "{'anger': 0.016673248111097216, 'negative': 0.032113141113881714, 'fear': 0.017287776991368024, 'sadness': 0.014876249102481044, 'joy': 0.032761804856188424, 'disgust': 0.011053201863412467, 'surprise': 0.01574304677625756, 'anticipation': 0.03547718596311523, 'positive': 0.06254326360747857, 'trust': 0.03506124290664489, 'valid_tweet_count': 4060.0}\n",
      "Calculating... Cliu00.csv\n",
      "0\n",
      "{'anger': 0.013806706114398421, 'joy': 0.03876725126725127, 'sadness': 0.004451566951566952, 'surprise': 0.004558404558404558, 'anticipation': 0.03400331861870323, 'positive': 0.05142496392496392, 'fear': 0.005437760245452553, 'trust': 0.05896927146927147, 'negative': 0.02352384083153314, 'valid_tweet_count': 39.0, 'disgust': 0.0}\n",
      "Calculating... katiecoats.csv\n",
      "0\n",
      "{'anger': 0.012036376401953859, 'joy': 0.03553181501671653, 'disgust': 0.008167773787936324, 'sadness': 0.012609404192011196, 'surprise': 0.019420510178379126, 'positive': 0.06394208137511435, 'fear': 0.018353876056586702, 'negative': 0.028862303525013285, 'anticipation': 0.036829360083933955, 'trust': 0.03513681515828228, 'valid_tweet_count': 888.0}\n",
      "Calculating... writerchelseam.csv\n",
      "0\n",
      "1000\n",
      "{'anger': 0.01245079509722649, 'disgust': 0.009115207550066704, 'surprise': 0.018737118163349133, 'fear': 0.017477374183322188, 'negative': 0.027650934107286498, 'positive': 0.079625078200996, 'trust': 0.04432134355053843, 'joy': 0.043815110632036136, 'sadness': 0.016057917790141787, 'anticipation': 0.037933513682246865, 'valid_tweet_count': 1029.0}\n",
      "Calculating... Earth_Unity.csv\n",
      "0\n",
      "{'surprise': 0.026632044842561604, 'anticipation': 0.033106639406263925, 'negative': 0.03580480815734518, 'anger': 0.015463971780181884, 'joy': 0.030845532632931, 'disgust': 0.010556343430339888, 'sadness': 0.015327224848045523, 'positive': 0.06981286954486368, 'fear': 0.024291646933130902, 'trust': 0.04747522459395417, 'valid_tweet_count': 357.0}\n",
      "Calculating... JAJAjoe.csv\n",
      "0\n",
      "{'disgust': 0.0016129032258064516, 'surprise': 0.009082415420928403, 'sadness': 0.009082415420928403, 'joy': 0.004832415420928403, 'anger': 0.018460470161886372, 'fear': 0.015628054740957964, 'negative': 0.016847566936079916, 'anticipation': 0.0027346637102734664, 'positive': 0.021524686564419054, 'trust': 0.009525604476823988, 'valid_tweet_count': 20.0}\n",
      ".csvulating... junkballjul\n",
      "0\n",
      "{'anger': 0.008522289236079545, 'joy': 0.032197323222285336, 'disgust': 0.00394350428809006, 'sadness': 0.010804732063733334, 'surprise': 0.01725058868076272, 'anticipation': 0.04287836455807746, 'fear': 0.008667448920318583, 'trust': 0.029214620407132404, 'negative': 0.01966656761872886, 'positive': 0.058027153437319554, 'valid_tweet_count': 117.0}\n",
      "Calculating... dubliportal.csv\n",
      "0\n",
      "{'disgust': 0.0014152205818872485, 'anger': 0.00047225501770956313, 'surprise': 0.004377037928731333, 'negative': 0.028898703884192748, 'fear': 0.02504057548060981, 'sadness': 0.024738085338547478, 'anticipation': 0.005177912138696451, 'positive': 0.009819082801538943, 'trust': 0.006952844101966911, 'joy': 0.006104975271641938, 'valid_tweet_count': 495.0}\n",
      "Calculating... chadmue11er_.csv\n",
      "0\n",
      "{'anger': 0.011475409836065573, 'joy': 0.011175096130146368, 'disgust': 0.004098360655737705, 'sadness': 0.02083008066614624, 'surprise': 0.011130217687594738, 'anticipation': 0.02282426134885151, 'positive': 0.03563121141957179, 'fear': 0.012965722801788376, 'trust': 0.021571803248164958, 'negative': 0.03432569252241383, 'valid_tweet_count': 61.0}\n",
      "Calculating... TheOnlyNishant.csv\n",
      "0\n",
      "{'anger': 0.008384803853667815, 'joy': 0.02259206856236752, 'disgust': 0.006277561815464474, 'surprise': 0.006674982359538639, 'anticipation': 0.021733429814365584, 'positive': 0.04314893836965943, 'fear': 0.010630454505586787, 'trust': 0.0311588691876984, 'negative': 0.017190726783876266, 'sadness': 0.007987347316417044, 'valid_tweet_count': 478.0}\n",
      "Calculating... Kiweez1_.csv\n",
      "0\n",
      "1000\n",
      "{'anger': 0.01648218298935085, 'disgust': 0.01599588175762179, 'sadness': 0.017259206716949242, 'surprise': 0.013610202541369677, 'fear': 0.01709184297188657, 'negative': 0.04415939091069893, 'positive': 0.05010612508865226, 'anticipation': 0.022447599309005247, 'trust': 0.03657317994276574, 'joy': 0.021159894746269264, 'valid_tweet_count': 1720.0}\n",
      "Calculating... FordeINC.csv\n",
      "0\n",
      "{'anger': 0.004762426900584795, 'joy': 0.044016161727849036, 'disgust': 0.0020535714285714285, 'sadness': 0.0020535714285714285, 'surprise': 0.008544584500466851, 'anticipation': 0.032073179271708684, 'positive': 0.06057953707798909, 'fear': 0.0044846491228070174, 'trust': 0.0371282065457762, 'negative': 0.00609920020639835, 'valid_tweet_count': 100.0}\n",
      "Calculating... VCooper51_.csv\n",
      "0\n",
      "{'anger': 0.01639718363506433, 'joy': 0.03127213627450897, 'disgust': 0.011309407828736255, 'sadness': 0.016636471468848394, 'surprise': 0.02120030895031838, 'fear': 0.017057372601370576, 'trust': 0.043753725892427625, 'negative': 0.03233909197474166, 'positive': 0.07863083339461106, 'anticipation': 0.0331363798932664, 'valid_tweet_count': 956.0}\n",
      "Calculating... AragoneJC.csv\n",
      "0\n",
      "{'joy': 0.03831022063802062, 'disgust': 0.007934994026587996, 'sadness': 0.010636491758429276, 'surprise': 0.01581948061875823, 'anticipation': 0.038576870368944735, 'positive': 0.07008649971229715, 'fear': 0.011490265760620138, 'trust': 0.0444821276290896, 'anger': 0.013708361345785252, 'negative': 0.023966178182868992, 'valid_tweet_count': 255.0}\n",
      "Calculating... Tpalmo1230Pam.csv\n",
      "0\n",
      "{'anger': 0.013613949645352754, 'disgust': 0.01303766827519163, 'sadness': 0.014906859762506573, 'fear': 0.015116231339369655, 'negative': 0.0296545447521891, 'positive': 0.10160629755880783, 'joy': 0.0731067847188834, 'surprise': 0.031981050839197875, 'anticipation': 0.045078205429221, 'trust': 0.06195705866969571, 'valid_tweet_count': 284.0}\n",
      "Calculating... ChiTownMaggie_.csv\n",
      "0\n",
      "{'anger': 0.008856987704179815, 'joy': 0.04222130454464205, 'disgust': 0.007158956348095918, 'sadness': 0.00944490937633953, 'surprise': 0.0216464802342368, 'anticipation': 0.03482336048701781, 'positive': 0.08319799943077216, 'fear': 0.007617463863173588, 'trust': 0.053484883046468396, 'negative': 0.01778151656711424, 'valid_tweet_count': 618.0}\n",
      "Calculating... debl115.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "{'anger': 0.023775455311349603, 'joy': 0.019636777846532297, 'disgust': 0.023994664034759437, 'sadness': 0.016363830545871226, 'anticipation': 0.02300483168875236, 'positive': 0.03681258729313702, 'fear': 0.014469356333358309, 'trust': 0.023494175494572094, 'negative': 0.04651399316616406, 'surprise': 0.013271205234059611, 'valid_tweet_count': 3193.0}\n",
      "Calculating... Kelley_Smith.csv\n",
      "0\n",
      "{'anger': 0.02287878787878788, 'joy': 0.01534090909090909, 'sadness': 0.0029411764705882353, 'surprise': 0.0074866310160427805, 'anticipation': 0.013952101243500473, 'fear': 0.028698752228163992, 'trust': 0.056266219873408574, 'negative': 0.03137551990493167, 'positive': 0.08487174375332271, 'valid_tweet_count': 20.0, 'disgust': 0.0}\n",
      "Calculating... michaelaholmber.csv\n",
      "0\n",
      "{'disgust': 0.010320432787099362, 'negative': 0.027963217132032262, 'fear': 0.013278398154859804, 'sadness': 0.014582390679350927, 'anger': 0.01272347871064662, 'joy': 0.039693091497638694, 'surprise': 0.016887076660132026, 'anticipation': 0.042930399965107356, 'positive': 0.0807552088798864, 'trust': 0.048078935153044886, 'valid_tweet_count': 925.0}\n",
      "Calculating... Pharoe73_.csv\n",
      "0\n",
      "{'anger': 0.02199236640911616, 'joy': 0.017548365005992123, 'disgust': 0.0056664763544125455, 'sadness': 0.016644936983920035, 'surprise': 0.014674175479260223, 'anticipation': 0.028899161102550926, 'positive': 0.0671180827960489, 'fear': 0.015039871321027855, 'trust': 0.029378984812683712, 'negative': 0.03371220559655255, 'valid_tweet_count': 59.0}\n",
      "Calculating... CrazyMJsWife_.csv\n",
      "0\n",
      "{'anger': 0.018544746056308098, 'disgust': 0.012452809573113203, 'surprise': 0.021520129929886115, 'anticipation': 0.03861185188299875, 'fear': 0.01852275773766471, 'negative': 0.029101072735762148, 'joy': 0.08451198649427595, 'positive': 0.11283047829655499, 'sadness': 0.013302105698515313, 'trust': 0.06333920380150125, 'valid_tweet_count': 682.0}\n",
      "Calculating... Mark_Viktor.csv\n",
      "0\n",
      "{'anger': 0.02181729444180485, 'joy': 0.024682680857676425, 'disgust': 0.022846399581516096, 'sadness': 0.02007413204467202, 'surprise': 0.010143709312112358, 'anticipation': 0.025878405773280436, 'positive': 0.05099637573395174, 'fear': 0.02131298659203385, 'trust': 0.031122608303059133, 'negative': 0.04072618674660777, 'valid_tweet_count': 830.0}\n",
      "Calculating... RRStumpf.csv\n",
      "0\n",
      "{'anger': 0.019059603183797975, 'joy': 0.026518627238618073, 'disgust': 0.013067188487359023, 'sadness': 0.019215280554939297, 'surprise': 0.014808309105840198, 'anticipation': 0.024169629779067923, 'fear': 0.022871934670813134, 'trust': 0.048816169455502156, 'negative': 0.04393850512276562, 'positive': 0.08906421494290874, 'valid_tweet_count': 311.0}\n",
      ".csvulating... krlanavarrete\n",
      "0\n",
      "{'anger': 0.005747126436781609, 'anticipation': 0.002028397565922921, 'fear': 0.005747126436781609, 'negative': 0.005747126436781609, 'valid_tweet_count': 58.0, 'joy': 0.0, 'disgust': 0.0, 'sadness': 0.0, 'surprise': 0.0, 'positive': 0.0, 'trust': 0.0}\n",
      "Calculating... surfcosta.csv\n",
      "0\n",
      "{'surprise': 0.00625, 'trust': 0.07333333333333333, 'valid_tweet_count': 20.0, 'anger': 0.0, 'joy': 0.0, 'disgust': 0.0, 'sadness': 0.0, 'anticipation': 0.0, 'positive': 0.0, 'fear': 0.0, 'negative': 0.0}\n",
      "Calculating... JerryBray.csv\n",
      "0\n",
      "1000\n",
      "{'positive': 0.05661950151017736, 'trust': 0.03463815228531531, 'joy': 0.026689023178710213, 'anger': 0.019577185473723193, 'disgust': 0.016040628333865162, 'sadness': 0.020143700494447084, 'surprise': 0.013369006090797875, 'anticipation': 0.02487243096705483, 'fear': 0.028795551268940272, 'negative': 0.045090933475582344, 'valid_tweet_count': 1023.0}\n",
      "Calculating... rahulvr0507.csv\n",
      "0\n",
      "{'anger': 0.011047979797979798, 'joy': 0.0279491341991342, 'surprise': 0.008928571428571428, 'positive': 0.05504148629148629, 'fear': 0.0030303030303030303, 'trust': 0.028814935064935064, 'negative': 0.011047979797979798, 'anticipation': 0.0334505772005772, 'valid_tweet_count': 22.0, 'disgust': 0.0, 'sadness': 0.0}\n",
      "Calculating... tonyutter_.csv\n",
      "0\n",
      "1000\n",
      "{'anger': 0.015449812774215484, 'disgust': 0.012548238964609878, 'sadness': 0.017841825399951064, 'surprise': 0.019057491538376978, 'fear': 0.016795257947812912, 'negative': 0.03351423988504631, 'anticipation': 0.03527856705715417, 'positive': 0.06271954477234659, 'trust': 0.03737855842998171, 'joy': 0.03523312317318515, 'valid_tweet_count': 1698.0}\n",
      "Calculating... soon2bking.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "{'anger': 0.013113334704536758, 'joy': 0.032649742811505636, 'disgust': 0.006525900523339506, 'sadness': 0.012986482095827135, 'surprise': 0.00837466044936342, 'anticipation': 0.02154979192519866, 'positive': 0.05491805787908759, 'fear': 0.014862212663957219, 'trust': 0.04137415994061765, 'negative': 0.023207821121042402, 'valid_tweet_count': 3029.0}\n",
      "Calculating... trixa09.csv\n",
      "0\n",
      "1000\n",
      "{'disgust': 0.01811971961969876, 'anger': 0.020700356879246228, 'trust': 0.03792563546518309, 'sadness': 0.016972223909228406, 'positive': 0.05637997493595633, 'joy': 0.03903702733699847, 'surprise': 0.014300746352861342, 'anticipation': 0.04026327608878268, 'fear': 0.022253887809083283, 'negative': 0.04191173217069095, 'valid_tweet_count': 1059.0}\n",
      "Calculating... coni12thwoman.csv\n",
      "0\n",
      "{'anger': 0.027959183673469383, 'joy': 0.05455247133818562, 'disgust': 0.01933373349339736, 'sadness': 0.039070294784580496, 'surprise': 0.03908555729984301, 'positive': 0.10544019006203882, 'fear': 0.049467120181405894, 'trust': 0.06969866617975862, 'anticipation': 0.05467865817655733, 'negative': 0.07078498065893024, 'valid_tweet_count': 35.0}\n",
      "Calculating... AlexCorretja74.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "{'anger': 0.0032276233332123104, 'joy': 0.008071057059392777, 'disgust': 0.002523487381776763, 'sadness': 0.0025359343431346024, 'surprise': 0.0034201862821402564, 'anticipation': 0.007160256221131853, 'positive': 0.014617507918260613, 'fear': 0.0035440416289721044, 'trust': 0.010616555470137602, 'negative': 0.008332416356953132, 'valid_tweet_count': 4728.0}\n",
      "Calculating... NorCalBill.csv\n",
      "0\n",
      "{'anger': 0.009614177267670335, 'joy': 0.035986668408641745, 'disgust': 0.002324434274091025, 'sadness': 0.008244434274091024, 'surprise': 0.02386022690889025, 'anticipation': 0.042238486654626275, 'positive': 0.0639406380188962, 'fear': 0.011854870152872751, 'trust': 0.03170137715771314, 'negative': 0.018960955122977102, 'valid_tweet_count': 125.0}\n",
      "Calculating... PathfinderVill.csv\n",
      "0\n",
      "{'joy': 0.011350807662283071, 'disgust': 0.001366120218579235, 'sadness': 0.001366120218579235, 'surprise': 0.001366120218579235, 'anticipation': 0.014356218739682744, 'fear': 0.007962529274004681, 'trust': 0.024105325655575122, 'negative': 0.007962529274004681, 'positive': 0.062133857866217085, 'valid_tweet_count': 61.0, 'anger': 0.0}\n",
      "Calculating... MyShanDairy.csv\n",
      "0\n",
      "{'anger': 0.0025929751792272073, 'disgust': 0.0028811010201143217, 'sadness': 0.006296551253347959, 'surprise': 0.012109588483190045, 'fear': 0.003090665639883859, 'negative': 0.008641372176794412, 'anticipation': 0.04527991626545992, 'positive': 0.08585870723585819, 'trust': 0.044408975438619644, 'joy': 0.062320851570923035, 'valid_tweet_count': 302.0}\n",
      "Calculating... Martin3zz10.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "{'anger': 0.01710572931249489, 'joy': 0.03078586849908372, 'disgust': 0.016528992296145878, 'sadness': 0.01918517118798636, 'surprise': 0.014668081195516252, 'anticipation': 0.042052341723693126, 'positive': 0.048855697102928246, 'fear': 0.01925058052715079, 'trust': 0.029971008920148763, 'negative': 0.040311749687225534, 'valid_tweet_count': 12680.0}\n",
      "Calculating... nealcapapas.csv\n",
      "0\n",
      "1000\n",
      "{'joy': 0.028979835462790662, 'sadness': 0.013177348929106332, 'surprise': 0.012103091913432387, 'anticipation': 0.03214657212845962, 'positive': 0.052980493753100606, 'trust': 0.0346622902567991, 'disgust': 0.010880174111928235, 'anger': 0.016188548101784658, 'fear': 0.018423934793348213, 'negative': 0.038362024895719424, 'valid_tweet_count': 1030.0}\n",
      "Calculating... cstapholz.csv\n",
      "0\n",
      "{'anger': 0.009995886466474702, 'joy': 0.0503752426063639, 'disgust': 0.0013986013986013986, 'sadness': 0.008049270990447461, 'surprise': 0.03635919635919636, 'anticipation': 0.04622663436428618, 'positive': 0.09290969777835181, 'fear': 0.01581725807732, 'trust': 0.06095483395518601, 'negative': 0.020257588988239143, 'valid_tweet_count': 65.0}\n",
      "Calculating... ryanbello.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "{'anger': 0.013469913033405442, 'joy': 0.03789971947402437, 'disgust': 0.00864555728524838, 'sadness': 0.014664855616372539, 'surprise': 0.016883446504312033, 'anticipation': 0.03281247346225722, 'positive': 0.06725639219210704, 'fear': 0.016699347365306393, 'trust': 0.03639485480772222, 'negative': 0.028543894375918782, 'valid_tweet_count': 7199.0}\n",
      "Calculating... mljoker93_.csv\n",
      "0\n",
      "{'anger': 0.01790741309972079, 'joy': 0.043399549168779944, 'disgust': 0.022702297702297702, 'sadness': 0.018361776068542984, 'surprise': 0.01961820231051, 'positive': 0.055681238785634385, 'fear': 0.025342341290866453, 'trust': 0.03967264420561124, 'negative': 0.06222418655183257, 'anticipation': 0.04323859900782978, 'valid_tweet_count': 91.0}\n",
      "Calculating... RebeccaMHowell_.csv\n",
      "0\n",
      "{'anger': 0.015830362665974325, 'joy': 0.0310035120601477, 'disgust': 0.00984464934310785, 'sadness': 0.01806173217279786, 'surprise': 0.013978661448528062, 'anticipation': 0.04154658407415067, 'positive': 0.05493811840725976, 'fear': 0.01948307612872287, 'trust': 0.03654661884544988, 'negative': 0.03212181498900571, 'valid_tweet_count': 901.0}\n",
      ".csvulating... KiiKcreate\n",
      "0\n",
      "{'anger': 0.009213248142438991, 'joy': 0.03344038224890676, 'disgust': 0.004078676017917573, 'sadness': 0.013173978186473699, 'surprise': 0.01383651567866248, 'anticipation': 0.03625077195197238, 'positive': 0.053560825895607546, 'fear': 0.004955795231830868, 'trust': 0.022553109686144657, 'negative': 0.014632360669564986, 'valid_tweet_count': 729.0}\n",
      "Calculating... LoriJulia_.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "{'anger': 0.01329811142717825, 'joy': 0.04136069695013564, 'disgust': 0.008869232408433602, 'sadness': 0.014292869894487581, 'surprise': 0.01781900388767823, 'anticipation': 0.032635412336675905, 'positive': 0.070004668578663, 'fear': 0.0143018040648676, 'trust': 0.03881808631388545, 'negative': 0.02491845076558569, 'valid_tweet_count': 4500.0}\n",
      "Calculating... glomob.csv\n",
      "0\n",
      "{'anger': 0.031098153547133137, 'fear': 0.031098153547133137, 'anticipation': 0.05573224960980063, 'positive': 0.15400850094727675, 'trust': 0.1321401576503617, 'joy': 0.03166504697116942, 'valid_tweet_count': 147.0, 'disgust': 0.0, 'sadness': 0.0, 'surprise': 0.0, 'negative': 0.0}\n",
      "Calculating... carleton_snow.csv\n",
      "0\n",
      "{'anger': 0.00972193329172734, 'disgust': 0.006543990177722847, 'sadness': 0.013911685635672714, 'fear': 0.01663353802686149, 'trust': 0.036298443928306626, 'negative': 0.027880057559287602, 'surprise': 0.029426542408101167, 'anticipation': 0.05347194669048217, 'positive': 0.0847275110002395, 'joy': 0.04065551518970552, 'valid_tweet_count': 50.0}\n",
      ".csvulating... stephengillett\n",
      "0\n",
      "1000\n",
      "2000\n",
      "{'anger': 0.014391986165209958, 'joy': 0.024847529978537303, 'disgust': 0.006477981161329079, 'surprise': 0.015983358058982124, 'anticipation': 0.03171513042498104, 'fear': 0.019698937851941913, 'negative': 0.03049841401979852, 'sadness': 0.012025452609068498, 'trust': 0.038845744193296436, 'positive': 0.06049897348068246, 'valid_tweet_count': 2980.0}\n",
      "Calculating... KTej13.csv\n",
      "0\n",
      "1000\n",
      "{'anger': 0.011922957046259378, 'joy': 0.02310322075756789, 'disgust': 0.01164501783989462, 'sadness': 0.013997138795522217, 'surprise': 0.014596477856573569, 'anticipation': 0.023300506111481552, 'positive': 0.0542615113417058, 'fear': 0.014145151989708444, 'trust': 0.03568153316696727, 'negative': 0.031431094399016056, 'valid_tweet_count': 1297.0}\n",
      "Calculating... marceliuzca.csv\n",
      "0\n",
      "{'anger': 0.004047224196477928, 'joy': 0.002803443101950565, 'disgust': 0.006987070419906241, 'sadness': 0.004634565268893627, 'surprise': 0.0007107320540156361, 'anticipation': 0.0010424070125562661, 'positive': 0.007030101989770282, 'fear': 0.005291005291005291, 'trust': 0.007573244886677723, 'negative': 0.009094588385633161, 'valid_tweet_count': 201.0}\n",
      "Calculating... snakepitalehous.csv\n",
      "0\n",
      "{'joy': 0.013333333333333332, 'anticipation': 0.021666666666666667, 'positive': 0.0225, 'trust': 0.01888888888888889, 'negative': 0.005555555555555555, 'valid_tweet_count': 20.0, 'anger': 0.0, 'disgust': 0.0, 'sadness': 0.0, 'surprise': 0.0, 'fear': 0.0}\n",
      "Calculating... Oleblloyd_.csv\n",
      "0\n",
      "{'anger': 0.00853686567194881, 'joy': 0.015309879459366084, 'disgust': 0.0016558278428433467, 'sadness': 0.009206205134074297, 'positive': 0.053363582661313545, 'trust': 0.029300609315880077, 'surprise': 0.007597465769290434, 'anticipation': 0.017820733316600362, 'fear': 0.015154936243836, 'negative': 0.016203748630091018, 'valid_tweet_count': 108.0}\n",
      ".csvulating... MrPhilHarrison\n",
      "0\n",
      "{'surprise': 0.01911748835794153, 'anticipation': 0.04487208428600348, 'joy': 0.040662145869606536, 'anger': 0.008819207602518036, 'disgust': 0.00462579674443406, 'sadness': 0.009225647215027563, 'fear': 0.010097840742094083, 'negative': 0.017222272004314924, 'positive': 0.07796494075970248, 'trust': 0.04225727800055488, 'valid_tweet_count': 408.0}\n",
      "Calculating... Sequoioideae.csv\n",
      "0\n",
      "{'anger': 0.008044598636066916, 'joy': 0.08582835487867412, 'disgust': 0.07954744649135839, 'sadness': 0.08387745728355404, 'surprise': 0.07995538576753844, 'anticipation': 0.08638411056580081, 'positive': 0.0933574258449386, 'fear': 0.08325631916241595, 'trust': 0.08706257012267604, 'negative': 0.08908669980747914, 'valid_tweet_count': 280.0}\n",
      "Calculating... sharkims.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "{'anger': 0.01485035126651189, 'joy': 0.028071454410004144, 'disgust': 0.011070686310278582, 'sadness': 0.014708183787101647, 'surprise': 0.017308847159765522, 'anticipation': 0.03221528468498015, 'positive': 0.05634346632210781, 'fear': 0.01457596458900272, 'trust': 0.03317836418220073, 'negative': 0.028183147127366862, 'valid_tweet_count': 2561.0}\n",
      "Calculating... suzannetaub.csv\n",
      "0\n",
      "{'anger': 0.0203266872016872, 'joy': 0.05974213960352436, 'disgust': 0.023050453334544245, 'sadness': 0.02157844694135017, 'surprise': 0.02254730524570464, 'anticipation': 0.021361326293437278, 'positive': 0.08408039246290819, 'fear': 0.013853586434390976, 'trust': 0.040377244136414275, 'negative': 0.04516548147429188, 'valid_tweet_count': 330.0}\n",
      "Calculating... tweetviaphoenix.csv\n",
      "0\n",
      "1000\n",
      "{'anger': 0.015051489586064054, 'joy': 0.03836165607442211, 'disgust': 0.005379484581612237, 'sadness': 0.016652127423404016, 'surprise': 0.01790523601693814, 'anticipation': 0.03826178401976287, 'positive': 0.13013059930613055, 'fear': 0.0213013744529702, 'trust': 0.046476357566783144, 'negative': 0.03800284969167953, 'valid_tweet_count': 1880.0}\n",
      "Calculating... federalli169_.csv\n",
      "0\n",
      "{'anger': 0.02576845758079752, 'joy': 0.027507458894864542, 'disgust': 0.01937357219995519, 'sadness': 0.014781055691620018, 'surprise': 0.013014493282282909, 'anticipation': 0.033301648438247296, 'positive': 0.0750985304190455, 'fear': 0.027999090079999754, 'trust': 0.05410978800900433, 'negative': 0.04789803680297664, 'valid_tweet_count': 240.0}\n",
      "Calculating... rodneykeene_.csv\n",
      "0\n",
      "{'anger': 0.016454149573559618, 'joy': 0.02524253766083831, 'disgust': 0.005504164970679458, 'sadness': 0.01284005911306393, 'surprise': 0.04036230916390877, 'anticipation': 0.028021685624165026, 'positive': 0.05235270791363841, 'fear': 0.021523992403690583, 'trust': 0.027923083387264677, 'negative': 0.02460023021196575, 'valid_tweet_count': 108.0}\n",
      "Calculating... JasminsTable.csv\n",
      "0\n",
      "{'joy': 0.027979797979797976, 'sadness': 0.006545454545454546, 'surprise': 0.002, 'anticipation': 0.01537878787878788, 'positive': 0.04256313131313132, 'trust': 0.026767676767676763, 'negative': 0.008545454545454545, 'valid_tweet_count': 20.0, 'anger': 0.0, 'disgust': 0.0, 'fear': 0.0}\n",
      "Calculating... lileiguang.csv\n",
      "0\n",
      "{'anger': 0.01735771517757341, 'joy': 0.04297106088862965, 'disgust': 0.008404157502893594, 'sadness': 0.020276654726466076, 'surprise': 0.018806088017084263, 'anticipation': 0.04131359513478872, 'fear': 0.022880784868845594, 'trust': 0.05168788989257965, 'negative': 0.03362197873349612, 'positive': 0.08530526504245096, 'valid_tweet_count': 242.0}\n",
      "Calculating... eilujkell.csv\n",
      "0\n",
      "{'anger': 0.007936507936507936, 'joy': 0.009259259259259259, 'disgust': 0.007936507936507936, 'sadness': 0.007275132275132274, 'surprise': 0.004273504273504274, 'anticipation': 0.038444580111246775, 'positive': 0.026098901098901096, 'fear': 0.0023148148148148147, 'trust': 0.015847578347578346, 'negative': 0.01521164021164021, 'valid_tweet_count': 18.0}\n",
      "Calculating... RobbinsGroupLLC_.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "{'joy': 0.025486873263070736, 'disgust': 0.007416211805147285, 'sadness': 0.011570120096289058, 'surprise': 0.00934696729988626, 'anticipation': 0.022379323930455008, 'positive': 0.06856753423854145, 'fear': 0.012742868905170419, 'trust': 0.03706951472752512, 'anger': 0.015324142982637012, 'negative': 0.02902476736278592, 'valid_tweet_count': 9420.0}\n",
      "Calculating... Warrej_.csv\n",
      "0\n",
      "1000\n",
      "{'anger': 0.01702854538773818, 'joy': 0.054392065046481676, 'disgust': 0.01669099516475539, 'sadness': 0.01652339756794026, 'surprise': 0.015411322843924002, 'anticipation': 0.0186135952871191, 'positive': 0.09291439652979068, 'fear': 0.018354460404810355, 'trust': 0.07519379550545321, 'negative': 0.04002873408066402, 'valid_tweet_count': 2000.0}\n",
      "Calculating... chasselljones.csv\n",
      "0\n",
      "{'anger': 0.0229310243844617, 'joy': 0.04008236502843317, 'disgust': 0.011917882058096331, 'sadness': 0.018797650876187722, 'surprise': 0.022093317758952437, 'anticipation': 0.04585911902660278, 'positive': 0.06788724548518536, 'fear': 0.03258004860192423, 'trust': 0.04379036281439098, 'negative': 0.03065716518234818, 'valid_tweet_count': 55.0}\n",
      "Calculating... qwikshower.csv\n",
      "0\n",
      "{'anger': 0.015476190476190473, 'joy': 0.030537518037518037, 'disgust': 0.011201298701298702, 'sadness': 0.004464285714285714, 'surprise': 0.013095238095238094, 'anticipation': 0.027759740259740255, 'positive': 0.058991702741702734, 'fear': 0.004464285714285714, 'trust': 0.06095598845598845, 'negative': 0.013582251082251081, 'valid_tweet_count': 20.0}\n",
      "Calculating... ricinMD_.csv\n",
      "0\n",
      "{'anger': 0.03890901847861123, 'joy': 0.040867418173552765, 'disgust': 0.028603903175085373, 'sadness': 0.02892329030368002, 'surprise': 0.0393204158111318, 'anticipation': 0.03778971506202556, 'positive': 0.06957692011775775, 'fear': 0.030870079227460667, 'trust': 0.04386499188199258, 'negative': 0.06195851487604629, 'valid_tweet_count': 531.0}\n",
      "Calculating... HumboldtMobile.csv\n",
      "0\n",
      "{'anger': 0.005165078570317156, 'disgust': 0.004199735170380288, 'sadness': 0.008077152412254231, 'surprise': 0.01734608980709706, 'anticipation': 0.04999601924566071, 'fear': 0.005535654930000953, 'trust': 0.043658794752517015, 'negative': 0.012265384967963939, 'positive': 0.10177660882906629, 'joy': 0.07779294735885132, 'valid_tweet_count': 859.0}\n",
      "Calculating... TheBandTheYanks.csv\n",
      "0\n",
      "{'anger': 0.008116883116883116, 'joy': 0.029061624649859945, 'disgust': 0.0074866310160427805, 'sadness': 0.01992997198879552, 'surprise': 0.02278711484593838, 'positive': 0.037633053221288515, 'trust': 0.014215686274509804, 'negative': 0.03409090909090909, 'anticipation': 0.029929971988795517, 'fear': 0.010714285714285714, 'valid_tweet_count': 20.0}\n",
      "Calculating... JCitrolo.csv\n",
      "0\n",
      "{'anger': 0.010329893228494893, 'joy': 0.03528072456567697, 'disgust': 0.005525672941182655, 'sadness': 0.008987031181986321, 'surprise': 0.013888013300901076, 'anticipation': 0.03448789756697871, 'positive': 0.08692075903124237, 'fear': 0.013723788289661414, 'trust': 0.04230646891110953, 'negative': 0.02185749674492454, 'valid_tweet_count': 799.0}\n",
      "Calculating... chesskillertips.csv\n",
      "0\n",
      "{'anger': 0.0054928320996373925, 'joy': 0.02699149535244276, 'disgust': 0.0013726725724946564, 'sadness': 0.008225368815550067, 'surprise': 0.025246876657696187, 'anticipation': 0.020763816097909282, 'positive': 0.04425606511061862, 'fear': 0.007307841250018499, 'trust': 0.029978849714477427, 'negative': 0.006846143527451211, 'valid_tweet_count': 115.0}\n",
      "Calculating... GabriellaNY.csv\n",
      "0\n",
      "{'anger': 0.01123515915996059, 'joy': 0.08808746837066415, 'disgust': 0.004437557959814311, 'sadness': 0.009522305802745323, 'surprise': 0.018096923229872452, 'fear': 0.009877543759447526, 'trust': 0.053465452442912745, 'negative': 0.01967002045652391, 'anticipation': 0.049504168000859036, 'positive': 0.113882100020875, 'valid_tweet_count': 806.0}\n",
      "Calculating... vicki_hou.csv\n",
      "0\n",
      "{'anger': 0.017060701073049262, 'joy': 0.04080840815017413, 'disgust': 0.02262676337859225, 'sadness': 0.028689551128921374, 'surprise': 0.02470244026029818, 'positive': 0.08402962378348275, 'trust': 0.04541348303652673, 'anticipation': 0.03742427960911646, 'fear': 0.02496815085250779, 'negative': 0.04043901407328927, 'valid_tweet_count': 245.0}\n",
      ".csvulating... ibjade\n",
      "0\n",
      "{'anger': 0.0073716241069086055, 'joy': 0.03787703700548032, 'disgust': 0.0045268953369808134, 'sadness': 0.006393608108316874, 'surprise': 0.019920295041211927, 'anticipation': 0.03434620257110187, 'positive': 0.06933047916088735, 'fear': 0.007800554894105982, 'trust': 0.042004914626429274, 'negative': 0.01728399551177803, 'valid_tweet_count': 840.0}\n",
      "Calculating... Rajacenna.csv\n",
      "0\n",
      "1000\n",
      "{'anger': 0.007119178936406878, 'joy': 0.052090953646478665, 'disgust': 0.00701576589261304, 'sadness': 0.009341884756022763, 'surprise': 0.026626737887063878, 'anticipation': 0.04715930772986452, 'positive': 0.06959303335247141, 'fear': 0.009347650303718239, 'trust': 0.04136733316089448, 'negative': 0.017263270294729835, 'valid_tweet_count': 1864.0}\n",
      "Calculating... revjeffgrant.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "{'anger': 0.036390435902862686, 'joy': 0.0367750482182662, 'disgust': 0.014264925445910105, 'sadness': 0.026217594104504128, 'surprise': 0.008513131137137671, 'anticipation': 0.04109626020012879, 'positive': 0.07838637540150582, 'fear': 0.035088358740949094, 'trust': 0.062241383563170216, 'negative': 0.05432739206109717, 'valid_tweet_count': 9957.0}\n",
      "Calculating... officership_.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "{'anger': 0.01728677049600973, 'joy': 0.025423973503404102, 'disgust': 0.00957409858414049, 'sadness': 0.015496938937406333, 'surprise': 0.013806637531377784, 'positive': 0.07208106687297981, 'fear': 0.023450151393527904, 'trust': 0.0479588528633811, 'negative': 0.035893960352808264, 'anticipation': 0.032860901332022255, 'valid_tweet_count': 4947.0}\n",
      "Calculating... plagerisms.csv\n",
      "0\n",
      "{'anger': 0.01715764638106843, 'disgust': 0.016279582248086212, 'sadness': 0.013316652366620428, 'fear': 0.016810953460421548, 'negative': 0.025543653172362162, 'positive': 0.047463590625946545, 'joy': 0.02439366646431925, 'surprise': 0.012828366738272224, 'anticipation': 0.023082765828929635, 'trust': 0.02793348077413816, 'valid_tweet_count': 480.0}\n",
      "Calculating... josephzhou.csv\n",
      "0\n",
      "{'anger': 0.013267873324003112, 'joy': 0.014107869245412692, 'disgust': 0.005778085650132895, 'sadness': 0.010600667823131304, 'surprise': 0.008817929847969969, 'anticipation': 0.026477432360973767, 'positive': 0.055823130051561, 'fear': 0.016959309290010015, 'trust': 0.03831725069105376, 'negative': 0.032397858591618534, 'valid_tweet_count': 254.0}\n",
      "Calculating... ronaldskelton.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "{'disgust': 0.0033434825569480125, 'trust': 0.040930874765803676, 'sadness': 0.007244948651079745, 'anger': 0.005095107459197384, 'fear': 0.009128020869594293, 'negative': 0.01544925239103449, 'surprise': 0.010915497704949937, 'anticipation': 0.02814067146064512, 'positive': 0.07674946598901752, 'joy': 0.02650042564642152, 'valid_tweet_count': 5980.0}\n",
      "Calculating... slamb63_.csv\n",
      "0\n",
      "{'anger': 0.012055155436759127, 'joy': 0.0150638607046599, 'disgust': 0.00897386136009408, 'sadness': 0.014677926584557828, 'surprise': 0.005290980990088313, 'anticipation': 0.014718357822211203, 'positive': 0.045207339268816135, 'fear': 0.0216497019052067, 'trust': 0.018746013060538975, 'negative': 0.03304593177904029, 'valid_tweet_count': 112.0}\n",
      "Calculating... Daytrippr777.csv\n",
      "0\n",
      "{'anger': 0.014654429244833612, 'joy': 0.02757766017552928, 'disgust': 0.008450781689162403, 'sadness': 0.011189701656030164, 'surprise': 0.019427740935018013, 'anticipation': 0.034699299071906206, 'fear': 0.009979477386966827, 'trust': 0.03056771787453479, 'negative': 0.025180256016154152, 'positive': 0.05101947364509553, 'valid_tweet_count': 732.0}\n",
      "Calculating... Allison0414.csv\n",
      "0\n",
      "{'anger': 0.0101010101010101, 'disgust': 0.0101010101010101, 'sadness': 0.004545454545454545, 'fear': 0.004545454545454545, 'negative': 0.0101010101010101, 'joy': 0.08740601503759397, 'surprise': 0.055059523809523815, 'anticipation': 0.03333333333333333, 'positive': 0.11801378446115289, 'trust': 0.08358395989974937, 'valid_tweet_count': 20.0}\n",
      "Calculating... forginglory.csv\n",
      "0\n",
      "1000\n",
      "{'joy': 0.023960388144168433, 'surprise': 0.014006201586434714, 'anticipation': 0.027740711943033774, 'positive': 0.04679191583149063, 'trust': 0.03645828615938947, 'anger': 0.019197363458269806, 'disgust': 0.015198716402380762, 'sadness': 0.015050115076947784, 'fear': 0.019724468566840084, 'negative': 0.032649172400291075, 'valid_tweet_count': 1868.0}\n",
      "Calculating... VanessaShealy.csv\n",
      "0\n",
      "1000\n",
      "{'anger': 0.007065264732994938, 'joy': 0.04150615744483778, 'disgust': 0.004866748820370949, 'sadness': 0.010236392226446824, 'surprise': 0.015209855786600399, 'fear': 0.00891625049822069, 'trust': 0.04191055160106841, 'negative': 0.0170106128748051, 'anticipation': 0.03948967701187734, 'positive': 0.06443490884980996, 'valid_tweet_count': 1894.0}\n",
      "Calculating... JoesNoLimits.csv\n",
      "0\n",
      "1000\n",
      "{'anger': 0.006093134216860247, 'joy': 0.04846642045010859, 'disgust': 0.0017766116110336009, 'sadness': 0.005259564614728605, 'surprise': 0.009524184068290907, 'anticipation': 0.04975018962760821, 'positive': 0.07012785079480255, 'fear': 0.008166575939185475, 'trust': 0.03708665551279336, 'negative': 0.010719639184630515, 'valid_tweet_count': 1202.0}\n",
      "Calculating... blpfunk_.csv\n",
      "0\n",
      "1000\n",
      "{'joy': 0.019941562767794692, 'disgust': 0.01289090180956897, 'sadness': 0.02569797790758965, 'surprise': 0.024467224564387, 'anticipation': 0.02502837689352262, 'positive': 0.05432925004046859, 'trust': 0.03815392671894846, 'anger': 0.020764171526930726, 'fear': 0.027023200280413166, 'negative': 0.04742652624081518, 'valid_tweet_count': 1331.0}\n",
      ".csvulating... MarceloRios75\n",
      "0\n",
      "{'anger': 0.0010744183725550187, 'joy': 8.662508662508663e-05, 'disgust': 0.0004632390113756573, 'sadness': 0.0005521437055435094, 'surprise': 0.00039067914067914065, 'anticipation': 0.00028153153153153153, 'positive': 0.0030568014553370377, 'fear': 0.0010744183725550187, 'trust': 0.0016825626490330138, 'negative': 0.001497896770861792, 'valid_tweet_count': 296.0}\n",
      "Calculating... duelly22_.csv\n",
      "0\n",
      "{'anger': 0.025241697851642698, 'joy': 0.04176623880722384, 'disgust': 0.025529188375690532, 'sadness': 0.02648652029249982, 'surprise': 0.02826485519976106, 'anticipation': 0.05340757824297626, 'positive': 0.07949137140119651, 'fear': 0.02420119518636151, 'trust': 0.05084324351097888, 'negative': 0.042193984792108945, 'valid_tweet_count': 89.0}\n",
      "Calculating... MDG1972_.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "{'anger': 0.027574572248166094, 'joy': 0.03491382844236441, 'disgust': 0.02648751197710805, 'sadness': 0.02199104441116205, 'surprise': 0.013462134733429066, 'anticipation': 0.017199053644315163, 'positive': 0.05626097979015247, 'fear': 0.027626875943385743, 'trust': 0.029555094297899244, 'negative': 0.057828675976393094, 'valid_tweet_count': 2514.0}\n",
      "Calculating... SalkMNLO.csv\n",
      "0\n",
      "{'joy': 0.08333333333333333, 'anticipation': 0.027777777777777776, 'positive': 0.08333333333333333, 'trust': 0.03333333333333333, 'valid_tweet_count': 6.0, 'anger': 0.0, 'disgust': 0.0, 'sadness': 0.0, 'surprise': 0.0, 'fear': 0.0, 'negative': 0.0}\n",
      "Calculating... globulltrader_.csv\n",
      "0\n",
      "{'joy': 0.026606657457267213, 'surprise': 0.0037037037037037034, 'anticipation': 0.008754208754208754, 'positive': 0.07468497923313203, 'trust': 0.0452403976742212, 'anger': 0.014224837662337664, 'fear': 0.016497564935064934, 'negative': 0.028706800144300142, 'disgust': 0.00909090909090909, 'sadness': 0.01700261544011544, 'valid_tweet_count': 20.0}\n",
      "Calculating... 1SunRisen.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "{'anger': 0.019824825141973253, 'joy': 0.019973165550453968, 'disgust': 0.018070820870834742, 'sadness': 0.02125795443879462, 'surprise': 0.010050885150418578, 'anticipation': 0.021356762266378126, 'positive': 0.04741662261783733, 'fear': 0.022189128259351047, 'trust': 0.034955325610839735, 'negative': 0.04648501801424057, 'valid_tweet_count': 7160.0}\n",
      "Calculating... princess_rah_12.csv\n",
      "0\n",
      "{'anger': 0.017182200837324177, 'joy': 0.052620290097292806, 'disgust': 0.026214458901840303, 'surprise': 0.013848510801319975, 'anticipation': 0.025093720126823826, 'positive': 0.07998770894241564, 'trust': 0.03593273034521693, 'negative': 0.03486876898321911, 'fear': 0.017241539822184983, 'sadness': 0.017153214169343203, 'valid_tweet_count': 310.0}\n",
      "Calculating... eileengreenauth.csv\n",
      "0\n",
      "1000\n",
      "{'anger': 0.006185381628354714, 'disgust': 0.005791582168439704, 'sadness': 0.007322110380666991, 'surprise': 0.015963359879468394, 'anticipation': 0.02536590338734025, 'fear': 0.009375666060075491, 'negative': 0.018270511274911232, 'trust': 0.03788842570779228, 'positive': 0.05170661650275599, 'joy': 0.03584200563471614, 'valid_tweet_count': 1099.0}\n",
      ".csvulating... alexisohanian\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "{'anger': 0.00938229030096936, 'joy': 0.03510829267383462, 'disgust': 0.006551174267358327, 'sadness': 0.007604147811865474, 'surprise': 0.014801211769294349, 'anticipation': 0.03489466724323217, 'fear': 0.010143240262021777, 'negative': 0.018389728059663955, 'positive': 0.07135092026723132, 'trust': 0.04136301528346543, 'valid_tweet_count': 5980.0}\n",
      "Calculating... susanne1229_.csv\n",
      "0\n",
      "{'anger': 0.01020408163265306, 'joy': 0.030952380952380953, 'disgust': 0.022379406307977738, 'sadness': 0.026275510204081635, 'surprise': 0.07746598639455782, 'anticipation': 0.03969363969363969, 'positive': 0.13423600209314496, 'fear': 0.07603586889301174, 'trust': 0.12658294086865515, 'negative': 0.05136054421768708, 'valid_tweet_count': 14.0}\n",
      "Calculating... DoLLyRach.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "{'anger': 0.014601811573156874, 'joy': 0.04087091793469235, 'disgust': 0.014235606749751491, 'sadness': 0.018205352606247217, 'surprise': 0.017338072933480483, 'anticipation': 0.04053069338078345, 'positive': 0.06141859428451956, 'fear': 0.017591434140212362, 'trust': 0.03728112247066715, 'negative': 0.03404971278333693, 'valid_tweet_count': 13543.0}\n",
      "Calculating... VictoriaAnn841.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "{'anger': 0.028505040563233247, 'disgust': 0.026838881472183287, 'sadness': 0.023850007979037698, 'fear': 0.023914011197565522, 'negative': 0.06362987258198449, 'joy': 0.04880342277203137, 'surprise': 0.018377876161532473, 'anticipation': 0.0350531509187751, 'positive': 0.07842722455982097, 'trust': 0.049362785131886903, 'valid_tweet_count': 2270.0}\n",
      "Calculating... mela0521.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "{'anger': 0.013976843418881422, 'joy': 0.04715625869597485, 'disgust': 0.012532797754024497, 'sadness': 0.01720720594593501, 'surprise': 0.019634303600204954, 'anticipation': 0.042125013780282994, 'positive': 0.07649659918766692, 'fear': 0.02023880868864981, 'trust': 0.046003096579521535, 'negative': 0.033663291243041266, 'valid_tweet_count': 3486.0}\n",
      "Calculating... TNDVS_.csv\n",
      "0\n",
      "{'anger': 0.006200980370490556, 'disgust': 0.0030677169132766226, 'sadness': 0.012398476003450731, 'surprise': 0.007207970897225504, 'fear': 0.01695214540882177, 'negative': 0.020549628824355813, 'anticipation': 0.028163329690152835, 'positive': 0.07946428552843916, 'trust': 0.051501461106536445, 'joy': 0.021338556334670484, 'valid_tweet_count': 545.0}\n",
      "Calculating... Tassie206.csv\n",
      "0\n",
      "{'anger': 0.013871625309400854, 'joy': 0.059997479322096384, 'disgust': 0.011217709999817124, 'sadness': 0.018838868063684493, 'surprise': 0.01997045943804575, 'anticipation': 0.03615495915267854, 'positive': 0.08829144306100005, 'fear': 0.01803084143219184, 'trust': 0.0475037952226781, 'negative': 0.03547431330484634, 'valid_tweet_count': 359.0}\n",
      "Calculating... Jakeweindling_.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "{'anger': 0.020688903746572705, 'disgust': 0.01528732585166663, 'sadness': 0.01602837678454586, 'fear': 0.021139547344520473, 'negative': 0.0398949296602204, 'positive': 0.051067362530082754, 'trust': 0.03607716050330204, 'surprise': 0.016177222011851455, 'anticipation': 0.02530977186689386, 'joy': 0.02256859632892093, 'valid_tweet_count': 8920.0}\n",
      "Calculating... shipmeant2b_.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "{'anger': 0.019418270258018188, 'joy': 0.03494787842370612, 'disgust': 0.012124671771604846, 'sadness': 0.021600137771286086, 'surprise': 0.01860050171203742, 'anticipation': 0.036721695736992965, 'fear': 0.03107519972240214, 'negative': 0.04199379332889547, 'positive': 0.07545469169928838, 'trust': 0.04831033520674437, 'valid_tweet_count': 7970.0}\n",
      "Calculating... alexnoodle.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "{'joy': 0.0254612090896467, 'sadness': 0.016669684891048888, 'surprise': 0.014308660194538133, 'anticipation': 0.028305490635680414, 'positive': 0.05261494116225468, 'fear': 0.019065342843749007, 'trust': 0.034597238055526995, 'disgust': 0.01796524648061669, 'anger': 0.01807212841200613, 'negative': 0.03849573638113168, 'valid_tweet_count': 4960.0}\n",
      "Calculating... Killamanjaro85_.csv\n",
      "0\n",
      "{'anger': 0.01329599567099567, 'disgust': 0.009446803196803197, 'sadness': 0.02451073926073926, 'surprise': 0.004982517482517483, 'negative': 0.05219555444555444, 'joy': 0.027393689643689646, 'positive': 0.10219222444222445, 'trust': 0.05857309357309357, 'anticipation': 0.03775624375624376, 'fear': 0.03490451215451216, 'valid_tweet_count': 20.0}\n",
      "Calculating... wayilong.csv\n",
      "0\n",
      "{'anger': 0.003859791524265208, 'joy': 0.04759926823654691, 'disgust': 0.020756578947368418, 'sadness': 0.0046007876834944506, 'surprise': 0.02481632794511766, 'positive': 0.06855548817736858, 'fear': 0.010393660296434471, 'trust': 0.045535044512579066, 'negative': 0.02967941324981237, 'anticipation': 0.041186389375908634, 'valid_tweet_count': 266.0}\n",
      "Calculating... DarylCerdinio.csv\n",
      "0\n",
      "{'anger': 0.01116964758269106, 'joy': 0.04093969454641393, 'disgust': 0.010016844157160363, 'sadness': 0.008990345403388882, 'surprise': 0.008886754440114122, 'anticipation': 0.03264111380537794, 'positive': 0.06584207816576257, 'fear': 0.012196398609442088, 'trust': 0.03244285953927122, 'negative': 0.024719061132104612, 'valid_tweet_count': 99.0}\n",
      "Calculating... dirtteamgirl.csv\n",
      "0\n",
      "{'anger': 0.008254677886129087, 'disgust': 0.006756339153897692, 'sadness': 0.006048891440274935, 'surprise': 0.025486655719961834, 'fear': 0.01005441192477172, 'trust': 0.04873669871586437, 'negative': 0.020802488847036282, 'anticipation': 0.056743824411096884, 'positive': 0.08332674953601041, 'joy': 0.06303437465420994, 'valid_tweet_count': 824.0}\n",
      "Calculating... MyDailyArmor.csv\n",
      "0\n",
      "{'disgust': 0.007958937198067634, 'anger': 0.0011111111111111111, 'fear': 0.016454365079365076, 'sadness': 0.004166666666666667, 'surprise': 0.007838203463203464, 'positive': 0.08572761296674339, 'negative': 0.015377352116482551, 'joy': 0.05602013626470147, 'anticipation': 0.03496404983904984, 'trust': 0.06207926855752943, 'valid_tweet_count': 20.0}\n",
      "Calculating... nikitamaloo.csv\n",
      "0\n",
      "{'anger': 0.008848707393588178, 'disgust': 0.010080645161290322, 'sadness': 0.006429023222192102, 'surprise': 0.016597477211803588, 'anticipation': 0.04525435746660654, 'negative': 0.020129695275619707, 'joy': 0.058135585355199866, 'positive': 0.08860110332259036, 'fear': 0.021146443605996185, 'trust': 0.056718385299355044, 'valid_tweet_count': 62.0}\n",
      "Calculating... newstiger.csv\n",
      "0\n",
      "{'sadness': 0.02066189943459334, 'surprise': 0.01584408641070639, 'anticipation': 0.02996197663082642, 'fear': 0.028696473819075547, 'trust': 0.044524470379618424, 'disgust': 0.016246483094608865, 'anger': 0.01898439852820895, 'negative': 0.04782738917484262, 'positive': 0.058405009842133884, 'joy': 0.02723748789001437, 'valid_tweet_count': 987.0}\n",
      "Calculating... AmyChoyne.csv\n",
      "0\n",
      "{'anger': 0.02555580013207132, 'joy': 0.097051763024497, 'disgust': 0.017800890258517377, 'sadness': 0.014599383667180275, 'surprise': 0.017561205273069678, 'anticipation': 0.05091240332581526, 'positive': 0.1343906952786835, 'fear': 0.020552376060850634, 'trust': 0.061850664687805444, 'negative': 0.033223744240693395, 'valid_tweet_count': 118.0}\n",
      "Calculating... ngonzales78.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "{'anger': 0.018860753585991506, 'joy': 0.010225142250419525, 'disgust': 0.011228013667731747, 'sadness': 0.005850078107674669, 'surprise': 0.006815828663591652, 'anticipation': 0.008604732423578745, 'positive': 0.017991573264096963, 'fear': 0.020263048457477676, 'trust': 0.012906481169195648, 'negative': 0.02832610442080434, 'valid_tweet_count': 2656.0}\n",
      "Calculating... rajnish_samir.csv\n",
      "0\n",
      "{'anger': 0.004532348607222324, 'disgust': 0.004921100480820214, 'sadness': 0.008720719862157045, 'fear': 0.01126098111901436, 'negative': 0.008780353595613494, 'joy': 0.014776197797217836, 'surprise': 0.013260288096323618, 'anticipation': 0.019045064895032306, 'positive': 0.040512876621757454, 'trust': 0.038256941053502885, 'valid_tweet_count': 114.0}\n",
      "Calculating... dtonseth.csv\n",
      "0\n",
      "{'anger': 0.014074373164812512, 'joy': 0.020231283005550053, 'disgust': 0.008091684479314187, 'sadness': 0.010108731573717392, 'surprise': 0.010165138019080719, 'anticipation': 0.03312395878440237, 'positive': 0.03997189445577036, 'fear': 0.012369382795218703, 'trust': 0.02910697520738401, 'negative': 0.02614435712645273, 'valid_tweet_count': 588.0}\n",
      ".csvulating... mamoonha\n",
      "0\n",
      "1000\n",
      "{'anger': 0.008830712955777944, 'joy': 0.03620377031778755, 'disgust': 0.006694540246193499, 'sadness': 0.01010949633413522, 'surprise': 0.017198238325283905, 'anticipation': 0.03683081980422902, 'positive': 0.07405938646538708, 'fear': 0.012828045862387368, 'trust': 0.045847855748955765, 'negative': 0.02364292663282557, 'valid_tweet_count': 1324.0}\n",
      "Calculating... healthyfather.csv\n",
      "0\n",
      "{'anger': 0.009887427747583492, 'joy': 0.052406302566616665, 'disgust': 0.008598348494557108, 'sadness': 0.014100531804179863, 'surprise': 0.02299268351309767, 'anticipation': 0.04150422953353714, 'fear': 0.019684551621885076, 'trust': 0.05112006741634424, 'negative': 0.02723944065044124, 'positive': 0.10251584797397899, 'valid_tweet_count': 201.0}\n",
      "Calculating... djones_weather.csv\n",
      "0\n",
      "{'anger': 0.005008738657416684, 'joy': 0.005347903486523342, 'disgust': 0.001672903367818622, 'sadness': 0.0017050913842681396, 'surprise': 0.003429273510992639, 'negative': 0.012824512328444143, 'fear': 0.0029591531279816183, 'anticipation': 0.010686492454206234, 'positive': 0.026278479134338242, 'trust': 0.017655064634802112, 'valid_tweet_count': 413.0}\n",
      "Calculating... singlaank.csv\n",
      "0\n",
      "1000\n",
      "{'anger': 0.005237409286241942, 'negative': 0.01306805627342787, 'fear': 0.007490190335202907, 'sadness': 0.005610851641781256, 'joy': 0.029817646905362823, 'disgust': 0.004827631422073866, 'surprise': 0.014437535037654008, 'anticipation': 0.0353857776888223, 'positive': 0.06465121199773236, 'trust': 0.04112354527941064, 'valid_tweet_count': 1483.0}\n",
      "Calculating... PhillipTino.csv\n",
      "0\n",
      "{'joy': 0.022727272727272728, 'surprise': 0.02987012987012987, 'anticipation': 0.04489177489177489, 'positive': 0.022727272727272728, 'trust': 0.05974025974025974, 'negative': 0.007142857142857143, 'valid_tweet_count': 20.0, 'anger': 0.0, 'disgust': 0.0, 'sadness': 0.0, 'fear': 0.0}\n",
      ".csvulating... karomuchova7\n",
      "0\n",
      "{'anger': 0.0020152505446623093, 'joy': 0.026522361081184605, 'disgust': 0.003439751969163734, 'sadness': 0.002701121600903736, 'surprise': 0.020472719002130765, 'anticipation': 0.03330502785159647, 'positive': 0.034779038237643896, 'fear': 0.0020152505446623093, 'trust': 0.024631928982419175, 'negative': 0.007979158741685975, 'valid_tweet_count': 108.0}\n",
      "Calculating... NEF_LISC_.csv\n",
      "0\n",
      "{'anger': 0.007324378975274958, 'disgust': 0.004772423131068471, 'sadness': 0.009048802473034257, 'anticipation': 0.027597544668208452, 'fear': 0.009636103716604333, 'negative': 0.014346514500914986, 'joy': 0.024943276903876044, 'surprise': 0.01082467767130523, 'positive': 0.08027316878222202, 'trust': 0.04202759293267674, 'valid_tweet_count': 341.0}\n",
      "Calculating... CharlieLance_.csv\n",
      "0\n",
      "{'anger': 0.01974793797653469, 'joy': 0.016956888755134056, 'disgust': 0.011959773880704246, 'sadness': 0.015534624866307186, 'surprise': 0.008273638887137925, 'anticipation': 0.02045455474260069, 'positive': 0.04326789273069203, 'fear': 0.025191128772952102, 'trust': 0.027070167381704684, 'negative': 0.03853415311231659, 'valid_tweet_count': 885.0}\n",
      "Calculating... Orange_Papers.csv\n",
      "0\n",
      "{'anger': 0.02535198401938367, 'joy': 0.03688130414125087, 'disgust': 0.020358573996137563, 'sadness': 0.02313069356363913, 'surprise': 0.0330193957568724, 'anticipation': 0.03544374146572429, 'positive': 0.07387358845154877, 'fear': 0.03208207910477639, 'trust': 0.05335249292897222, 'negative': 0.05353385635601195, 'valid_tweet_count': 934.0}\n",
      "Calculating... Paulinaqueensny.csv\n",
      "0\n",
      "{'anger': 0.0038623284639220895, 'joy': 0.03952490730194156, 'disgust': 0.00478853815507202, 'sadness': 0.00610789166566059, 'surprise': 0.015520120067719146, 'anticipation': 0.03864763995818724, 'fear': 0.004816009751530824, 'negative': 0.012332847542010889, 'positive': 0.06148601496837035, 'trust': 0.029331426590532575, 'valid_tweet_count': 251.0}\n",
      "Calculating... BigBoyCasey.csv\n",
      "0\n",
      "1000\n",
      "{'anger': 0.016499332537917914, 'joy': 0.048680647526805704, 'disgust': 0.01339898495390851, 'sadness': 0.016117471303380523, 'surprise': 0.02339943714505275, 'anticipation': 0.04974324041404348, 'fear': 0.013768390060582043, 'trust': 0.036272725148432335, 'negative': 0.03667451227649982, 'positive': 0.0685280570497463, 'valid_tweet_count': 1333.0}\n",
      "Calculating... GaryGwolson5227.csv\n",
      "0\n",
      "{'anger': 0.013975125710622071, 'joy': 0.061229648898343675, 'disgust': 0.015154671970813494, 'sadness': 0.013962636467363598, 'surprise': 0.01109184728043289, 'anticipation': 0.043649799260801724, 'positive': 0.0782020697842244, 'fear': 0.015389930160106436, 'trust': 0.01649037320756886, 'negative': 0.02978329646037379, 'valid_tweet_count': 65.0}\n",
      "Calculating... latanyalucas101.csv\n",
      "0\n",
      "{'anger': 0.02591680101712863, 'disgust': 0.021900547716910267, 'sadness': 0.021466056491742096, 'surprise': 0.028328193066067448, 'negative': 0.045997453971556544, 'joy': 0.067970761092133, 'anticipation': 0.03547974857100506, 'positive': 0.09401827092213315, 'fear': 0.019393037766731507, 'trust': 0.05762459892934595, 'valid_tweet_count': 252.0}\n",
      "Calculating... calzgraphics_.csv\n",
      "0\n",
      "{'disgust': 0.00878932083539504, 'negative': 0.022511271704653495, 'sadness': 0.008829021569364576, 'anger': 0.004053163261585101, 'joy': 0.026042384745615113, 'surprise': 0.008094418120857422, 'anticipation': 0.014375858029506746, 'positive': 0.03644165703631945, 'fear': 0.013097342984725409, 'trust': 0.02975103789623458, 'valid_tweet_count': 387.0}\n",
      "Calculating... TBrave.csv\n",
      "0\n",
      "1000\n",
      "{'anger': 0.005444355783665532, 'joy': 0.028194428697369947, 'disgust': 0.0043026190689107145, 'sadness': 0.0061869433151297325, 'surprise': 0.011346885333384368, 'anticipation': 0.029070539166195588, 'fear': 0.007616024934977321, 'trust': 0.0322560318133686, 'negative': 0.010238077378146688, 'positive': 0.055964826905398724, 'valid_tweet_count': 1120.0}\n",
      "Calculating... jtkstc_.csv\n",
      "0\n",
      "{'anger': 0.009375, 'joy': 0.023839285714285716, 'disgust': 0.01294642857142857, 'sadness': 0.03021683673469388, 'surprise': 0.05982130533372769, 'anticipation': 0.014591836734693877, 'positive': 0.05301704377403136, 'fear': 0.029196428571428575, 'trust': 0.03642986542443064, 'negative': 0.05331207482993198, 'valid_tweet_count': 20.0}\n",
      "Calculating... SeattleSPU.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "{'anger': 0.007306052059633481, 'joy': 0.02773740845545786, 'sadness': 0.00782019864461427, 'surprise': 0.009734366895860533, 'anticipation': 0.026417796880015297, 'fear': 0.009353157042578806, 'trust': 0.03533594859952543, 'positive': 0.07200539833722248, 'disgust': 0.020693690853810343, 'negative': 0.032592433964371705, 'valid_tweet_count': 4759.0}\n",
      "Calculating... TrulyDougTaylor.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "{'anger': 0.01438352853268989, 'disgust': 0.009253207730092528, 'sadness': 0.014958345654449317, 'fear': 0.01668105126989815, 'negative': 0.029076020683894945, 'joy': 0.024729985279736143, 'surprise': 0.015441704513561826, 'anticipation': 0.030063229289921455, 'positive': 0.054484574766165396, 'trust': 0.03606051089356871, 'valid_tweet_count': 14445.0}\n",
      "Calculating... Okameister.csv\n",
      "0\n",
      "{'anger': 0.0109107997265892, 'joy': 0.01978201622938465, 'disgust': 0.0035714285714285713, 'surprise': 0.014904306220095693, 'anticipation': 0.032144863146007306, 'positive': 0.05485066611496817, 'fear': 0.009774436090225564, 'trust': 0.04393805025383972, 'negative': 0.006904761904761905, 'valid_tweet_count': 20.0, 'sadness': 0.0}\n",
      "Calculating... MrsKaminski1_.csv\n",
      "0\n",
      "{'disgust': 0.0052282866008356195, 'anger': 0.007707885880732772, 'sadness': 0.0029739724239065475, 'positive': 0.09112595176201266, 'trust': 0.03194146123171381, 'joy': 0.05310712499752524, 'surprise': 0.012101460585536798, 'anticipation': 0.05460742022597541, 'fear': 0.010246160944744703, 'negative': 0.018390158714879194, 'valid_tweet_count': 132.0}\n",
      "Calculating... therealsamuelc.csv\n",
      "0\n",
      "{'anger': 0.02381256121105249, 'joy': 0.018008840980690957, 'disgust': 0.022434849476639106, 'sadness': 0.01538815079395899, 'surprise': 0.010096207911033687, 'anticipation': 0.018774544122805516, 'positive': 0.06085455907374854, 'fear': 0.016979284808638886, 'trust': 0.043584431981136845, 'negative': 0.04978406434761305, 'valid_tweet_count': 827.0}\n",
      "Calculating... murrdashewrote.csv\n",
      "0\n",
      "{'joy': 0.03620825435126191, 'surprise': 0.01286892747415021, 'anticipation': 0.03887556695739689, 'positive': 0.05545874800594496, 'trust': 0.03297249952176091, 'anger': 0.011485359902835269, 'disgust': 0.010480170083165985, 'sadness': 0.015331751673965437, 'fear': 0.013595875891626094, 'negative': 0.02939549169231687, 'valid_tweet_count': 396.0}\n",
      "Calculating... wiredhigh.csv\n",
      "0\n",
      "{'anger': 0.026447751051121175, 'joy': 0.026081634488528252, 'disgust': 0.02115466924788959, 'sadness': 0.026776588879959005, 'surprise': 0.007129840498484565, 'anticipation': 0.03330719365979102, 'fear': 0.02240994645655663, 'trust': 0.038295575394485214, 'negative': 0.04145072631948448, 'positive': 0.056189614323482295, 'valid_tweet_count': 118.0}\n",
      "Calculating... 206moose.csv\n",
      "0\n",
      "{'anger': 0.014490816089281563, 'joy': 0.016620329482648327, 'disgust': 0.004221563460693895, 'surprise': 0.015379531230980506, 'anticipation': 0.025610533364618108, 'positive': 0.037748571337835594, 'fear': 0.0058224077280565655, 'trust': 0.029668698339192053, 'negative': 0.032612872114150884, 'sadness': 0.010098419033841028, 'valid_tweet_count': 138.0}\n",
      "Calculating... Moogilu.csv\n",
      "0\n",
      "1000\n",
      "{'anger': 0.0008032245532245535, 'disgust': 0.00033738191632928474, 'sadness': 0.00021561771561771564, 'surprise': 0.003310061398296686, 'fear': 0.0020290725786081807, 'negative': 0.003812136006408446, 'anticipation': 0.08423919704879504, 'positive': 0.10278367172330126, 'trust': 0.08132575055949731, 'joy': 0.0903284174259413, 'valid_tweet_count': 1560.0}\n",
      "Calculating... smkee22.csv\n",
      "0\n",
      "{'anger': 0.012655918239571906, 'disgust': 0.007380628177439947, 'sadness': 0.010397642400065512, 'fear': 0.016758380127520227, 'negative': 0.023627651903151106, 'joy': 0.03671052683910129, 'surprise': 0.0235672886160472, 'anticipation': 0.031956254107350555, 'positive': 0.06872954110811534, 'trust': 0.04741715566968295, 'valid_tweet_count': 734.0}\n",
      "Calculating... SmileAgainDDS.csv\n",
      "0\n",
      "{'anger': 0.00945122820675909, 'joy': 0.046816889648258, 'disgust': 0.007422529628079073, 'sadness': 0.011160095764957382, 'surprise': 0.026640381768007947, 'positive': 0.07043083728173727, 'fear': 0.013046620432665686, 'trust': 0.04624821913221926, 'negative': 0.01801384328346486, 'anticipation': 0.03815291963011727, 'valid_tweet_count': 559.0}\n",
      "Calculating... kenyankee_.csv\n",
      "0\n",
      "{'anger': 0.020586170827161937, 'joy': 0.02284327240149659, 'disgust': 0.01619973430494137, 'sadness': 0.017572344236358377, 'surprise': 0.014308871606353113, 'anticipation': 0.023899387440638447, 'positive': 0.05387390625988675, 'fear': 0.016325119888616263, 'trust': 0.03739813873129774, 'negative': 0.03950936091119282, 'valid_tweet_count': 766.0}\n",
      "Calculating... enlightphoto.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "{'anger': 0.014236954978957791, 'joy': 0.028988379520926994, 'disgust': 0.007517877964731224, 'sadness': 0.015549671494361891, 'surprise': 0.016980989161059508, 'anticipation': 0.0311827118819121, 'fear': 0.016234790567424984, 'negative': 0.027674921254497272, 'trust': 0.03086924413894463, 'positive': 0.056923607320348554, 'valid_tweet_count': 13180.0}\n",
      "Calculating... garjones.csv\n",
      "0\n",
      "1000\n",
      "{'anger': 0.012173351972670176, 'joy': 0.027707393740832715, 'disgust': 0.00910410689619249, 'sadness': 0.014120714249822615, 'surprise': 0.013199782879624965, 'anticipation': 0.030461175969693843, 'fear': 0.013642204182273802, 'trust': 0.0302614742261123, 'negative': 0.03095409414531557, 'positive': 0.05532732753201831, 'valid_tweet_count': 1059.0}\n",
      "Calculating... LeslieDTrew.csv\n",
      "0\n",
      "{'anger': 0.007714223126374828, 'joy': 0.03664056026155874, 'disgust': 0.003244020289474835, 'sadness': 0.008873747083649308, 'surprise': 0.013271787135423499, 'anticipation': 0.03138603938567075, 'positive': 0.05721546233812353, 'fear': 0.010034590257289384, 'trust': 0.024563348861477208, 'negative': 0.014131332171544666, 'valid_tweet_count': 132.0}\n",
      "Calculating... jodawi.csv\n",
      "0\n",
      "{'anger': 0.02484895034267889, 'joy': 0.020119131388841967, 'disgust': 0.010254182313857618, 'sadness': 0.021044967690440567, 'surprise': 0.01666380128955337, 'anticipation': 0.023572564559250667, 'positive': 0.04667778116678354, 'fear': 0.020736884915157155, 'trust': 0.040864565418083476, 'negative': 0.033427494886360265, 'valid_tweet_count': 139.0}\n",
      "Calculating... abubokor1993.csv\n",
      "0\n",
      "{'valid_tweet_count': 6.0, 'anger': 0.0, 'joy': 0.0, 'disgust': 0.0, 'sadness': 0.0, 'surprise': 0.0, 'anticipation': 0.0, 'positive': 0.0, 'fear': 0.0, 'trust': 0.0, 'negative': 0.0}\n",
      ".csvulating... friedberg\n",
      "0\n",
      "{'anger': 0.00811214204322032, 'disgust': 0.008553373556186935, 'sadness': 0.017390852843300997, 'surprise': 0.007151112656143805, 'fear': 0.025513222617186773, 'negative': 0.04104004237253802, 'anticipation': 0.020768831129582305, 'positive': 0.04890079278884929, 'trust': 0.027721934337879953, 'joy': 0.012697953165405588, 'valid_tweet_count': 343.0}\n",
      "Calculating... rmh056.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "{'anger': 0.019558940966899682, 'joy': 0.03141132784670583, 'disgust': 0.013828506044564585, 'sadness': 0.018501438276068472, 'surprise': 0.011689899645380444, 'anticipation': 0.032780597653439186, 'positive': 0.06111530872847842, 'fear': 0.02651761190371525, 'trust': 0.044114364396012136, 'negative': 0.0370302631142064, 'valid_tweet_count': 2451.0}\n",
      "Calculating... danastephanie.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "{'anger': 0.01229154011043523, 'joy': 0.04999371056357453, 'disgust': 0.009314637193897015, 'sadness': 0.014673085904532547, 'surprise': 0.018206139850393675, 'anticipation': 0.03736214490379838, 'positive': 0.07172550320981748, 'fear': 0.014622477860107735, 'trust': 0.03840467332691783, 'negative': 0.028086104182104322, 'valid_tweet_count': 6410.0}\n",
      "Calculating... AnnieNero.csv\n",
      "0\n",
      "{'anger': 0.008813924741344095, 'joy': 0.05246676576931238, 'disgust': 0.0066411354521110615, 'sadness': 0.006921949452437258, 'surprise': 0.02171085847556436, 'anticipation': 0.05026709928275391, 'positive': 0.08986704729129058, 'fear': 0.013933963933963935, 'trust': 0.06585331486896952, 'negative': 0.020486280298204675, 'valid_tweet_count': 148.0}\n",
      ".csvulating... tashems\n",
      "0\n",
      "{'anger': 0.0011441647597254005, 'joy': 0.01879231998747993, 'sadness': 0.00946699609767961, 'surprise': 0.007827934676009493, 'anticipation': 0.02238999537883514, 'fear': 0.0091946507949033, 'trust': 0.01579884686301632, 'negative': 0.0061215578328303434, 'positive': 0.04082586959283761, 'valid_tweet_count': 92.0, 'disgust': 0.0}\n",
      "Calculating... tracyqou.csv\n",
      "0\n",
      "{'anger': 0.024539118880085583, 'joy': 0.039817637290898496, 'disgust': 0.023392870337371075, 'sadness': 0.024116215767935725, 'surprise': 0.016491310339623404, 'anticipation': 0.032691454338939524, 'fear': 0.023939594826093938, 'trust': 0.03684339213484868, 'negative': 0.04230283864315911, 'positive': 0.07099363615982696, 'valid_tweet_count': 811.0}\n",
      "Calculating... stanandtayna.csv\n",
      "0\n",
      "{'joy': 0.26, 'surprise': 0.01, 'anticipation': 0.01, 'positive': 0.26, 'trust': 0.01, 'valid_tweet_count': 4.0, 'anger': 0.0, 'disgust': 0.0, 'sadness': 0.0, 'fear': 0.0, 'negative': 0.0}\n",
      "Calculating... pgrl29.csv\n",
      "0\n",
      "{'positive': 0.004166666666666667, 'valid_tweet_count': 20.0, 'anger': 0.0, 'joy': 0.0, 'disgust': 0.0, 'sadness': 0.0, 'surprise': 0.0, 'anticipation': 0.0, 'fear': 0.0, 'trust': 0.0, 'negative': 0.0}\n",
      "Calculating... IamChandgo.csv\n",
      "0\n",
      "{'fear': 0.01416170634920635, 'sadness': 0.007696428571428571, 'anger': 0.007633928571428572, 'negative': 0.014235576923076924, 'joy': 0.06908197577276524, 'surprise': 0.030133928571428575, 'anticipation': 0.08243209787288736, 'positive': 0.13397880116959066, 'trust': 0.07591530910609859, 'valid_tweet_count': 40.0, 'disgust': 0.0}\n",
      "Calculating... ePositiveVibe.csv\n",
      "0\n",
      "{'surprise': 0.014163752913752917, 'anger': 0.0017919580419580423, 'fear': 0.0005769230769230769, 'anticipation': 0.017453071767975618, 'positive': 0.03992136306883379, 'joy': 0.016226082944832947, 'trust': 0.020830050778838403, 'disgust': 0.0005208333333333333, 'negative': 0.00423794955044955, 'sadness': 0.002793560606060606, 'valid_tweet_count': 208.0}\n",
      "Calculating... BellevueDT.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "{'anger': 0.0048444755267897585, 'joy': 0.04128129481379464, 'disgust': 0.0019287870646729442, 'sadness': 0.009114279459944558, 'surprise': 0.01935276990057627, 'anticipation': 0.04387693270242915, 'positive': 0.07883893190280895, 'fear': 0.006034050162805418, 'trust': 0.04015516217537792, 'negative': 0.01216870787372153, 'valid_tweet_count': 4702.0}\n",
      "Calculating... DManFWTX_.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "{'anger': 0.01755802229688686, 'joy': 0.02324303532274048, 'disgust': 0.010444442838982585, 'sadness': 0.013568162596719014, 'surprise': 0.014506906666839068, 'anticipation': 0.02794604933676245, 'positive': 0.045741154194701705, 'fear': 0.017533502261959686, 'trust': 0.032040204790822056, 'negative': 0.03301347904990984, 'valid_tweet_count': 2200.0}\n",
      "Calculating... HempNews.csv\n",
      "0\n",
      "{'anger': 0.007423744019138756, 'joy': 0.0069718567251461985, 'disgust': 0.015583466241360977, 'sadness': 0.008639021796916533, 'surprise': 0.008639021796916533, 'anticipation': 0.012975146198830409, 'positive': 0.050561299081035925, 'fear': 0.020703273334852283, 'trust': 0.03602389021796916, 'negative': 0.03166142154628997, 'valid_tweet_count': 20.0}\n",
      "Calculating... gina702.csv\n",
      "0\n",
      "{'anger': 0.010517392528142986, 'joy': 0.050971508033391816, 'disgust': 0.011003477816700413, 'sadness': 0.01349887491037443, 'surprise': 0.0213410245079145, 'anticipation': 0.04749469987433705, 'positive': 0.08321242563916802, 'fear': 0.015321798263843122, 'trust': 0.04543799667631749, 'negative': 0.02577723897997772, 'valid_tweet_count': 801.0}\n",
      "Calculating... Sheilabjeletich.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "{'joy': 0.05124206020571738, 'disgust': 0.029424868393657932, 'sadness': 0.022539840755540698, 'surprise': 0.03152794497432456, 'anticipation': 0.04087160143459633, 'positive': 0.07685878933050784, 'trust': 0.04666918316473049, 'anger': 0.025814330669520196, 'fear': 0.032911754372406773, 'negative': 0.06328996109155714, 'valid_tweet_count': 2769.0}\n",
      "Calculating... haabanews.csv\n",
      "0\n",
      "1000\n",
      "{'anger': 0.034965315534036055, 'joy': 0.026510535278307854, 'disgust': 0.012904718591922371, 'sadness': 0.0317826956847495, 'surprise': 0.016770408516064112, 'anticipation': 0.0376234437845814, 'positive': 0.07336152087336921, 'fear': 0.04898456087239671, 'trust': 0.050530062062447624, 'negative': 0.07133899392983134, 'valid_tweet_count': 1899.0}\n",
      "Calculating... bhogleharsha.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cary/.local/share/virtualenvs/TextAnalytics-9hFs7Vd6/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (21) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "{'anger': 0.009871051850627493, 'disgust': 0.005929043067988764, 'surprise': 0.018834552540071353, 'fear': 0.012173068948348307, 'negative': 0.022760491177155787, 'anticipation': 0.03347983411458735, 'positive': 0.06049640577407822, 'trust': 0.038075284909087806, 'joy': 0.029221569577656877, 'sadness': 0.011916172919446027, 'valid_tweet_count': 40986.0}\n",
      "Calculating... carioke.csv\n",
      "0\n",
      "{'anger': 0.021866826173858326, 'disgust': 0.021208849252392113, 'sadness': 0.01984943943198693, 'surprise': 0.020384638615235897, 'fear': 0.022476967603852257, 'negative': 0.04503931283825027, 'positive': 0.07499027041263652, 'anticipation': 0.023205619505605297, 'trust': 0.040126819141147935, 'joy': 0.03213930990906951, 'valid_tweet_count': 474.0}\n",
      ".csvulating... williamready\n",
      "0\n",
      "{'anger': 0.008648043979225764, 'joy': 0.032158674636792936, 'disgust': 0.0032671474925733295, 'sadness': 0.005358956810588358, 'surprise': 0.013729800020834161, 'anticipation': 0.0470676282694289, 'positive': 0.07288176366995108, 'fear': 0.009207845408057018, 'trust': 0.04581464093525456, 'negative': 0.017417911951522574, 'valid_tweet_count': 937.0}\n",
      "Calculating... TahoeRCD.csv\n",
      "0\n",
      "{'anger': 0.004486098380449651, 'joy': 0.027582287933118305, 'disgust': 0.0033286316020931586, 'sadness': 0.009260105640081078, 'surprise': 0.00807377787668384, 'anticipation': 0.033898873242806334, 'positive': 0.0771739120708445, 'fear': 0.012299765045256272, 'trust': 0.03741510956956735, 'negative': 0.015046653439367714, 'valid_tweet_count': 822.0}\n",
      "Calculating... CArecycler.csv\n",
      "0\n",
      "{'joy': 0.006083846413130298, 'disgust': 0.0014342888823498242, 'surprise': 0.0023816196728096042, 'anticipation': 0.005254564030492279, 'positive': 0.01571389360534209, 'trust': 0.011239805953488802, 'anger': 0.002697548966405103, 'negative': 0.008735824545544713, 'fear': 0.002340437754030732, 'sadness': 0.0022203458576230462, 'valid_tweet_count': 456.0}\n",
      "Calculating... AleBritoFlores.csv\n",
      "0\n",
      "{'anger': 0.01233106516125384, 'joy': 0.04420312998267318, 'disgust': 0.003606787122179376, 'sadness': 0.010896134362305944, 'surprise': 0.02053482763512555, 'anticipation': 0.050632938438732664, 'positive': 0.07065989261663023, 'fear': 0.02851198674436013, 'trust': 0.04374866966767143, 'negative': 0.029268747074541294, 'valid_tweet_count': 53.0}\n",
      "Calculating... hergus_.csv\n",
      "0\n",
      "1000\n",
      "{'anger': 0.018492317542864574, 'joy': 0.025836492127696665, 'disgust': 0.015296635005629068, 'sadness': 0.015613941447733481, 'surprise': 0.016277965985005555, 'positive': 0.06638865414383513, 'fear': 0.02160005876508396, 'trust': 0.03808609064153579, 'negative': 0.03550342731261619, 'anticipation': 0.03980566680816572, 'valid_tweet_count': 1468.0}\n",
      "Calculating... mizzslim5.csv\n",
      "0\n",
      "{'anger': 0.04198721913007627, 'joy': 0.05739260739260738, 'disgust': 0.014401154401154402, 'sadness': 0.0313969363969364, 'surprise': 0.015295815295815297, 'positive': 0.12167832167832167, 'fear': 0.019592867450010307, 'trust': 0.10144022644022643, 'negative': 0.060552265195122336, 'anticipation': 0.03457514707514708, 'valid_tweet_count': 35.0}\n",
      "Calculating... UdiSch.csv\n",
      "0\n",
      "{'anger': 0.007142857142857143, 'disgust': 0.019642857142857142, 'sadness': 0.019642857142857142, 'fear': 0.013392857142857142, 'negative': 0.022584033613445378, 'surprise': 0.06178571428571428, 'anticipation': 0.06456349206349206, 'positive': 0.08208800186741362, 'trust': 0.05831349206349205, 'joy': 0.06456349206349206, 'valid_tweet_count': 20.0}\n",
      "Calculating... renegoscinny.csv\n",
      "0\n",
      "{'anger': 0.004997453526865292, 'joy': 0.045952557630758326, 'disgust': 0.012350394703335882, 'sadness': 0.00919135330900037, 'surprise': 0.029143079143079148, 'anticipation': 0.04039364774658893, 'fear': 0.011455592337945278, 'negative': 0.017143423025775966, 'positive': 0.08168728298486083, 'trust': 0.04063197951606256, 'valid_tweet_count': 102.0}\n",
      "Calculating... Christa_Belle.csv\n",
      "0\n",
      "{'anger': 0.0029411764705882353, 'disgust': 0.0014705882352941176, 'sadness': 0.006512605042016806, 'surprise': 0.00546444384205295, 'fear': 0.008496732026143792, 'positive': 0.07475421506452716, 'negative': 0.022782446311858072, 'anticipation': 0.03472129809890721, 'trust': 0.0474965157128345, 'joy': 0.03004958092719004, 'valid_tweet_count': 20.0}\n",
      "Calculating... Gimmie18USC2381.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "{'anger': 0.02503605765226366, 'joy': 0.034459646729621526, 'disgust': 0.021407400306389403, 'sadness': 0.023349776678928274, 'surprise': 0.01692789371846776, 'anticipation': 0.03699048761901572, 'positive': 0.057052967100551424, 'fear': 0.022384671580726875, 'trust': 0.03611390279713969, 'negative': 0.05035546346320821, 'valid_tweet_count': 3180.0}\n",
      "Calculating... JuanPierreBowly.csv\n",
      "0\n",
      "{'anger': 0.022747743090735396, 'disgust': 0.021432969750533316, 'sadness': 0.020873454127880674, 'surprise': 0.013499632800342441, 'anticipation': 0.020226374748846653, 'fear': 0.019590302198661327, 'negative': 0.04322763404813706, 'joy': 0.028917012906854573, 'positive': 0.04504255924562237, 'trust': 0.0226425495767514, 'valid_tweet_count': 445.0}\n",
      "Calculating... lilgde90_.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "{'joy': 0.031025153134272412, 'disgust': 0.022470843416321322, 'sadness': 0.016209633725854333, 'surprise': 0.012543305181355515, 'anticipation': 0.027308930647627662, 'positive': 0.053587220934826166, 'trust': 0.03422605399318611, 'anger': 0.02587082265889831, 'fear': 0.018161855491987344, 'negative': 0.040503837854041734, 'valid_tweet_count': 3547.0}\n",
      "Calculating... SpilledInkRepU.csv\n",
      "0\n",
      "{'anger': 0.022596153846153846, 'disgust': 0.027141608391608396, 'sadness': 0.016346153846153847, 'surprise': 0.03446303696303697, 'fear': 0.016346153846153847, 'trust': 0.06693056943056942, 'negative': 0.03785589410589411, 'anticipation': 0.13436313686313686, 'positive': 0.10690621878121878, 'joy': 0.07585914085914085, 'valid_tweet_count': 20.0}\n",
      "Calculating... sundarpichai.csv\n",
      "0\n",
      "{'anger': 0.008354887787456352, 'joy': 0.0399576880602451, 'disgust': 0.0038268644715829057, 'sadness': 0.007602943850848612, 'surprise': 0.018289240213637932, 'anticipation': 0.043348455546144006, 'positive': 0.07667855356957286, 'fear': 0.00987309495323959, 'trust': 0.04349390972378458, 'negative': 0.01517857500326869, 'valid_tweet_count': 802.0}\n",
      "Calculating... mongabay.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "{'disgust': 0.012370073998656238, 'anger': 0.02013722828522084, 'anticipation': 0.027112316465398228, 'fear': 0.03109156107801782, 'negative': 0.044161868475954956, 'sadness': 0.01717843723417802, 'surprise': 0.012151463317420863, 'joy': 0.017253568356425525, 'positive': 0.06030564129462096, 'trust': 0.0370860904766127, 'valid_tweet_count': 8740.0}\n",
      "Calculating... AmandaK0812.csv\n",
      "0\n",
      "{'anger': 0.008524200379717774, 'disgust': 0.00831853960102841, 'sadness': 0.014911047791232644, 'surprise': 0.018219071855924716, 'fear': 0.01682578266262561, 'trust': 0.03502865459045931, 'negative': 0.02684033466635467, 'anticipation': 0.044529911986807044, 'positive': 0.06927389909484911, 'joy': 0.04432724962983028, 'valid_tweet_count': 240.0}\n",
      "Calculating... rajeshsawhney.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "{'surprise': 0.017054932582410056, 'anticipation': 0.03792575956934091, 'trust': 0.04496252525247, 'joy': 0.03861304148500183, 'anger': 0.010000455269094075, 'disgust': 0.005912740099282149, 'sadness': 0.010337614018866004, 'fear': 0.01282132110051651, 'negative': 0.02167533561448557, 'positive': 0.07665395229196528, 'valid_tweet_count': 12538.0}\n",
      "Calculating... jpaul237_.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "{'anger': 0.01504332517083698, 'joy': 0.008787803127368857, 'disgust': 0.009983189788858152, 'sadness': 0.011670610291553928, 'surprise': 0.00490276786246906, 'anticipation': 0.013192842436408713, 'fear': 0.015126150416172658, 'negative': 0.027706463752916678, 'trust': 0.018309197262733078, 'positive': 0.024311173995627797, 'valid_tweet_count': 3173.0}\n",
      "Calculating... OCSportsXchange.csv\n",
      "0\n",
      "{'anger': 0.007567130936696155, 'joy': 0.027077574861015686, 'disgust': 0.0007215007215007215, 'surprise': 0.007055811015141158, 'anticipation': 0.031066293687195812, 'positive': 0.048702600963351224, 'fear': 0.006845630215195432, 'trust': 0.020929115168245603, 'negative': 0.004455813546722637, 'valid_tweet_count': 66.0, 'sadness': 0.0}\n",
      "Calculating... BPositive104.csv\n",
      "0\n",
      "{'anger': 0.011005149534561299, 'joy': 0.031071428571428576, 'disgust': 0.004545454545454545, 'sadness': 0.01087743561374393, 'surprise': 0.01380952380952381, 'positive': 0.05861948746869901, 'fear': 0.006269592476489028, 'trust': 0.04068297953219107, 'negative': 0.01990326816898825, 'anticipation': 0.026216931216931215, 'valid_tweet_count': 20.0}\n",
      "Calculating... dwalden0726.csv\n",
      "0\n",
      "1000\n",
      "{'anger': 0.030112069847974845, 'joy': 0.020157488806619092, 'disgust': 0.029704924798135992, 'sadness': 0.026029129430886137, 'surprise': 0.0217029747880705, 'anticipation': 0.02227057379843565, 'fear': 0.025392199962583007, 'trust': 0.034261829546508256, 'negative': 0.06727854222193809, 'positive': 0.05284993840939217, 'valid_tweet_count': 1080.0}\n",
      ".csvulating... DohertyShannen\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "{'anger': 0.013472942420021528, 'joy': 0.05580917090496764, 'disgust': 0.00996280492197876, 'sadness': 0.011439945149458003, 'surprise': 0.019301996814824467, 'anticipation': 0.04094679441904655, 'positive': 0.08314830238713017, 'fear': 0.01576625416422355, 'trust': 0.04710842677491828, 'negative': 0.02516139171186867, 'valid_tweet_count': 8334.0}\n",
      "Calculating... urbanchillage_.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "{'anger': 0.027345640118364344, 'disgust': 0.020724647625459044, 'sadness': 0.019685085974199434, 'surprise': 0.015864205223825943, 'fear': 0.023989462991663914, 'negative': 0.04396705674704388, 'anticipation': 0.030059701545313247, 'positive': 0.057738545315085495, 'trust': 0.03364442031897608, 'joy': 0.027670649211303213, 'valid_tweet_count': 2198.0}\n",
      "Calculating... mayank7jan.csv\n",
      "0\n",
      "{'anger': 0.014843425165937082, 'joy': 0.037540631932665804, 'disgust': 0.0027312778857567204, 'sadness': 0.012694809347700838, 'surprise': 0.01681735012395125, 'anticipation': 0.03423760471036196, 'positive': 0.07306317286587562, 'fear': 0.01616458471502122, 'trust': 0.04407028718969425, 'negative': 0.02791412015020891, 'valid_tweet_count': 107.0}\n",
      "Calculating... Candi_CA.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "{'anger': 0.013881993396619361, 'joy': 0.03887179822355878, 'disgust': 0.013277157731858084, 'sadness': 0.016678491700948036, 'surprise': 0.023305465810758805, 'anticipation': 0.04135418076067889, 'positive': 0.06606599036584233, 'fear': 0.01462434095900778, 'trust': 0.04005700100678679, 'negative': 0.03508005577667726, 'valid_tweet_count': 5518.0}\n",
      "Calculating... zack_kreish_.csv\n",
      "0\n",
      "{'anger': 0.002430395913154534, 'joy': 0.0569643124872389, 'disgust': 0.0031836228287841196, 'sadness': 0.006819986465147756, 'surprise': 0.013816510099751886, 'anticipation': 0.040378265597380746, 'positive': 0.09304381060350173, 'fear': 0.005392118401192811, 'trust': 0.049264476019328415, 'negative': 0.014006619689378315, 'valid_tweet_count': 50.0}\n",
      "Calculating... adamgeraldlight_.csv\n",
      "0\n",
      "{'anger': 0.011451455324535117, 'disgust': 0.014046648879618569, 'sadness': 0.007192492308535629, 'fear': 0.010033960736746098, 'negative': 0.02126645499087404, 'joy': 0.04189185720569046, 'surprise': 0.021674932631796155, 'anticipation': 0.029799948409913544, 'positive': 0.09167694929538321, 'trust': 0.05421692668574828, 'valid_tweet_count': 238.0}\n",
      "Calculating... kierstenmh.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "{'joy': 0.03790276945334486, 'disgust': 0.008738300732079747, 'sadness': 0.01859181470075321, 'surprise': 0.01651483900134455, 'anticipation': 0.03545999590118565, 'positive': 0.0635721767677177, 'trust': 0.0426180583456357, 'anger': 0.012433098086791411, 'fear': 0.016085621726666395, 'negative': 0.03090167027246875, 'valid_tweet_count': 5465.0}\n",
      "Calculating... tk63.csv\n",
      "0\n",
      "1000\n",
      "{'anger': 0.017316319177978195, 'joy': 0.03318071944332238, 'disgust': 0.019526602153957504, 'sadness': 0.019786089363217164, 'surprise': 0.012487424631513819, 'anticipation': 0.029491925924305686, 'positive': 0.06109056503340174, 'fear': 0.021803865965885648, 'trust': 0.033355329134944815, 'negative': 0.04606752299825326, 'valid_tweet_count': 1655.0}\n",
      ".csvulating... RyanSeacrest\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "{'anger': 0.008459350921843238, 'joy': 0.04111779032054718, 'disgust': 0.0059095161627455125, 'sadness': 0.010181028094669831, 'surprise': 0.016388477469193703, 'anticipation': 0.047609119635792806, 'positive': 0.06800521610958452, 'fear': 0.010662436252743396, 'trust': 0.045234577902828366, 'negative': 0.018865091863854218, 'valid_tweet_count': 3779.0}\n",
      "Calculating... williger.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "{'anticipation': 0.046512248781938534, 'trust': 0.02737525362048163, 'joy': 0.026217992537792844, 'anger': 0.008573813669108503, 'disgust': 0.006284110504879943, 'sadness': 0.007966005949221956, 'surprise': 0.022515132806873124, 'fear': 0.020230073392237907, 'negative': 0.017505688185380574, 'positive': 0.04570598991251037, 'valid_tweet_count': 12140.0}\n",
      "Calculating... mzshorter.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "{'anger': 0.010939583795131243, 'joy': 0.022546925903021434, 'disgust': 0.006757889887529046, 'sadness': 0.00872918015390567, 'surprise': 0.012176198021741247, 'anticipation': 0.025941021830219402, 'positive': 0.05031036270290521, 'fear': 0.012545598668604862, 'trust': 0.02835450943820299, 'negative': 0.021897276234240676, 'valid_tweet_count': 4144.0}\n",
      "Calculating... CatGray.csv\n",
      "0\n",
      "1000\n",
      "{'anger': 0.02830527441552468, 'joy': 0.030383413902302266, 'disgust': 0.017717908102980903, 'sadness': 0.02302898076564164, 'surprise': 0.01641265117297515, 'anticipation': 0.028838527818198924, 'positive': 0.06401028455289996, 'fear': 0.03249792934371883, 'trust': 0.036577412356445696, 'negative': 0.044932528795749556, 'valid_tweet_count': 1832.0}\n",
      "Calculating... AlexRamel.csv\n",
      "0\n",
      "{'anger': 0.01190099470016917, 'joy': 0.021473184500134454, 'disgust': 0.00598696147379388, 'sadness': 0.011063164709672385, 'surprise': 0.012855021728351743, 'anticipation': 0.027880146665491337, 'positive': 0.06545111633329206, 'fear': 0.01671073845230244, 'trust': 0.05063291281323508, 'negative': 0.029734866762048184, 'valid_tweet_count': 240.0}\n",
      "Calculating... GetFreeBooks.csv\n",
      "0\n",
      "{'anger': 0.0005720823798627002, 'sadness': 0.0005720823798627002, 'fear': 0.0019426964149504193, 'negative': 0.0005720823798627002, 'joy': 0.021621956028619816, 'surprise': 0.018503221692780215, 'anticipation': 0.024398642061884794, 'positive': 0.06636835347695964, 'trust': 0.062352754782568395, 'valid_tweet_count': 76.0, 'disgust': 0.0}\n",
      "Calculating... maracelyyy.csv\n",
      "0\n",
      "{'anger': 0.02135503467313154, 'joy': 0.022355257451886833, 'disgust': 0.014861900563530036, 'sadness': 0.02307427390548951, 'surprise': 0.01132574662323565, 'positive': 0.05280970557528577, 'anticipation': 0.025499013508398734, 'negative': 0.041601223298066994, 'trust': 0.025338239187598866, 'fear': 0.024109364257592365, 'valid_tweet_count': 160.0}\n",
      "Calculating... IG_bybrookelle.csv\n",
      "0\n",
      "{'anger': 0.013003250547786928, 'joy': 0.042617630753707086, 'disgust': 0.013390509225013609, 'sadness': 0.01677367250798882, 'surprise': 0.017977292606452668, 'anticipation': 0.030946108485985738, 'positive': 0.06736896132168246, 'fear': 0.014810857052293123, 'trust': 0.033578685344460374, 'negative': 0.03115615983387941, 'valid_tweet_count': 994.0}\n",
      "Calculating... egstorey_.csv\n",
      "0\n",
      "{'anger': 0.010287917019211786, 'disgust': 0.005518407377530891, 'sadness': 0.010510970222185985, 'surprise': 0.01662561146766692, 'fear': 0.01789832792874419, 'negative': 0.020321173368605953, 'positive': 0.0848794387003713, 'trust': 0.04512812678049495, 'anticipation': 0.03487838388144253, 'joy': 0.030954900337955105, 'valid_tweet_count': 357.0}\n",
      "Calculating... michaelwhere.csv\n",
      "0\n",
      "{'anger': 0.023809523809523808, 'sadness': 0.023809523809523808, 'positive': 0.015606962481962482, 'fear': 0.047619047619047616, 'trust': 0.011696428571428571, 'anticipation': 0.010497835497835497, 'valid_tweet_count': 20.0, 'joy': 0.0, 'disgust': 0.0, 'surprise': 0.0, 'negative': 0.0}\n",
      "Calculating... mps3mom.csv\n",
      "0\n",
      "{'anger': 0.033503057222214305, 'joy': 0.05497602097488404, 'disgust': 0.014775338236202527, 'sadness': 0.03630585227198808, 'surprise': 0.03480941934314119, 'anticipation': 0.056901376699179586, 'positive': 0.07609334085158229, 'fear': 0.021960661216244477, 'trust': 0.054211786957034144, 'negative': 0.04607773542082221, 'valid_tweet_count': 910.0}\n",
      "Calculating... DebbyBRealtor.csv\n",
      "0\n",
      "{'anger': 0.0028539382945045625, 'joy': 0.034237174976702804, 'disgust': 0.0014873974234481922, 'sadness': 0.00330889530011341, 'surprise': 0.0082938950158546, 'anticipation': 0.021317885769599892, 'fear': 0.0026509296035778828, 'trust': 0.0355537062813526, 'negative': 0.008930128404871044, 'positive': 0.07465012477330746, 'valid_tweet_count': 241.0}\n",
      "Calculating... rmscrypto.csv\n",
      "0\n",
      "{'anger': 0.002840909090909091, 'joy': 0.10135281385281386, 'sadness': 0.010227272727272727, 'surprise': 0.03465909090909091, 'anticipation': 0.05990259740259741, 'fear': 0.005113636363636364, 'trust': 0.040746753246753246, 'negative': 0.04016135379771743, 'positive': 0.10914502164502166, 'valid_tweet_count': 44.0, 'disgust': 0.0}\n",
      "Calculating... 7GeorgeCostanza.csv\n",
      "0\n",
      "{'anger': 0.021083039561300428, 'disgust': 0.009133862122992557, 'sadness': 0.019676389944932142, 'surprise': 0.05396306632719676, 'fear': 0.019588066327196764, 'negative': 0.04574098627807068, 'anticipation': 0.09184185420598463, 'positive': 0.09411950147440303, 'trust': 0.049688182397762334, 'joy': 0.08051032728791137, 'valid_tweet_count': 20.0}\n",
      "Calculating... dchiger22.csv\n",
      "0\n",
      "{'anger': 0.011668800296727195, 'joy': 0.036718407095631886, 'disgust': 0.013151348302690392, 'sadness': 0.013184345320267651, 'surprise': 0.015195060774654389, 'anticipation': 0.041278026427182785, 'positive': 0.07235455488685745, 'fear': 0.013436520329724212, 'trust': 0.0347040049950417, 'negative': 0.03163423938837989, 'valid_tweet_count': 103.0}\n",
      "Calculating... ChuyBerumen1_.csv\n",
      "0\n",
      "1000\n",
      "{'anger': 0.017003682144627195, 'disgust': 0.014971589344449686, 'sadness': 0.02010688695448588, 'surprise': 0.016430965315072123, 'anticipation': 0.03407798298650565, 'fear': 0.021771959868133687, 'trust': 0.04194090310777494, 'negative': 0.03934762539578585, 'positive': 0.05906179041945642, 'joy': 0.034547974554345995, 'valid_tweet_count': 1437.0}\n",
      "Calculating... ycatsnonnac.csv\n",
      "0\n",
      "{'anger': 0.015588738712382425, 'joy': 0.029102317344818107, 'disgust': 0.013530158156390311, 'sadness': 0.013918359034576161, 'surprise': 0.011573880626452619, 'anticipation': 0.03147738067545432, 'positive': 0.062426872358811385, 'fear': 0.014396723839540613, 'trust': 0.03701707814824225, 'negative': 0.034781152469710155, 'valid_tweet_count': 915.0}\n",
      "Calculating... WTW_WestCoast.csv\n",
      "0\n",
      "{'anger': 0.010135075334410885, 'joy': 0.023218039045183846, 'disgust': 0.008102316657133934, 'sadness': 0.004985333972044935, 'surprise': 0.013062380587297532, 'anticipation': 0.042563116752094635, 'positive': 0.05345279549737337, 'fear': 0.020340857652759146, 'negative': 0.013468148684095528, 'trust': 0.043392736317507175, 'valid_tweet_count': 301.0}\n",
      "Calculating... K80LP_.csv\n",
      "0\n",
      "1000\n",
      "{'anger': 0.012607185187994354, 'disgust': 0.009468181392115926, 'sadness': 0.011641127767103715, 'surprise': 0.015701972357845012, 'anticipation': 0.03313450532855247, 'fear': 0.012694040108959168, 'joy': 0.03125566387204482, 'positive': 0.06391064082594647, 'trust': 0.04124566563559288, 'negative': 0.027179440788331375, 'valid_tweet_count': 1409.0}\n",
      "Calculating... Oakpnyc.csv\n",
      "0\n",
      "{'anger': 0.009237540764106229, 'joy': 0.014652749211572742, 'disgust': 0.007422459893048128, 'sadness': 0.008835067947022405, 'surprise': 0.007130124777183599, 'anticipation': 0.008382069763143932, 'positive': 0.03018544097415477, 'fear': 0.013034414352251163, 'trust': 0.020024613168825693, 'negative': 0.012617217696914094, 'valid_tweet_count': 85.0}\n",
      "Calculating... paulwhitworth.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "{'anger': 0.011950997491041237, 'joy': 0.027776278545013158, 'disgust': 0.008971311061216776, 'sadness': 0.014351614814076478, 'surprise': 0.018029985757709435, 'anticipation': 0.03471277259347121, 'positive': 0.05310932565857376, 'fear': 0.015070425977292096, 'trust': 0.03459248296603868, 'negative': 0.025205076739575102, 'valid_tweet_count': 2963.0}\n",
      "Calculating... CaliforniaCal.csv\n",
      "0\n",
      "{'anger': 0.008388888888888888, 'joy': 0.012873977873977874, 'disgust': 0.02281481481481482, 'sadness': 0.019, 'surprise': 0.013850168350168349, 'anticipation': 0.011442760942760944, 'positive': 0.04919408369408371, 'fear': 0.031776094276094284, 'trust': 0.04743482443482444, 'negative': 0.06636868686868688, 'valid_tweet_count': 150.0}\n",
      "Calculating... WeThePawns.csv\n",
      "0\n",
      "{'anger': 0.027312155608609133, 'joy': 0.04755503949456149, 'disgust': 0.027355767111906282, 'sadness': 0.026387357768972778, 'surprise': 0.022982722176775564, 'fear': 0.03333431580886604, 'trust': 0.06472311530931034, 'negative': 0.06111040940190574, 'anticipation': 0.029266879798469075, 'positive': 0.0877105018420508, 'valid_tweet_count': 359.0}\n",
      "Calculating... IslamPaggio_.csv\n",
      "0\n",
      "{'trust': 0.025396825396825393, 'anticipation': 0.029711029711029697, 'positive': 0.07423687423687425, 'joy': 0.029711029711029697, 'valid_tweet_count': 63.0, 'anger': 0.0, 'disgust': 0.0, 'sadness': 0.0, 'surprise': 0.0, 'fear': 0.0, 'negative': 0.0}\n",
      "Calculating... Swamy39.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "{'anger': 0.01929597823100667, 'joy': 0.017518210893310963, 'disgust': 0.014395765166395083, 'sadness': 0.018712276026445793, 'surprise': 0.011802094110425087, 'anticipation': 0.027176060436270816, 'positive': 0.0516549834196962, 'fear': 0.025440706888125105, 'trust': 0.03944026422821295, 'negative': 0.051961471505857955, 'valid_tweet_count': 38800.0}\n",
      "Calculating... Starviewfarmvt.csv\n",
      "0\n",
      "{'anger': 0.010110581368066397, 'joy': 0.024936233094915734, 'disgust': 0.006881691163128288, 'sadness': 0.01359272796398545, 'surprise': 0.008890768247055671, 'anticipation': 0.02278386949045632, 'positive': 0.04618430471723884, 'fear': 0.019375750663175813, 'trust': 0.028121097133073175, 'negative': 0.0237051039446249, 'valid_tweet_count': 167.0}\n",
      "Calculating... ethan_marketing.csv\n",
      "0\n",
      "{'anger': 0.005683398211396596, 'joy': 0.030393080554573414, 'disgust': 0.0016856060606060604, 'surprise': 0.0157178781363564, 'anticipation': 0.03707105340922718, 'positive': 0.07658313380795613, 'fear': 0.0054629928814324425, 'trust': 0.042059147431975925, 'negative': 0.01828909172765324, 'sadness': 0.004078767279269433, 'valid_tweet_count': 200.0}\n",
      "Calculating... JerryTheTidd_.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "{'anger': 0.021845450527179747, 'joy': 0.021332267164193036, 'disgust': 0.010942894512339006, 'sadness': 0.019237806966773095, 'surprise': 0.021596587035149117, 'anticipation': 0.02635731869453058, 'fear': 0.029026054753733065, 'trust': 0.04163476044312815, 'negative': 0.04352782696147471, 'positive': 0.05875057865490372, 'valid_tweet_count': 9766.0}\n",
      "Calculating... fourbags57.csv\n",
      "0\n",
      "{'anger': 0.019343475454586572, 'joy': 0.02399957130805084, 'disgust': 0.013675752231307785, 'sadness': 0.022726327170771613, 'surprise': 0.024335973747996457, 'anticipation': 0.0259678618913225, 'positive': 0.06334714325879331, 'fear': 0.04606106606321604, 'trust': 0.039719294415573494, 'negative': 0.04047931464374532, 'valid_tweet_count': 270.0}\n",
      "Calculating... Chrisypoooh.csv\n",
      "0\n",
      "{'anger': 0.008234863717949509, 'disgust': 0.008114330637915543, 'sadness': 0.008537706663290099, 'fear': 0.013264740785374088, 'negative': 0.026698567649374522, 'joy': 0.02951775547019962, 'surprise': 0.009382772548699295, 'anticipation': 0.03301643157665388, 'positive': 0.05042181140236441, 'trust': 0.032604780728718794, 'valid_tweet_count': 106.0}\n"
     ]
    }
   ],
   "source": [
    "filecount = 0\n",
    "for soldierCSVFile in soldierCSVs:\n",
    "    if soldierCSVFile == 'cleaned_vet_tweet_df.csv': continue\n",
    "    if soldierCSVFile == 'combined_civilians.csv': continue\n",
    "\n",
    "    print('Calculating... ' + soldierCSVFile)\n",
    "    \n",
    "    tempDF = pd.read_csv(os.getcwd() + \"/data/civilians/\" + soldierCSVFile, encoding='utf8')\n",
    "    tempDF.dropna(subset=['tweet'], inplace=True) # clear empty tweets\n",
    "    tempDF.drop(uselessColumns, axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    singleResult = {}\n",
    "    count = 0.0\n",
    "    for id, row in tempDF.iterrows():\n",
    "        emo = calEmoForTweet(row['tweet'])\n",
    "        count += 1\n",
    "        if (id % 1000 ) == 0: print(id)\n",
    "#         if (soldierCSVFile == 'cNikonphoto.csv'): print(id)\n",
    "        singleResult = dict(Counter(emo) + Counter(singleResult))\n",
    "    \n",
    "    singleResult['valid_tweet_count'] = count\n",
    "    \n",
    "    for key in lexicon.keys():\n",
    "        if key in singleResult:\n",
    "            singleResult[key] = singleResult[key] / count\n",
    "        else:\n",
    "            singleResult[key] = 0.0\n",
    "    \n",
    "    \n",
    "    soldierEmoDict[filecount] = singleResult\n",
    "    filecount++\n",
    "#     print(singleResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame.from_dict(soldierEmoDict, orient=\"index\").to_csv(\"soldierEmo.csv\")\n",
    "pd.DataFrame.from_dict(soldierEmoDict, orient=\"index\").to_csv(\"civilianEmo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('TextAnalytics': pipenv)",
   "language": "python",
   "name": "python37764bittextanalyticspipenvec0a72c8bc7e410ea9ad476aba2b0271"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
