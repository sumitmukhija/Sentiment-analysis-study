{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_lex import EmoLex\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.tokenize.casual import TweetTokenizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from twitter_preprocessor import TwitterPreprocessor\n",
    "import os\n",
    "import glob\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon = EmoLex('./NRC-Emotion-Lexicon-Wordlevel-v0.92-headless.csv')\n",
    "lexicon.dump('./lexicon.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anger',\n",
       " 'anticipation',\n",
       " 'disgust',\n",
       " 'fear',\n",
       " 'joy',\n",
       " 'negative',\n",
       " 'positive',\n",
       " 'sadness',\n",
       " 'surprise',\n",
       " 'trust'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon = EmoLex()\n",
    "lexicon.load('./lexicon.pickle')\n",
    "\n",
    "lexicon.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where stores the total data\n",
    "soldierEmoDict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file list\n",
    "soldierCSVs = []\n",
    "files = os.listdir(os.getcwd() + \"/data/soldiers\")\n",
    "for file in files:\n",
    "     if not os.path.isdir(file) and file.endswith(\".csv\"):\n",
    "            soldierCSVs.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useless columns for analyzing\n",
    "uselessColumns = [\n",
    "    \"id\",\n",
    "    \"conversation_id\",\n",
    "    \"place\",\n",
    "    \"photos\",\n",
    "    \"video\",\n",
    "    \"near\",\n",
    "    \"geo\",\n",
    "    \"source\",\n",
    "    \"user_rt_id\",\n",
    "    \"user_rt\",\n",
    "    \"retweet_id\",\n",
    "    \"reply_to\",\n",
    "    \"retweet_date\",\n",
    "    \"translate\",\n",
    "    \"trans_src\",\n",
    "    \"trans_dest\",\n",
    "    \"link\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calEmoForTweet(tweet):\n",
    "    tempTweet = tweet\n",
    "    tempTweetCleaned = TwitterPreprocessor(tempTweet).fully_preprocess().text\n",
    "    \n",
    "#     tempTokens = TweetTokenizer.tokenize(tempTweetCleaned)\n",
    "    tempTokens = nltk.word_tokenize(tempTweetCleaned)\n",
    "#     tempTokens = [tempToken.lower() for tempToken in tempTokens if len(tempToken)>2]\n",
    "#     tempTokens = [tempToken.lower() for tempToken in tempTokens if tempToken.lower() not in stopset and len(tempToken)>2]\n",
    "    \n",
    "    summary = lexicon.summarize_doc(tempTokens)\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating... fcharles81.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "{'positive': 0.08077758103602568, 'sadness': 0.02006569630885572, 'trust': 0.05014820855863482, 'anticipation': 0.048726328784548245, 'negative': 0.04552184172069993, 'fear': 0.03088518842587695, 'joy': 0.04432112301476929, 'surprise': 0.028664386003705234, 'disgust': 0.017283581615450107, 'anger': 0.02841112320039621, 'valid_tweet_count': 2483.0}\n",
      "Calculating... GeoffMillard.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "{'positive': 0.08850023371534158, 'sadness': 0.033235892276753554, 'trust': 0.058780233562243746, 'anticipation': 0.044306846162893355, 'negative': 0.06464355161982124, 'anger': 0.03555015322514268, 'fear': 0.035744380868346096, 'joy': 0.042416665869899506, 'surprise': 0.022545487813523384, 'disgust': 0.023644540377432504, 'valid_tweet_count': 10766.0}\n",
      "Calculating... cNikonphoto.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "{'sadness': 0.009221199458654405, 'trust': 0.023883385007700503, 'anticipation': 0.02244573451250814, 'negative': 0.019485540238784602, 'anger': 0.01027292272888411, 'fear': 0.013288582800013478, 'joy': 0.029163731824777193, 'surprise': 0.010738754770084812, 'disgust': 0.007103624795911249, 'positive': 0.04945459736927983, 'valid_tweet_count': 6981.0}\n",
      "Calculating... veteranhank.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "{'positive': 0.09712437856131395, 'sadness': 0.03145352186380291, 'trust': 0.06199392383128199, 'anticipation': 0.03920568898764476, 'negative': 0.06605931671774884, 'anger': 0.03273828951731852, 'fear': 0.040639623201962474, 'joy': 0.03792250726551803, 'surprise': 0.024414494906677863, 'disgust': 0.024326196453270454, 'valid_tweet_count': 4980.0}\n",
      "Calculating... RalasGang.csv\n",
      "0\n",
      "1000\n",
      "{'positive': 0.09693936532108634, 'sadness': 0.03328480544804224, 'trust': 0.060574178384649825, 'anticipation': 0.04851342321105067, 'fear': 0.035518376581398364, 'joy': 0.06626154942535178, 'surprise': 0.028946946464659364, 'disgust': 0.01679004268424325, 'anger': 0.02135458851997136, 'negative': 0.050120778710581404, 'valid_tweet_count': 1209.0}\n",
      "Calculating... jamesmartin0848.csv\n",
      "0\n",
      "1000\n",
      "{'sadness': 0.016941057072112936, 'anticipation': 0.053477779752557526, 'negative': 0.03860047031505965, 'anger': 0.018533193311524813, 'fear': 0.024933630520698368, 'joy': 0.05647173231722715, 'surprise': 0.03436214563787056, 'disgust': 0.01689709300385107, 'positive': 0.10808337043195206, 'trust': 0.0494178513773445, 'valid_tweet_count': 1021.0}\n",
      "Calculating... UndrshfGElliott.csv\n",
      "0\n",
      "{'positive': 0.05824130644355868, 'sadness': 0.027676794211114804, 'trust': 0.04898286397820262, 'anticipation': 0.03635222511693098, 'negative': 0.055592870395073136, 'anger': 0.03708467768912451, 'fear': 0.03871557351459998, 'joy': 0.02837033277355857, 'surprise': 0.022188589153484782, 'disgust': 0.014344625786751022, 'valid_tweet_count': 465.0}\n",
      "Calculating... JeffLaughlin2.csv\n",
      "0\n",
      "{'positive': 0.06582345804452025, 'sadness': 0.019241584405909243, 'trust': 0.05162383060529098, 'anticipation': 0.029352741670397836, 'negative': 0.049948764350353524, 'anger': 0.021117213705032226, 'fear': 0.02779661494842127, 'joy': 0.03954588424318535, 'surprise': 0.018645406880700998, 'disgust': 0.01997278194140542, 'valid_tweet_count': 442.0}\n",
      "Calculating... jerryesummers.csv\n",
      "0\n",
      "{'sadness': 0.01169299645813739, 'anticipation': 0.07472402061557407, 'negative': 0.017813411131183635, 'anger': 0.008264590450763888, 'fear': 0.015158469363621786, 'surprise': 0.011005751342450793, 'disgust': 0.005042551595486389, 'positive': 0.14697244178404664, 'joy': 0.1113252211020361, 'trust': 0.09096681591944304, 'valid_tweet_count': 291.0}\n",
      "Calculating... tulsatilly.csv\n",
      "0\n",
      "{'sadness': 0.022627038997575483, 'negative': 0.05627578080003922, 'anger': 0.025555038456749602, 'surprise': 0.019741884700324612, 'disgust': 0.018460557735890493, 'positive': 0.10847428604873999, 'joy': 0.04888926383592305, 'anticipation': 0.047463192348222716, 'trust': 0.06905517578141578, 'fear': 0.023975717835252958, 'valid_tweet_count': 572.0}\n",
      "Calculating... MelanieSmith82.csv\n",
      "0\n",
      "{'sadness': 0.027759059598682242, 'trust': 0.06259457606279849, 'anticipation': 0.04272496371552975, 'negative': 0.035200255719123635, 'anger': 0.0172495219665031, 'fear': 0.019298442647499255, 'joy': 0.0528140622480245, 'surprise': 0.02245514608970418, 'disgust': 0.01886792452830189, 'positive': 0.12772520015568672, 'valid_tweet_count': 212.0}\n",
      "Calculating... anthonysbbqrubs.csv\n",
      "0\n",
      "{'positive': 0.1142810569010333, 'sadness': 0.011504048983065477, 'trust': 0.049431230202929596, 'anticipation': 0.0548884856626537, 'negative': 0.035259524359208344, 'anger': 0.012176529953265416, 'fear': 0.01898828188696856, 'joy': 0.08812112752568964, 'surprise': 0.022300210295174247, 'disgust': 0.009054245733420218, 'valid_tweet_count': 533.0}\n",
      "Calculating... lavekyl.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "{'positive': 0.07459687263541173, 'sadness': 0.02591991511273417, 'trust': 0.0494879404981789, 'anticipation': 0.046925074731618326, 'negative': 0.057347479321411605, 'anger': 0.03506305427170865, 'fear': 0.032086601939093316, 'joy': 0.03291416535232304, 'surprise': 0.02591923302381103, 'disgust': 0.023571830800684986, 'valid_tweet_count': 2148.0}\n",
      "Calculating... AnitaResists.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "{'positive': 0.09726072190830758, 'sadness': 0.04045040652289457, 'trust': 0.06961094742756123, 'anticipation': 0.04664273856140441, 'negative': 0.08850987842210711, 'anger': 0.047688282435243735, 'fear': 0.05282711692111337, 'joy': 0.049144999926583666, 'surprise': 0.030841988631064646, 'disgust': 0.034963295079966344, 'valid_tweet_count': 5515.0}\n",
      "Calculating... BurntShine.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "{'sadness': 0.026071281271131105, 'anger': 0.02503535529599437, 'fear': 0.029230333263123246, 'surprise': 0.024677089519856553, 'disgust': 0.021777702413203863, 'positive': 0.1028247315078916, 'trust': 0.05735721900095398, 'joy': 0.056859709779354325, 'anticipation': 0.04140066554517381, 'negative': 0.0525708019975163, 'valid_tweet_count': 2191.0}\n",
      "Calculating... Persch83.csv\n",
      "0\n",
      "1000\n",
      "{'anticipation': 0.03381868285548394, 'positive': 0.06617403755145333, 'trust': 0.03415064289071298, 'negative': 0.04226695707936309, 'anger': 0.023500274492647008, 'joy': 0.02481682825334321, 'surprise': 0.014051272420046616, 'disgust': 0.015385760520013277, 'sadness': 0.018559771684407724, 'fear': 0.024453415273560916, 'valid_tweet_count': 1437.0}\n",
      "Calculating... ricinMD.csv\n",
      "0\n",
      "1000\n",
      "{'positive': 0.07393384717322793, 'sadness': 0.037174487596718604, 'trust': 0.04199996469119609, 'anticipation': 0.05299017162356719, 'negative': 0.08382281136969864, 'anger': 0.05845432628658048, 'fear': 0.041606181606427164, 'joy': 0.04563295587082902, 'surprise': 0.042819015043828526, 'disgust': 0.03569381230295414, 'valid_tweet_count': 1608.0}\n",
      "Calculating... lesletx.csv\n",
      "0\n",
      "1000\n",
      "{'sadness': 0.016076920703865433, 'anticipation': 0.04191688848292583, 'negative': 0.03438997421563287, 'anger': 0.017735698481245756, 'fear': 0.017952646532767638, 'joy': 0.04949438322707005, 'surprise': 0.02084939008743299, 'disgust': 0.014051693681413454, 'positive': 0.09130755312918527, 'trust': 0.06540010835004621, 'valid_tweet_count': 1767.0}\n",
      "Calculating... Stuckertmellisa.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "{'sadness': 0.029561788865643472, 'negative': 0.04671309084880359, 'anger': 0.027024922632836706, 'joy': 0.04594343847141984, 'surprise': 0.028646207353235486, 'disgust': 0.016258744491361422, 'positive': 0.08317263696067292, 'fear': 0.03669061581674402, 'anticipation': 0.04904792202966287, 'trust': 0.056066375906680406, 'valid_tweet_count': 2280.0}\n",
      "Calculating... Ironman_Tri2001.csv\n",
      "0\n",
      "{'trust': 0.08653823170845802, 'anticipation': 0.04062495443356515, 'negative': 0.0341254458219877, 'anger': 0.014160484255651914, 'fear': 0.0224154403977857, 'joy': 0.04537570971913434, 'surprise': 0.011078283813699154, 'positive': 0.1312953871844651, 'sadness': 0.018172640264210206, 'disgust': 0.0069875070932866185, 'valid_tweet_count': 664.0}\n",
      "Calculating... mcbain120041.csv\n",
      "0\n",
      "{'positive': 0.14604446544307953, 'sadness': 0.001893939393939394, 'trust': 0.13974019466512452, 'anticipation': 0.026530276524089423, 'negative': 0.012764097417001229, 'anger': 0.0012626262626262625, 'fear': 0.001893939393939394, 'joy': 0.04260674643449763, 'surprise': 0.006686179981634527, 'valid_tweet_count': 66.0, 'disgust': 0.0}\n",
      "Calculating... mungerRoyan.csv\n",
      "0\n",
      "{'anger': 0.011523599698599195, 'sadness': 0.013748878195918668, 'fear': 0.022858217404519262, 'positive': 0.0925723862014909, 'trust': 0.06284077614495732, 'anticipation': 0.04692745598432958, 'joy': 0.03241339193198931, 'surprise': 0.013433986185035537, 'disgust': 0.007643089354994939, 'negative': 0.021502055937794688, 'valid_tweet_count': 721.0}\n",
      "Calculating... kiwiibones.csv\n",
      "0\n",
      "{'positive': 0.06759121214016453, 'sadness': 0.01902038174480004, 'trust': 0.04093533521062287, 'anticipation': 0.0355704991193193, 'negative': 0.04902457419776298, 'anger': 0.01907619834774779, 'fear': 0.01591921378707471, 'joy': 0.04817440421397004, 'surprise': 0.020625516751221085, 'disgust': 0.018072011277986952, 'valid_tweet_count': 244.0}\n",
      "Calculating... RichardDunlop.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "{'positive': 0.07694477756722827, 'trust': 0.04758612391766133, 'anticipation': 0.0364298029852055, 'anger': 0.019323970069712006, 'joy': 0.03161415860725957, 'surprise': 0.017182274974092016, 'disgust': 0.011177317344637087, 'fear': 0.02051292145582928, 'sadness': 0.017725038938442912, 'negative': 0.03682459936655026, 'valid_tweet_count': 14073.0}\n",
      "Calculating... StuartMcCarthy_.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "{'positive': 0.07655102058479413, 'trust': 0.05521368293477798, 'anticipation': 0.0346721508795685, 'joy': 0.018716775877212845, 'surprise': 0.01201294896066699, 'disgust': 0.022132341888677742, 'fear': 0.04766787273612098, 'sadness': 0.03518906094683023, 'negative': 0.0700538896373984, 'anger': 0.02794215023866349, 'valid_tweet_count': 10016.0}\n",
      "Calculating... mikesimonsays.csv\n",
      "0\n",
      "1000\n",
      "{'positive': 0.10052156047717523, 'sadness': 0.03753825047410204, 'trust': 0.06876428818188629, 'anticipation': 0.04871867828237104, 'negative': 0.07721303880168867, 'anger': 0.034778390945422816, 'fear': 0.0410593272646545, 'joy': 0.05886786488645717, 'surprise': 0.024374930248709976, 'disgust': 0.04106864998122493, 'valid_tweet_count': 1837.0}\n",
      "Calculating... QueenBlaqu.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "{'fear': 0.030037464764126946, 'disgust': 0.031842124633809955, 'positive': 0.0776218766753695, 'trust': 0.04351067590133031, 'sadness': 0.030852720730613264, 'anticipation': 0.036511645895794254, 'negative': 0.0633144630766274, 'anger': 0.034869526242639684, 'joy': 0.048239824438406395, 'surprise': 0.019441642796540013, 'valid_tweet_count': 7526.0}\n",
      "Calculating... zat954.csv\n",
      "0\n",
      "{'positive': 0.09796243091490879, 'sadness': 0.024773687800206473, 'trust': 0.0619889020223345, 'anticipation': 0.040097779688538775, 'negative': 0.060908137037728106, 'anger': 0.031215604258570732, 'fear': 0.03846156945978835, 'joy': 0.04394552141606714, 'surprise': 0.022186394571625294, 'disgust': 0.020207348577746406, 'valid_tweet_count': 297.0}\n",
      "Calculating... HuffmanForNC.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "{'anticipation': 0.039336955827378575, 'anger': 0.03576444400468717, 'joy': 0.031405494688215956, 'surprise': 0.02412203624637589, 'disgust': 0.01879348709247746, 'positive': 0.07684950696378838, 'trust': 0.06007305064509316, 'sadness': 0.026625358862762443, 'negative': 0.061275840397044735, 'fear': 0.034726662279016836, 'valid_tweet_count': 5480.0}\n",
      "Calculating... Matkaufman1220.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "{'positive': 0.0842143212343875, 'sadness': 0.02535019748216089, 'trust': 0.05439773609977199, 'anticipation': 0.04543837511615482, 'negative': 0.052422617874677106, 'anger': 0.025829634835844092, 'fear': 0.026467669580969324, 'joy': 0.04277119395354706, 'surprise': 0.020957756503565243, 'disgust': 0.017973026085163227, 'valid_tweet_count': 5760.0}\n",
      "Calculating... MikeCopeland395.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "{'positive': 0.07937529928540085, 'trust': 0.05509810562380059, 'anticipation': 0.0517567295644777, 'fear': 0.03507898252405931, 'joy': 0.04775799218142163, 'surprise': 0.02631242708260585, 'anger': 0.034852674432952487, 'sadness': 0.033986650913643265, 'disgust': 0.03129499007936714, 'negative': 0.07475129356813678, 'valid_tweet_count': 7182.0}\n",
      "Calculating... pryteighpaper.csv\n",
      "0\n",
      "{'sadness': 0.014288498695278358, 'negative': 0.033420496640835635, 'fear': 0.013233428530038702, 'surprise': 0.025058180990384385, 'disgust': 0.0038597560631458937, 'positive': 0.12759411492462333, 'trust': 0.06418779901830747, 'anticipation': 0.06665560898611743, 'anger': 0.011066875685519754, 'joy': 0.07572863577100862, 'valid_tweet_count': 118.0}\n",
      "Calculating... mdmellott.csv\n",
      "0\n",
      "{'anger': 0.010218093366229048, 'sadness': 0.01063094493636962, 'disgust': 0.007389326785746222, 'negative': 0.0243695511971042, 'fear': 0.02207528813780166, 'positive': 0.14108525389812607, 'anticipation': 0.08791031710723339, 'trust': 0.0965659681275921, 'joy': 0.06763201376466077, 'surprise': 0.025458514754578346, 'valid_tweet_count': 345.0}\n",
      "Calculating... EsqRaza.csv\n",
      "0\n",
      "{'sadness': 0.02352096080323194, 'negative': 0.04444497939212081, 'anger': 0.014886352432936288, 'fear': 0.01878658108803381, 'surprise': 0.025156350086136745, 'disgust': 0.01110972360972361, 'positive': 0.1305405206596412, 'joy': 0.07223486444030991, 'anticipation': 0.0694621965186372, 'trust': 0.0877507378992065, 'valid_tweet_count': 322.0}\n",
      "Calculating... xanderinvictus.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "{'sadness': 0.019216825198058663, 'disgust': 0.014971965451753349, 'surprise': 0.02609723686752776, 'trust': 0.05265321249246402, 'positive': 0.08656121416881125, 'joy': 0.04943422988708706, 'anger': 0.022958252325591334, 'fear': 0.02566411034209077, 'anticipation': 0.06118351246278241, 'negative': 0.04465800425428674, 'valid_tweet_count': 4620.0}\n",
      "Calculating... jackvelbar.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "{'positive': 0.09364379873687707, 'sadness': 0.017003755787098028, 'trust': 0.06724546713763996, 'anticipation': 0.042876474247354385, 'negative': 0.03893706585313881, 'anger': 0.018766199570450944, 'fear': 0.02855603085953751, 'joy': 0.04488256603630673, 'surprise': 0.015416392759831041, 'disgust': 0.013054050667792489, 'valid_tweet_count': 7178.0}\n",
      "Calculating... AmerHeroesRadio.csv\n",
      "0\n",
      "1000\n",
      "{'positive': 0.13714068294407872, 'sadness': 0.020153768648028196, 'trust': 0.09663932147690699, 'anticipation': 0.04402489294738158, 'negative': 0.048884780427401714, 'anger': 0.03062293452830098, 'fear': 0.07327012632728155, 'joy': 0.026687319882559898, 'surprise': 0.014266828427754627, 'disgust': 0.005317429605806797, 'valid_tweet_count': 1800.0}\n",
      "Calculating... Timothy_M_Jones.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "{'positive': 0.14757455951475862, 'sadness': 0.013024625377000434, 'trust': 0.08476259741290439, 'negative': 0.025120816064683842, 'anger': 0.011872218066430306, 'fear': 0.01804905304069568, 'joy': 0.08995946240414038, 'surprise': 0.03706881828463638, 'disgust': 0.0059753875570365345, 'anticipation': 0.08186097686484509, 'valid_tweet_count': 3309.0}\n",
      "Calculating... Jen_Everitt.csv\n",
      "0\n",
      "{'sadness': 0.017661319258232673, 'trust': 0.04240154609782137, 'anticipation': 0.04256505275966861, 'negative': 0.03648372796620875, 'anger': 0.01342497571301944, 'fear': 0.01654499951687667, 'joy': 0.04994064151718241, 'surprise': 0.022518290691740595, 'disgust': 0.014072087406309972, 'positive': 0.08048418837543408, 'valid_tweet_count': 863.0}\n",
      "Calculating... MalanaShea.csv\n",
      "0\n",
      "1000\n",
      "{'trust': 0.053564222478341965, 'joy': 0.06542842916947206, 'anticipation': 0.052510690115885994, 'positive': 0.08901887382832849, 'sadness': 0.025160417265795487, 'negative': 0.04150446027385861, 'anger': 0.01933328179576034, 'fear': 0.021440076021443, 'surprise': 0.02645077323081893, 'disgust': 0.011782979207372445, 'valid_tweet_count': 1924.0}\n",
      "Calculating... robveteran2232.csv\n",
      "0\n",
      "{'positive': 0.020670429788076847, 'sadness': 0.0023965141612200436, 'trust': 0.011633986928104575, 'anticipation': 0.004674192909487027, 'negative': 0.007855706385118151, 'anger': 0.005664488017429193, 'fear': 0.0056225909167085635, 'joy': 0.00843731431966726, 'surprise': 0.0017429193899782135, 'disgust': 0.00457516339869281, 'valid_tweet_count': 153.0}\n",
      "Calculating... ILIntelCorp.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "{'sadness': 0.03621966937533355, 'anticipation': 0.04403105071425262, 'negative': 0.0791928602753155, 'anger': 0.03966320279319055, 'fear': 0.04137440987338561, 'joy': 0.035717635729072814, 'surprise': 0.022689827769073963, 'disgust': 0.02823280091054285, 'positive': 0.07864185867413695, 'trust': 0.06034185974084254, 'valid_tweet_count': 4552.0}\n",
      "Calculating... dvc9999.csv\n",
      "0\n",
      "{'positive': 0.08940270434172871, 'sadness': 0.022548352731279562, 'trust': 0.05703184011110838, 'anticipation': 0.05918013219842485, 'fear': 0.03155450579231066, 'joy': 0.05688863981546905, 'surprise': 0.0465615008297935, 'anger': 0.02194600792161768, 'disgust': 0.024281206598279773, 'negative': 0.051652175737541585, 'valid_tweet_count': 328.0}\n",
      "Calculating... dcbrant.csv\n",
      "0\n",
      "{'sadness': 0.023956276178794134, 'negative': 0.05437230723246803, 'anger': 0.02666395991645, 'fear': 0.02725800818886706, 'disgust': 0.022177579171191085, 'positive': 0.122343425067471, 'joy': 0.0642362932025907, 'trust': 0.07693026707835864, 'anticipation': 0.049518573098653124, 'surprise': 0.03475592823363796, 'valid_tweet_count': 663.0}\n",
      "Calculating... jtkstc.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "{'sadness': 0.03735194348473475, 'trust': 0.05180448206951773, 'anticipation': 0.03892688517325419, 'anger': 0.03562968783161775, 'fear': 0.040147389814378945, 'joy': 0.027177825458517938, 'surprise': 0.04788509183908174, 'disgust': 0.02407594702438018, 'negative': 0.07402023179217798, 'positive': 0.07616362843494642, 'valid_tweet_count': 2139.0}\n",
      "Calculating... CullenYossarian.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "{'sadness': 0.015599258504617968, 'negative': 0.041467938017195505, 'anger': 0.021071006573599536, 'fear': 0.023634750055863216, 'disgust': 0.015114020088564818, 'positive': 0.12155226462698056, 'trust': 0.07555073550068499, 'anticipation': 0.04896917557812468, 'joy': 0.05611500242356696, 'surprise': 0.022931885317778195, 'valid_tweet_count': 5560.0}\n",
      "Calculating... JustCallMeRage.csv\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cary/.local/share/virtualenvs/TextAnalytics-9hFs7Vd6/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (21) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "{'positive': 0.062065477519859864, 'joy': 0.03617771193790886, 'trust': 0.03804327985624282, 'surprise': 0.019855951470228183, 'sadness': 0.027013335035117086, 'negative': 0.05621970560847217, 'anger': 0.028939420545983273, 'fear': 0.026555534103392755, 'disgust': 0.02368124288565753, 'anticipation': 0.03392467649561844, 'valid_tweet_count': 16417.0}\n",
      "Calculating... StMarthasTable.csv\n",
      "0\n",
      "1000\n",
      "{'sadness': 0.02357625683706724, 'negative': 0.050351123640822906, 'anger': 0.016152197361477227, 'fear': 0.03733262298775152, 'surprise': 0.016694616843452893, 'disgust': 0.012193887601799942, 'positive': 0.14723397184623138, 'joy': 0.06824359269352323, 'anticipation': 0.05623005139247291, 'trust': 0.09085786831673945, 'valid_tweet_count': 1280.0}\n",
      "Calculating... amwyatt.csv\n",
      "0\n",
      "{'sadness': 0.012396406799391876, 'trust': 0.03924733842043578, 'negative': 0.02663343095585905, 'anger': 0.017225214333712092, 'fear': 0.02026473104172841, 'joy': 0.0335504503710653, 'surprise': 0.0222388250876614, 'disgust': 0.008035220721787886, 'anticipation': 0.043987440336499976, 'positive': 0.07006359870740378, 'valid_tweet_count': 201.0}\n",
      "Calculating... idfsniper.csv\n",
      "0\n",
      "{'sadness': 0.017946885298975385, 'anticipation': 0.037736242145053084, 'anger': 0.025801356511126947, 'fear': 0.032975507798503965, 'joy': 0.020913532907414645, 'surprise': 0.014974744214836173, 'positive': 0.06470207850513064, 'trust': 0.044132429163330884, 'disgust': 0.017882367771800967, 'negative': 0.05782999881206819, 'valid_tweet_count': 591.0}\n",
      "Calculating... Pharoe73.csv\n",
      "0\n",
      "{'positive': 0.09337350502604738, 'sadness': 0.027206691613471272, 'trust': 0.035431242347992095, 'anticipation': 0.03264790764790765, 'negative': 0.05483630277997177, 'anger': 0.03370483786735033, 'fear': 0.023532594856124262, 'joy': 0.0205743879472693, 'surprise': 0.020477474502898236, 'disgust': 0.0066568152684802736, 'valid_tweet_count': 59.0}\n",
      "Calculating... en4cer18.csv\n",
      "0\n",
      "{'positive': 0.08933001365514089, 'trust': 0.05429466780145596, 'joy': 0.03581850800103395, 'surprise': 0.03127024469992434, 'disgust': 0.013780703483739533, 'anger': 0.02564235469964831, 'fear': 0.02807382991974391, 'sadness': 0.026797619640712814, 'negative': 0.036112497895237614, 'anticipation': 0.0526899881582069, 'valid_tweet_count': 170.0}\n",
      "Calculating... JeremyPing1.csv\n",
      "0\n",
      "{'sadness': 0.020981250501370025, 'negative': 0.03908582309026017, 'anger': 0.018907758708525093, 'surprise': 0.023918128645899164, 'disgust': 0.009439064357542621, 'positive': 0.09147940282277994, 'joy': 0.047128433491829436, 'trust': 0.05618380546082122, 'anticipation': 0.047688777922879545, 'fear': 0.02944973255132232, 'valid_tweet_count': 280.0}\n",
      "Calculating... jscherer100.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "{'positive': 0.11288275769174638, 'sadness': 0.026747570781278696, 'trust': 0.07539722823992487, 'anticipation': 0.05671956320832731, 'negative': 0.05185286810567716, 'anger': 0.023595067853494845, 'fear': 0.028320200398852136, 'joy': 0.06383334829964046, 'surprise': 0.04390432414027923, 'disgust': 0.02280271413979281, 'valid_tweet_count': 2225.0}\n",
      "Calculating... WarHunden.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "{'positive': 0.0897458796264888, 'sadness': 0.023998694430095478, 'trust': 0.07382138373640923, 'anticipation': 0.036736689660468815, 'negative': 0.05538477074276012, 'anger': 0.032559540698744505, 'fear': 0.033025372725234634, 'joy': 0.05082863013685768, 'surprise': 0.020020376401777402, 'disgust': 0.026729918790787642, 'valid_tweet_count': 2386.0}\n",
      "Calculating... McGuireArmyNavy.csv\n",
      "0\n",
      "{'positive': 0.0847201112585536, 'sadness': 0.017085284085284074, 'trust': 0.04933726967788848, 'anticipation': 0.039535836542455495, 'negative': 0.04783270489405703, 'anger': 0.01950184966144218, 'fear': 0.03778295042000418, 'joy': 0.04396239789176729, 'surprise': 0.02270572178466914, 'disgust': 0.010178378808813587, 'valid_tweet_count': 555.0}\n",
      "Calculating... TeeliaLowery.csv\n",
      "0\n",
      "1000\n",
      "{'positive': 0.10224805714001274, 'sadness': 0.0223331864448204, 'trust': 0.060884488632656435, 'anticipation': 0.04752773181820481, 'negative': 0.04020314325864003, 'anger': 0.019470469870630176, 'fear': 0.029921626264680062, 'joy': 0.04901576212776471, 'surprise': 0.01786772601105319, 'disgust': 0.009790834783008876, 'valid_tweet_count': 1194.0}\n",
      "Calculating... Christi78790.csv\n",
      "0\n",
      "{'positive': 0.13208901222706979, 'sadness': 0.014870102978378945, 'trust': 0.07969054101233904, 'anticipation': 0.03812984377849689, 'negative': 0.03556493557168418, 'anger': 0.016763104320599246, 'fear': 0.02768607351221974, 'joy': 0.09817332804464471, 'surprise': 0.015105267338124822, 'disgust': 0.013258217350506314, 'valid_tweet_count': 347.0}\n",
      "Calculating... normanllamas.csv\n",
      "0\n",
      "{'sadness': 0.026902366606322593, 'negative': 0.052523257519671455, 'anger': 0.02202807288964025, 'fear': 0.03256704888810523, 'joy': 0.02728111231643387, 'surprise': 0.02339934490639403, 'disgust': 0.013601981657749316, 'positive': 0.08432107803465097, 'anticipation': 0.04033112857974606, 'trust': 0.04837731366439653, 'valid_tweet_count': 269.0}\n",
      "Calculating... WVPapiX3.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "{'sadness': 0.031302534009770816, 'trust': 0.0943861303408484, 'anticipation': 0.04773803600428533, 'negative': 0.07510009349313011, 'anger': 0.03827778837654597, 'fear': 0.03702412074928496, 'surprise': 0.0239734446439952, 'disgust': 0.025767903142338785, 'positive': 0.12539377694591608, 'joy': 0.06647844629694453, 'valid_tweet_count': 2759.0}\n",
      "Calculating... SNAFU_Sara.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "{'sadness': 0.027353669505114503, 'anticipation': 0.03918022717242502, 'negative': 0.05450912186971624, 'anger': 0.025963109425489482, 'fear': 0.028069085642301893, 'joy': 0.03349851525785684, 'surprise': 0.018244231800873888, 'disgust': 0.020442827717353243, 'trust': 0.04688119436584876, 'positive': 0.06967666646808146, 'valid_tweet_count': 19920.0}\n",
      "Calculating... Meastt23.csv\n",
      "0\n",
      "1000\n",
      "{'sadness': 0.027530931875377803, 'negative': 0.07001534406024358, 'anger': 0.042824994297398195, 'fear': 0.038242960872135835, 'surprise': 0.021190891063580207, 'disgust': 0.02852427393847342, 'positive': 0.0834970431664781, 'joy': 0.03902976373462485, 'anticipation': 0.04233687479339253, 'trust': 0.056992603724530466, 'valid_tweet_count': 1645.0}\n",
      "Calculating... VyceVictus.csv\n",
      "0\n",
      "{'positive': 0.0768450418518363, 'sadness': 0.030840557331156936, 'trust': 0.04884634777803282, 'anticipation': 0.04608439083930164, 'negative': 0.06712688356691622, 'anger': 0.037518419293245155, 'fear': 0.04423036531778728, 'joy': 0.03262238954562049, 'surprise': 0.0174967326276785, 'disgust': 0.028601858984515668, 'valid_tweet_count': 400.0}\n",
      "Calculating... dsdelamater.csv\n",
      "0\n",
      "{'sadness': 0.01262137807400224, 'trust': 0.05431805027502893, 'anticipation': 0.04970221784200009, 'anger': 0.01919581668802839, 'joy': 0.04812543501993905, 'surprise': 0.01778037465515451, 'disgust': 0.011620085522868195, 'negative': 0.0399591213753714, 'fear': 0.016473674007924398, 'positive': 0.09961423314740211, 'valid_tweet_count': 167.0}\n",
      "Calculating... HouseDivaJill.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "{'sadness': 0.02479070432399, 'trust': 0.04660733692213913, 'negative': 0.05921423705147528, 'anger': 0.03234056551570646, 'fear': 0.03924610308633087, 'surprise': 0.017615581017054835, 'disgust': 0.021340557290375206, 'positive': 0.07635965671820517, 'joy': 0.04210190498138111, 'anticipation': 0.036604682151160556, 'valid_tweet_count': 2093.0}\n",
      "Calculating... zack_kreish.csv\n",
      "0\n",
      "{'positive': 0.1463274718745306, 'sadness': 0.011422799422799423, 'trust': 0.08213619648325529, 'anticipation': 0.06573759573759572, 'negative': 0.02330851370851371, 'anger': 0.0047619047619047615, 'fear': 0.009984126984126982, 'joy': 0.08976762126762124, 'surprise': 0.021864579864579865, 'disgust': 0.005968253968253968, 'valid_tweet_count': 150.0}\n",
      "Calculating... missleatha3.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "{'positive': 0.07235944209152151, 'sadness': 0.028735780003247176, 'trust': 0.05030929457189903, 'anticipation': 0.032231881427195436, 'negative': 0.06800422654184288, 'anger': 0.0357003967325629, 'fear': 0.03625186134145766, 'joy': 0.02866255010373482, 'surprise': 0.027150848279550725, 'disgust': 0.025222446317814173, 'valid_tweet_count': 3880.0}\n",
      "Calculating... OldParaTRP.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "{'positive': 0.08728561587136435, 'sadness': 0.03420332591516321, 'anticipation': 0.04346063654885174, 'negative': 0.07487425122455506, 'anger': 0.03628325003337535, 'fear': 0.0422597030988698, 'joy': 0.03741846512197305, 'surprise': 0.024828692446363033, 'disgust': 0.023661315530204906, 'trust': 0.06258410574721582, 'valid_tweet_count': 5393.0}\n",
      "Calculating... PatrioticCPT.csv\n",
      "0\n",
      "{'sadness': 0.03461981696046829, 'negative': 0.07495960478736435, 'anger': 0.03910205260348112, 'joy': 0.034895388192364644, 'surprise': 0.020284090548808816, 'disgust': 0.027707322082021212, 'anticipation': 0.04184360183130118, 'trust': 0.06829675446519416, 'positive': 0.0870741898771664, 'fear': 0.04393346699194879, 'valid_tweet_count': 621.0}\n",
      "Calculating... E_Young_56.csv\n",
      "0\n",
      "1000\n",
      "{'positive': 0.10632734423962843, 'sadness': 0.01672107784603233, 'trust': 0.08395288168021871, 'anticipation': 0.07117485074592031, 'negative': 0.0566985255691352, 'anger': 0.02976891346617562, 'fear': 0.026821813217938983, 'joy': 0.06999613773687766, 'surprise': 0.0356910767480965, 'disgust': 0.025060362617180813, 'valid_tweet_count': 1320.0}\n",
      "Calculating... ToddTannerWV.csv\n",
      "0\n",
      "1000\n",
      "{'positive': 0.13330698139933073, 'trust': 0.08256928162930234, 'anticipation': 0.07500466501476033, 'joy': 0.08560533518821917, 'surprise': 0.03480768937083585, 'disgust': 0.026764572364018042, 'sadness': 0.03778669934213479, 'negative': 0.06957943515160019, 'anger': 0.03396191049902739, 'fear': 0.04902381698180866, 'valid_tweet_count': 1298.0}\n",
      "Calculating... thejamiekaiser.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "{'positive': 0.09187291430474456, 'sadness': 0.020966978378620105, 'trust': 0.05875415081033685, 'anticipation': 0.0476353455451238, 'negative': 0.0439592743144145, 'anger': 0.019455719179243592, 'fear': 0.026801031516059184, 'joy': 0.03657323448670899, 'surprise': 0.01905829775378089, 'disgust': 0.012654973964054675, 'valid_tweet_count': 9683.0}\n",
      "Calculating... OSUfan_2.csv\n",
      "0\n",
      "{'sadness': 0.021633855324398522, 'trust': 0.06157726614734774, 'anticipation': 0.06503784722121336, 'negative': 0.026584438848722542, 'anger': 0.012083341338900025, 'fear': 0.02166464077665878, 'surprise': 0.03225485111567295, 'disgust': 0.005798566393837995, 'positive': 0.11837636174429032, 'joy': 0.08916896600860852, 'valid_tweet_count': 330.0}\n",
      "Calculating... 3sixtyTax.csv\n",
      "0\n",
      "1000\n",
      "{'anger': 0.042742597575473225, 'fear': 0.04495128792676082, 'surprise': 0.023076312345419653, 'disgust': 0.035962971063674624, 'positive': 0.09524775179784657, 'joy': 0.04080771821697669, 'anticipation': 0.04280741443694759, 'trust': 0.06805473661777582, 'sadness': 0.04097736687439132, 'negative': 0.09076141655506839, 'valid_tweet_count': 1419.0}\n",
      "Calculating... EthanMilich.csv\n",
      "0\n",
      "{'sadness': 0.011489169439102014, 'anticipation': 0.017813360021080384, 'negative': 0.02376673924903194, 'anger': 0.011963349843923127, 'fear': 0.010212080871648845, 'surprise': 0.011073274324986688, 'disgust': 0.006698384799368383, 'positive': 0.043044146753136024, 'joy': 0.017803329378249997, 'trust': 0.02896298126278458, 'valid_tweet_count': 879.0}\n",
      "Calculating... C38557143.csv\n",
      "0\n",
      "{'positive': 0.10280949824554196, 'sadness': 0.02022076090561581, 'trust': 0.07063084960864056, 'anticipation': 0.042514113541935225, 'negative': 0.038335097865138563, 'anger': 0.017635394420283678, 'fear': 0.02578118824094738, 'joy': 0.06965883164013527, 'surprise': 0.02920043203933737, 'disgust': 0.016227823999173253, 'valid_tweet_count': 812.0}\n",
      "Calculating... BobVitale.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "{'positive': 0.09744030867930051, 'sadness': 0.03408113687770506, 'trust': 0.0659566042255219, 'anticipation': 0.0450278194520849, 'negative': 0.08504586821555242, 'anger': 0.0406372958718479, 'fear': 0.033787047517317995, 'joy': 0.04116184157006106, 'surprise': 0.028894814508517674, 'disgust': 0.03476446741594346, 'valid_tweet_count': 7011.0}\n",
      "Calculating... TheDarkRabbit.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "{'sadness': 0.020439881698435188, 'trust': 0.04669152502125416, 'anticipation': 0.04444851929103706, 'negative': 0.04348515840471408, 'anger': 0.021497499437030665, 'fear': 0.024286456036239815, 'surprise': 0.0206857214547667, 'disgust': 0.01749304651560249, 'positive': 0.07800257525192926, 'joy': 0.04529076724187017, 'valid_tweet_count': 17700.0}\n",
      "Calculating... ryanenser.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "{'positive': 0.1097525140944152, 'sadness': 0.009129769056574165, 'trust': 0.0795270929681752, 'anticipation': 0.06796614785160553, 'negative': 0.016555255397384634, 'anger': 0.0075557282336172205, 'fear': 0.0143826424308681, 'joy': 0.0769845112830716, 'surprise': 0.014628886262189288, 'disgust': 0.005749204793790775, 'valid_tweet_count': 3297.0}\n",
      "Calculating... Legewnis.csv\n",
      "0\n",
      "1000\n",
      "{'positive': 0.015844122889583565, 'sadness': 0.0031359178152544605, 'trust': 0.009894991905128724, 'anticipation': 0.0075875912900530895, 'negative': 0.015823682350651846, 'anger': 0.008848027390267256, 'fear': 0.014021762774139463, 'joy': 0.006804690393774584, 'surprise': 0.0036803578424970626, 'disgust': 0.003781549434320615, 'valid_tweet_count': 1550.0}\n",
      "Calculating... lilgde90.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "{'positive': 0.0688027209766509, 'sadness': 0.024849619236900412, 'trust': 0.04159543555897828, 'anticipation': 0.03797431304982912, 'anger': 0.03814336171680597, 'joy': 0.042762536652672246, 'surprise': 0.016367594307141894, 'disgust': 0.033486584358533286, 'fear': 0.027376285635795864, 'negative': 0.0579527370797246, 'valid_tweet_count': 9821.0}\n",
      "Calculating... BigFox57.csv\n",
      "0\n",
      "{'positive': 0.02185333791131282, 'sadness': 0.008232572771805098, 'trust': 0.01546357726142726, 'anticipation': 0.012596261836886648, 'negative': 0.02089890244029985, 'anger': 0.00943333031111641, 'fear': 0.01004561990879225, 'joy': 0.01047932146905082, 'surprise': 0.006633606148847813, 'disgust': 0.007206358738052545, 'valid_tweet_count': 953.0}\n",
      "Calculating... gemluvr257.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "{'sadness': 0.03214450543431395, 'trust': 0.062329122059420615, 'negative': 0.07542140877250686, 'anger': 0.037741585754210084, 'fear': 0.042185912030643195, 'disgust': 0.03154370158812949, 'positive': 0.08221800179279383, 'surprise': 0.03424279920268168, 'joy': 0.04286246361341581, 'anticipation': 0.04135430858388049, 'valid_tweet_count': 18545.0}\n",
      "Calculating... RobertLarkin3.csv\n",
      "0\n",
      "{'positive': 0.0787622114300618, 'sadness': 0.018439181313980226, 'trust': 0.0509968715245152, 'anticipation': 0.044806561902852024, 'negative': 0.0389447304206683, 'anger': 0.02264057626945003, 'fear': 0.022999956865999014, 'joy': 0.04097233921044093, 'surprise': 0.03287255916651365, 'disgust': 0.011014547709328566, 'valid_tweet_count': 408.0}\n",
      "Calculating... cheyyenne.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "{'positive': 0.0782676339406354, 'sadness': 0.023624689337610933, 'trust': 0.051543792396839885, 'anticipation': 0.04250344609193418, 'negative': 0.046427331135623286, 'anger': 0.024218871995405514, 'fear': 0.034355709968143515, 'joy': 0.05009794267047204, 'surprise': 0.02080954286963218, 'disgust': 0.019080960717970673, 'valid_tweet_count': 4025.0}\n",
      "Calculating... ill.csv\n",
      "0\n",
      "{'positive': 0.018364448051948052, 'sadness': 0.005147946859903382, 'trust': 0.013071710897797855, 'anticipation': 0.010430782985130813, 'negative': 0.009571256038647342, 'anger': 0.0070048309178743955, 'fear': 0.0069271911663216015, 'joy': 0.007666925465838511, 'surprise': 0.008344214662149445, 'disgust': 0.000981280193236715, 'valid_tweet_count': 368.0}\n",
      "Calculating... NjVeterans.csv\n",
      "0\n",
      "{'positive': 0.08964357492916149, 'sadness': 0.006273115211157641, 'trust': 0.05895075314658877, 'anticipation': 0.03883630583859235, 'negative': 0.01639431242108177, 'anger': 0.0034668216552623914, 'fear': 0.009105613986047752, 'joy': 0.059057829589323006, 'surprise': 0.0051594175431795555, 'disgust': 0.0019743689825657035, 'valid_tweet_count': 244.0}\n",
      "Calculating... FadedCanaDave.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "{'anger': 0.0301016577423534, 'sadness': 0.027979746606019193, 'fear': 0.02865246841360944, 'negative': 0.061650828994801954, 'positive': 0.08322674571930326, 'trust': 0.04748536072158497, 'anticipation': 0.05353567836692521, 'joy': 0.04645159406151592, 'surprise': 0.028426515660083158, 'disgust': 0.025730746421498647, 'valid_tweet_count': 7696.0}\n",
      "Calculating... CommonSense316.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "{'sadness': 0.030299732280443456, 'negative': 0.07812704074143713, 'anger': 0.03396179577125268, 'fear': 0.030886941786458, 'disgust': 0.028431675864099275, 'positive': 0.08269479580450793, 'trust': 0.05991655295659849, 'anticipation': 0.04105252719334343, 'joy': 0.03917568162463392, 'surprise': 0.027211815258132724, 'valid_tweet_count': 2227.0}\n",
      "Calculating... clsavage_7.csv\n",
      "0\n",
      "{'positive': 0.10233615342586261, 'sadness': 0.024985712307983785, 'trust': 0.07814373625162763, 'anticipation': 0.052974548487292286, 'negative': 0.047352656200305154, 'anger': 0.026070715038381622, 'fear': 0.01576253384153387, 'joy': 0.06147675802607203, 'surprise': 0.032157917503752076, 'disgust': 0.013051331261263954, 'valid_tweet_count': 239.0}\n",
      "Calculating... RaymondEMosher.csv\n",
      "0\n",
      "1000\n",
      "{'positive': 0.08211337975835724, 'sadness': 0.04223879623223811, 'trust': 0.05893055971219703, 'anticipation': 0.04882850646703795, 'negative': 0.08745026502221062, 'anger': 0.04451639064278538, 'fear': 0.04465661653525792, 'joy': 0.04070902915786538, 'surprise': 0.046812745317111916, 'disgust': 0.030341056851050624, 'valid_tweet_count': 1500.0}\n",
      "Calculating... Ginalolaknits.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "{'positive': 0.0038166980204986274, 'sadness': 0.0010517696421592955, 'trust': 0.002819634603684382, 'anticipation': 0.0022538484242573763, 'negative': 0.0026711762736764478, 'anger': 0.0013031690840675653, 'fear': 0.00131840517587419, 'joy': 0.0019737576567774055, 'surprise': 0.0016331673528287576, 'disgust': 0.000883986761744051, 'valid_tweet_count': 7920.0}\n",
      "Calculating... NormanZolkosMLO.csv\n",
      "0\n",
      "{'positive': 0.14336201950659774, 'sadness': 0.002065404475043029, 'trust': 0.14482501434308656, 'anticipation': 0.13740676993689036, 'negative': 0.008835341365461848, 'anger': 0.005823293172690762, 'fear': 0.00642570281124498, 'joy': 0.13453815261044175, 'surprise': 0.00321285140562249, 'disgust': 0.004475043029259897, 'valid_tweet_count': 83.0}\n",
      "Calculating... Jackmo23045.csv\n",
      "0\n",
      "{'positive': 0.0373791780060348, 'sadness': 0.01754076451046148, 'trust': 0.044114206473089404, 'anticipation': 0.020523210422200323, 'negative': 0.038485491753465606, 'anger': 0.02410237536500163, 'fear': 0.012659372493002913, 'joy': 0.01450690162811375, 'surprise': 0.012224457173952125, 'disgust': 0.009084471458208832, 'valid_tweet_count': 297.0}\n",
      "Calculating... VETS1775.csv\n",
      "0\n",
      "{'positive': 0.06839747296568345, 'sadness': 0.016089571417772074, 'trust': 0.05077584173696801, 'anticipation': 0.03763381331461314, 'negative': 0.046131772033201415, 'anger': 0.026166467616483342, 'fear': 0.04232864503186853, 'joy': 0.0354521380771781, 'surprise': 0.020453825185184293, 'disgust': 0.01157260008607605, 'valid_tweet_count': 240.0}\n",
      "Calculating... mr_jferg.csv\n",
      "0\n",
      "1000\n",
      "{'positive': 0.1206986793470096, 'sadness': 0.02591412605716381, 'trust': 0.07597581440385158, 'anticipation': 0.05711300524792645, 'negative': 0.05433498387606394, 'anger': 0.026744720984562, 'fear': 0.0354409492107558, 'joy': 0.05102719413395037, 'surprise': 0.023140075676503793, 'disgust': 0.01791730741520928, 'valid_tweet_count': 1622.0}\n",
      "Calculating... Oleblloyd.csv\n",
      "0\n",
      "{'positive': 0.07547217666578822, 'sadness': 0.012502743299459303, 'trust': 0.04458298078400651, 'anger': 0.010643087464439526, 'joy': 0.021902568116857722, 'disgust': 0.002401180379903784, 'surprise': 0.00995661516188462, 'fear': 0.018899170138544728, 'anticipation': 0.02443672948324071, 'negative': 0.01922046753118129, 'valid_tweet_count': 188.0}\n",
      "Calculating... Anc5E08.csv\n",
      "0\n",
      "{'positive': 0.057927485429672784, 'sadness': 0.02663091699542321, 'trust': 0.040549241436445865, 'anticipation': 0.02267408402753559, 'negative': 0.06053928663538522, 'anger': 0.02626753298330339, 'fear': 0.026002885508987723, 'joy': 0.0201018548434643, 'surprise': 0.014691801933411392, 'disgust': 0.024170813260248808, 'valid_tweet_count': 180.0}\n",
      "Calculating... Team_Harbaugh.csv\n",
      "0\n",
      "1000\n",
      "{'sadness': 0.02166971772979136, 'trust': 0.07509710353949162, 'anticipation': 0.04987160310707561, 'negative': 0.04414172092799502, 'anger': 0.027092537083920294, 'fear': 0.02844490113764714, 'joy': 0.03896384278329646, 'surprise': 0.02395716712498051, 'disgust': 0.011790172148095232, 'positive': 0.11307404151659059, 'valid_tweet_count': 1040.0}\n",
      "Calculating... mpdubois.csv\n",
      "0\n",
      "{'positive': 0.0637611587583567, 'trust': 0.04121819819993826, 'anticipation': 0.026486724573167388, 'fear': 0.018932113353142634, 'joy': 0.01657704540357601, 'surprise': 0.007601578808322374, 'disgust': 0.0030504265198142747, 'anger': 0.010722201377410829, 'sadness': 0.009580089715404711, 'negative': 0.01799574465361604, 'valid_tweet_count': 147.0}\n",
      "Calculating... OriginalSeanD.csv\n",
      "0\n",
      "1000\n",
      "{'sadness': 0.021649075155933017, 'anticipation': 0.03409339202026611, 'negative': 0.05487774515022591, 'anger': 0.02498577307327495, 'fear': 0.0305694327065532, 'joy': 0.04050254933891443, 'surprise': 0.021619142820734443, 'disgust': 0.017998728448706435, 'positive': 0.08284579644598722, 'trust': 0.044549771207391974, 'valid_tweet_count': 1604.0}\n",
      "Calculating... ambjg.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "{'positive': 0.07834465583647095, 'sadness': 0.030162230106370123, 'trust': 0.06129959796463774, 'anticipation': 0.03876280729939927, 'anger': 0.02824861507410573, 'fear': 0.0333962701301585, 'joy': 0.03397497266726807, 'surprise': 0.023676193037279004, 'disgust': 0.022082676643270023, 'negative': 0.06083281018059605, 'valid_tweet_count': 2541.0}\n",
      "Calculating... ShabbyDogQ.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "{'positive': 0.07844342077156981, 'sadness': 0.03159320566284726, 'trust': 0.06239396773857403, 'anticipation': 0.043932521886396965, 'negative': 0.09334200770640093, 'anger': 0.042046306849244944, 'fear': 0.035907826139051975, 'joy': 0.03335566837522799, 'disgust': 0.042585036568674926, 'surprise': 0.025365334239943152, 'valid_tweet_count': 3176.0}\n",
      "Calculating... madame_briar.csv\n",
      "0\n",
      "1000\n",
      "{'positive': 0.10989307044580315, 'trust': 0.06462667737962753, 'anticipation': 0.045107676066102706, 'joy': 0.060374572661017784, 'surprise': 0.0234812265531819, 'disgust': 0.022502377413396907, 'anger': 0.0250331258844816, 'fear': 0.03248463175539691, 'sadness': 0.023550975842231245, 'negative': 0.05730475452274603, 'valid_tweet_count': 1965.0}\n",
      "Calculating... warrior_vet.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "{'positive': 0.06421574007579434, 'sadness': 0.03472288418111287, 'trust': 0.04820695984485366, 'anticipation': 0.033670871735862584, 'anger': 0.042276423112336266, 'fear': 0.03920286224749619, 'joy': 0.03487197584145112, 'surprise': 0.025840245190634038, 'disgust': 0.03861390903700176, 'negative': 0.0752699060920037, 'valid_tweet_count': 4426.0}\n",
      "Calculating... tweetsbyjulio.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "{'positive': 0.028461692157329428, 'sadness': 0.006709945124245703, 'trust': 0.016950861092397768, 'anticipation': 0.014894239752042675, 'negative': 0.015454885822805424, 'anger': 0.008039121449677906, 'fear': 0.009444553249987461, 'joy': 0.01353691357117531, 'surprise': 0.00651291599057666, 'disgust': 0.005251128098274194, 'valid_tweet_count': 25487.0}\n",
      "Calculating... janus96159274.csv\n",
      "0\n",
      "{'positive': 0.09107448196543483, 'sadness': 0.03927769506544877, 'trust': 0.048052843301381314, 'anticipation': 0.040210590675178064, 'anger': 0.04061021659777537, 'joy': 0.02729035878808458, 'surprise': 0.02564440186434988, 'disgust': 0.04692709856108549, 'negative': 0.10951114771672431, 'fear': 0.04351900011084737, 'valid_tweet_count': 81.0}\n",
      "Calculating... dgartdeco.csv\n",
      "0\n",
      "1000\n",
      "{'positive': 0.1295486710739628, 'sadness': 0.028127994011303635, 'trust': 0.0834966194494597, 'anticipation': 0.055254992051445226, 'anger': 0.0241348542785538, 'fear': 0.030154041044399164, 'joy': 0.0708717167778748, 'surprise': 0.02521948465128642, 'disgust': 0.019448483228448298, 'negative': 0.05809634711096777, 'valid_tweet_count': 1133.0}\n",
      "Calculating... RaeRealtor.csv\n",
      "0\n",
      "{'sadness': 0.01469731781303289, 'trust': 0.04278993977831351, 'anticipation': 0.03435498627455386, 'negative': 0.026863274234655544, 'anger': 0.013034377676332237, 'fear': 0.010651393834160496, 'joy': 0.038916656734593755, 'surprise': 0.01689828973383239, 'disgust': 0.0071203695955502945, 'positive': 0.07041802493674015, 'valid_tweet_count': 568.0}\n",
      "Calculating... LsfarmLw.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "{'positive': 0.09544625250153096, 'sadness': 0.044999952927187455, 'trust': 0.06125845913099482, 'anticipation': 0.053319579269651377, 'negative': 0.07710255536395007, 'anger': 0.04190534488475107, 'fear': 0.037389282518959274, 'joy': 0.055599519624084326, 'surprise': 0.038701364981582026, 'disgust': 0.03231406561328428, 'valid_tweet_count': 4360.0}\n",
      "Calculating... frantny.csv\n",
      "0\n",
      "{'positive': 0.1297230479540107, 'sadness': 0.021700810033558986, 'trust': 0.0756438442114129, 'anticipation': 0.06284912179186578, 'negative': 0.054449281994760915, 'anger': 0.02574257871933393, 'fear': 0.027775320946779578, 'joy': 0.07138375810618199, 'surprise': 0.037735733101214496, 'disgust': 0.01755903436643475, 'valid_tweet_count': 186.0}\n",
      "Calculating... aliens2018.csv\n",
      "0\n",
      "{'positive': 0.059602595684605665, 'anticipation': 0.025698441002916215, 'anger': 0.01904345236589936, 'fear': 0.01443713382332137, 'joy': 0.032165244040327515, 'surprise': 0.02164757654922629, 'disgust': 0.015007691162420182, 'sadness': 0.021780514225897562, 'negative': 0.040250175712597695, 'trust': 0.04082524395758608, 'valid_tweet_count': 788.0}\n",
      "Calculating... DameKathy.csv\n",
      "0\n",
      "1000\n",
      "{'sadness': 0.035010574100226684, 'negative': 0.08043411428206589, 'anger': 0.03663603277062018, 'fear': 0.041911867033191066, 'surprise': 0.029807367522922727, 'disgust': 0.02936036271660193, 'positive': 0.09411161407665201, 'joy': 0.0441923369779293, 'anticipation': 0.04893543066479834, 'trust': 0.07392559270666112, 'valid_tweet_count': 1604.0}\n",
      "Calculating... mmillerjunior.csv\n",
      "0\n",
      "{'positive': 0.0769490793446125, 'trust': 0.04490187094251474, 'anticipation': 0.040714968424430065, 'joy': 0.038692530996163835, 'surprise': 0.01850837665274013, 'sadness': 0.021016395119472762, 'negative': 0.04692903129368072, 'anger': 0.028498992815046337, 'fear': 0.022534131095248607, 'disgust': 0.020117140330967936, 'valid_tweet_count': 753.0}\n",
      "Calculating... CharlieLance.csv\n",
      "0\n",
      "1000\n",
      "{'positive': 0.06538683627658619, 'sadness': 0.024080602363919745, 'trust': 0.0399486562636054, 'anticipation': 0.03182832948438043, 'negative': 0.056258227234046755, 'anger': 0.027561648167879416, 'fear': 0.03525615199114898, 'joy': 0.026733814615872417, 'surprise': 0.013622904916315513, 'disgust': 0.015982108489493645, 'valid_tweet_count': 1626.0}\n",
      "Calculating... Lucky_Mango.csv\n",
      "0\n",
      "{'positive': 0.12916446696934503, 'sadness': 0.014523281596452327, 'trust': 0.07865985640375885, 'anticipation': 0.09867094287825998, 'negative': 0.03689552317601099, 'anger': 0.010075493612078977, 'fear': 0.021646341463414633, 'joy': 0.10303690212226799, 'surprise': 0.03654511139267237, 'valid_tweet_count': 82.0, 'disgust': 0.0}\n",
      "Calculating... ChargerSix.csv\n",
      "0\n",
      "{'sadness': 0.014012184960564314, 'negative': 0.03577017300426663, 'anger': 0.0194090103573897, 'fear': 0.015727537768354092, 'joy': 0.018828311642737176, 'surprise': 0.017022297430460694, 'disgust': 0.008652707836381304, 'positive': 0.05394975993812871, 'trust': 0.036418915566052666, 'anticipation': 0.034672800620479456, 'valid_tweet_count': 245.0}\n",
      "Calculating... JerryNoland007.csv\n",
      "0\n",
      "{'sadness': 0.02694112835611791, 'trust': 0.09975817893795076, 'anticipation': 0.057348051838962605, 'negative': 0.06887863920030174, 'anger': 0.02972433366024676, 'fear': 0.042502043282538635, 'joy': 0.07811995933768981, 'surprise': 0.030950391561400163, 'disgust': 0.028589320214595607, 'positive': 0.11849042398716912, 'valid_tweet_count': 940.0}\n",
      "Calculating... CyberGopher.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "{'anger': 0.012929668796721926, 'sadness': 0.009384888448617205, 'positive': 0.07991486628414603, 'anticipation': 0.03333005526360463, 'fear': 0.014735352193282144, 'joy': 0.03858777869397685, 'surprise': 0.015787827973605076, 'trust': 0.04381976094393443, 'disgust': 0.0032665161039949274, 'negative': 0.021563528695524022, 'valid_tweet_count': 3575.0}\n",
      "Calculating... mb_hatch.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "{'sadness': 0.035937618815034614, 'negative': 0.09013339658709561, 'anger': 0.04145956844567348, 'fear': 0.04090510677549211, 'surprise': 0.023989459795029772, 'disgust': 0.03222855678485842, 'anticipation': 0.034371607458549475, 'positive': 0.08349317962732333, 'joy': 0.02883682193688545, 'trust': 0.06107201316788051, 'valid_tweet_count': 3960.0}\n",
      "Calculating... NickBreinerCPP.csv\n",
      "0\n",
      "{'sadness': 0.012363017702575054, 'anger': 0.00974310631505803, 'fear': 0.029870961011822343, 'surprise': 0.017122558899024143, 'disgust': 0.005795482729633214, 'positive': 0.10947703787971108, 'joy': 0.03675370139477363, 'anticipation': 0.03906190311040291, 'trust': 0.07898323362664725, 'negative': 0.028655365693348894, 'valid_tweet_count': 284.0}\n",
      "Calculating... jackeva53658017.csv\n",
      "0\n",
      "{'positive': 0.11637358391577905, 'sadness': 0.022398045239601216, 'negative': 0.056826849094401284, 'anger': 0.029886151610410073, 'fear': 0.05778109198412805, 'joy': 0.07250587930329268, 'surprise': 0.014727996461742592, 'disgust': 0.028846646185355863, 'trust': 0.08073383957609463, 'anticipation': 0.05831744087886103, 'valid_tweet_count': 62.0}\n",
      "Calculating... DavidMuirJr.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "{'sadness': 0.012850090150060558, 'anticipation': 0.04438588630174658, 'negative': 0.025729524000849862, 'anger': 0.011761845784097079, 'disgust': 0.007219179694162509, 'positive': 0.1016731377037806, 'joy': 0.04018414499217867, 'surprise': 0.01249466805264525, 'trust': 0.060793076580929105, 'fear': 0.017791558526594926, 'valid_tweet_count': 6672.0}\n",
      "Calculating... kody_kirk.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "{'positive': 0.0848164275592362, 'sadness': 0.02824777333805597, 'trust': 0.05837569120264702, 'negative': 0.05282503509751756, 'anger': 0.025369288573408994, 'fear': 0.02791243111451902, 'joy': 0.047389034511893954, 'surprise': 0.025587297837782807, 'disgust': 0.019570730237546644, 'anticipation': 0.04997938504377776, 'valid_tweet_count': 6736.0}\n",
      "Calculating... JustmeRobW.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "{'positive': 0.055952155777891914, 'sadness': 0.01808231737272568, 'trust': 0.035990458070586845, 'anticipation': 0.026226204802087597, 'negative': 0.051384828041673616, 'anger': 0.022099484560461232, 'fear': 0.020534540725694553, 'joy': 0.027244100304562157, 'surprise': 0.02205424397863597, 'disgust': 0.017536098572514227, 'valid_tweet_count': 19430.0}\n",
      "Calculating... TrueBennett.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "{'sadness': 0.04102022899302658, 'negative': 0.08257260258789254, 'fear': 0.053023226045596776, 'joy': 0.03270677695639444, 'surprise': 0.022376466316874066, 'disgust': 0.03046985576168943, 'anger': 0.040441067454754294, 'positive': 0.08344561006390674, 'anticipation': 0.04097554808530656, 'trust': 0.06068213852816573, 'valid_tweet_count': 9861.0}\n",
      "Calculating... WesleyTSmith3.csv\n",
      "0\n",
      "{'positive': 0.04525923093768346, 'disgust': 0.004202589536788109, 'joy': 0.014728248944551332, 'trust': 0.03845087026143817, 'anticipation': 0.018177549481781782, 'fear': 0.01265941658448434, 'surprise': 0.008628614093934549, 'anger': 0.006029121214066055, 'sadness': 0.00871095319410012, 'negative': 0.019732083590138852, 'valid_tweet_count': 67.0}\n",
      "Calculating... Zombie_Mel_.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "{'positive': 0.09624252621346115, 'sadness': 0.028225809800728616, 'trust': 0.049692112335934874, 'anticipation': 0.056246123070247976, 'negative': 0.055436767332783195, 'anger': 0.027431450511135463, 'fear': 0.02602469497937792, 'joy': 0.06479300083510575, 'surprise': 0.027468816902866625, 'disgust': 0.02749022091898589, 'valid_tweet_count': 4786.0}\n",
      "Calculating... dorknrok22.csv\n",
      "0\n",
      "{'positive': 0.11580190921521555, 'sadness': 0.03924393420705361, 'trust': 0.07685586354828132, 'negative': 0.0747667790406027, 'anger': 0.043832030935827375, 'fear': 0.04288238255035889, 'joy': 0.06301983599832481, 'surprise': 0.029664869347020763, 'disgust': 0.02700353228011919, 'anticipation': 0.07533487489252695, 'valid_tweet_count': 106.0}\n",
      "Calculating... ericlarson171.csv\n",
      "0\n",
      "{'sadness': 0.022951875863775187, 'trust': 0.05310039110278344, 'anticipation': 0.028292859453146538, 'negative': 0.1077812182154807, 'anger': 0.03750927937374786, 'fear': 0.031186552393126146, 'surprise': 0.015898763649959822, 'disgust': 0.038867104164587, 'positive': 0.07151115630780701, 'joy': 0.028112660863857032, 'valid_tweet_count': 165.0}\n",
      "Calculating... andrewrkirsch.csv\n",
      "0\n",
      "{'sadness': 0.05378501668677456, 'trust': 0.0699221370929996, 'negative': 0.09270127824037704, 'anger': 0.05576195841764364, 'fear': 0.05228878293853422, 'joy': 0.04380497571147229, 'surprise': 0.030035461060345152, 'disgust': 0.03941145040693716, 'positive': 0.10474684773561689, 'anticipation': 0.05798056228769069, 'valid_tweet_count': 84.0}\n",
      "Calculating... k_kamar.csv\n",
      "0\n",
      "{'anger': 0.012042499983676454, 'positive': 0.10029874348878873, 'sadness': 0.016724713195301426, 'trust': 0.05613015189938265, 'anticipation': 0.03670245541286265, 'negative': 0.039652439064203765, 'fear': 0.0405876149993797, 'joy': 0.0264540436938627, 'surprise': 0.016378392848981082, 'disgust': 0.012797202797202797, 'valid_tweet_count': 130.0}\n",
      "Calculating... hdwrench99.csv\n",
      "0\n",
      "{'sadness': 0.025229096374072127, 'trust': 0.05325142182909165, 'anticipation': 0.032795788235994855, 'negative': 0.05039919265549225, 'anger': 0.02839371697206194, 'fear': 0.026587017342253865, 'disgust': 0.01887284165762665, 'positive': 0.07200765722484573, 'joy': 0.04069105785717662, 'surprise': 0.01812419690060947, 'valid_tweet_count': 161.0}\n",
      "Calculating... StevenBeynon.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "{'anger': 0.03414622449904163, 'sadness': 0.02756410519731203, 'fear': 0.04199908404975198, 'negative': 0.06368327176758135, 'trust': 0.05282727189458585, 'positive': 0.07531908222960902, 'anticipation': 0.03994528001875857, 'joy': 0.029294514093387215, 'surprise': 0.019974003501328077, 'disgust': 0.020966239583208736, 'valid_tweet_count': 40775.0}\n",
      "Calculating... ChiefsDanny58.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "{'sadness': 0.030150152055561465, 'anticipation': 0.03731417058063715, 'negative': 0.06756408081074758, 'anger': 0.035903801185155994, 'fear': 0.031321361466581064, 'surprise': 0.020825638620716957, 'disgust': 0.024782533488119235, 'positive': 0.06658341544965657, 'joy': 0.03370750694703032, 'trust': 0.0496816963435315, 'valid_tweet_count': 2040.0}\n",
      "Calculating... ServiceK9s4Vets.csv\n",
      "0\n",
      "{'positive': 0.08631616086534065, 'sadness': 0.013872277676850961, 'trust': 0.0630420940602357, 'anticipation': 0.026775441161885783, 'negative': 0.04152884725619322, 'anger': 0.015837961654944596, 'fear': 0.0337108437344048, 'joy': 0.023406322137911034, 'surprise': 0.01143202644793131, 'disgust': 0.00455012258680019, 'valid_tweet_count': 482.0}\n",
      "Calculating... MattDrikas.csv\n",
      "0\n",
      "{'sadness': 0.021953688064195266, 'fear': 0.03223794745157164, 'joy': 0.04646473173058404, 'surprise': 0.024421637984883428, 'disgust': 0.01748539687025819, 'positive': 0.09897166029285583, 'anticipation': 0.050596277768129166, 'trust': 0.07076114749915999, 'anger': 0.024745312373912177, 'negative': 0.04948251368408419, 'valid_tweet_count': 360.0}\n",
      "Calculating... CarolinePestel.csv\n",
      "0\n",
      "{'positive': 0.09118718199363358, 'trust': 0.04431541576702865, 'anticipation': 0.04551466454692261, 'joy': 0.0530926600281439, 'surprise': 0.0237269719527784, 'sadness': 0.015047712144486336, 'negative': 0.029031327095843218, 'anger': 0.008008658008658008, 'fear': 0.013269239720852621, 'disgust': 0.012637899734673927, 'valid_tweet_count': 155.0}\n",
      "Calculating... marccgonzo.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "{'sadness': 0.026546557077196182, 'trust': 0.05698118763919297, 'negative': 0.05725834934029462, 'anger': 0.0263310198031219, 'fear': 0.03164626521585738, 'surprise': 0.02593329680013886, 'disgust': 0.02089343545419873, 'positive': 0.0880924268687011, 'joy': 0.04524276188306296, 'anticipation': 0.04340854281166046, 'valid_tweet_count': 2026.0}\n",
      "Calculating... fobosays.csv\n",
      "0\n",
      "{'sadness': 0.03226007204897147, 'negative': 0.055100409025930844, 'anger': 0.03426848030737974, 'fear': 0.02863966099260217, 'surprise': 0.019303613053613052, 'disgust': 0.010589952952381795, 'positive': 0.11258652488491197, 'joy': 0.07054463606882963, 'anticipation': 0.05259905864744575, 'trust': 0.07207536121198359, 'valid_tweet_count': 52.0}\n",
      "Calculating... JMFGoose.csv\n",
      "0\n",
      "1000\n",
      "{'sadness': 0.027305126647455418, 'trust': 0.05373854332945156, 'anticipation': 0.048040665180054065, 'negative': 0.047224282636192626, 'anger': 0.020039535130924706, 'fear': 0.03003528317388048, 'joy': 0.04969531994564576, 'surprise': 0.024318104084504022, 'disgust': 0.0176677653461026, 'positive': 0.08958220798020407, 'valid_tweet_count': 1518.0}\n",
      "Calculating... macleod842.csv\n",
      "0\n",
      "1000\n",
      "{'sadness': 0.026569942894943147, 'trust': 0.060313279240467345, 'anticipation': 0.0551331303868122, 'negative': 0.04845382132376801, 'anger': 0.02582634309074948, 'fear': 0.031000276672078973, 'joy': 0.051954443847378656, 'surprise': 0.029877552374593722, 'disgust': 0.02031394842540946, 'positive': 0.1007044806846227, 'valid_tweet_count': 1607.0}\n",
      "Calculating... GeneEdwardsSCMO.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "{'positive': 0.14265396235239025, 'sadness': 0.008833584628679352, 'trust': 0.10853689818582334, 'anticipation': 0.07144972543670199, 'negative': 0.017520578517489824, 'anger': 0.007427375326552001, 'fear': 0.00979197500275174, 'joy': 0.0658811479850262, 'surprise': 0.013684240370231485, 'disgust': 0.003892706863535914, 'valid_tweet_count': 8095.0}\n",
      "Calculating... realtoyaboyd.csv\n",
      "0\n",
      "1000\n",
      "{'positive': 0.1089947835175047, 'sadness': 0.01630213761807879, 'trust': 0.06684508559182553, 'anticipation': 0.03782630481453445, 'negative': 0.03967341841754681, 'anger': 0.020886729716970805, 'fear': 0.014221788228894245, 'joy': 0.059109055817611375, 'surprise': 0.01417640776631216, 'disgust': 0.017434375235053094, 'valid_tweet_count': 1509.0}\n",
      "Calculating... thedrillsgt.csv\n",
      "0\n",
      "{'sadness': 0.01592944994504448, 'trust': 0.06927752847830834, 'negative': 0.04889718407147605, 'anger': 0.022351400314363265, 'fear': 0.03600378576012103, 'joy': 0.06520420125683292, 'surprise': 0.025556086320046877, 'disgust': 0.01205041871708538, 'anticipation': 0.06082230743049465, 'positive': 0.11690097942419951, 'valid_tweet_count': 810.0}\n",
      "Calculating... ChattJazz.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "{'fear': 0.05462195167351601, 'joy': 0.03578663630766211, 'surprise': 0.04475633489611155, 'positive': 0.0963571739287017, 'trust': 0.06966248173874204, 'anger': 0.05333987767363579, 'sadness': 0.04383429139739616, 'disgust': 0.03764121772390904, 'negative': 0.10186458648200679, 'anticipation': 0.04093956721592716, 'valid_tweet_count': 13583.0}\n",
      "Calculating... TheSchlewis.csv\n",
      "0\n",
      "1000\n",
      "{'trust': 0.06930113684926348, 'anticipation': 0.049280788385889195, 'anger': 0.017885510498542593, 'fear': 0.022913996330269398, 'joy': 0.036412350578439875, 'disgust': 0.013809104237640424, 'positive': 0.09132236836536864, 'sadness': 0.025579656902428458, 'negative': 0.041804142801144646, 'surprise': 0.021116277964669708, 'valid_tweet_count': 1463.0}\n",
      "Calculating... AndreaBillingsl.csv\n",
      "0\n",
      "1000\n",
      "{'positive': 0.08466347364499392, 'sadness': 0.027853573022047606, 'trust': 0.06283187122110134, 'anticipation': 0.03613046074672349, 'negative': 0.05900774659766783, 'anger': 0.0316226808226352, 'fear': 0.03432187485775705, 'joy': 0.03326144921888415, 'surprise': 0.01809852152225604, 'disgust': 0.02386991790461334, 'valid_tweet_count': 1899.0}\n",
      "Calculating... jfrie1424.csv\n",
      "0\n",
      "1000\n",
      "{'positive': 0.0749967856722597, 'sadness': 0.013159974020035598, 'trust': 0.04655715190336955, 'anticipation': 0.03729174644891716, 'negative': 0.04379724444543267, 'anger': 0.018460772492529025, 'fear': 0.023524900858758073, 'joy': 0.041589177481804476, 'surprise': 0.015899344844434334, 'disgust': 0.013174683341547795, 'valid_tweet_count': 1834.0}\n",
      "Calculating... BDALE1.csv\n",
      "0\n",
      "{'positive': 0.08176005315487161, 'sadness': 0.02039034376495676, 'trust': 0.05397277794418095, 'anticipation': 0.05717247970384688, 'negative': 0.051037875999176294, 'anger': 0.031149184051660818, 'fear': 0.028024406004282163, 'joy': 0.04349126660312906, 'surprise': 0.03200126602644116, 'disgust': 0.012728188076485285, 'valid_tweet_count': 703.0}\n",
      "Calculating... RodReyesMota.csv\n",
      "0\n",
      "{'positive': 0.09256816830829989, 'sadness': 0.008454335016835016, 'trust': 0.061941669441669435, 'anticipation': 0.05387635512635514, 'negative': 0.015796749546749547, 'anger': 0.008065268065268064, 'fear': 0.014924242424242423, 'joy': 0.04788802632552632, 'surprise': 0.02265577015577016, 'disgust': 0.005757575757575757, 'valid_tweet_count': 120.0}\n",
      "Calculating... gachervenak.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "{'sadness': 0.02157948406469526, 'anticipation': 0.029675449003770286, 'negative': 0.05506132497382453, 'anger': 0.03055901674132246, 'fear': 0.032288186974243634, 'surprise': 0.016772540942096466, 'disgust': 0.017537675976613792, 'positive': 0.04953314943594408, 'joy': 0.031181775124793337, 'trust': 0.02698922196869917, 'valid_tweet_count': 4970.0}\n",
      "Calculating... bolingerj2004.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "{'sadness': 0.02487291348039891, 'trust': 0.06852368824431601, 'anticipation': 0.045457313307255685, 'negative': 0.05809242474931467, 'anger': 0.0288518847006299, 'fear': 0.034723931493155655, 'joy': 0.04450028530225426, 'surprise': 0.024267771966147267, 'disgust': 0.014066205076070112, 'positive': 0.10362370959661861, 'valid_tweet_count': 2537.0}\n",
      "Calculating... WarScar666.csv\n",
      "0\n",
      "1000\n",
      "{'positive': 0.06538251274144864, 'sadness': 0.024501437524119662, 'trust': 0.04329804162170556, 'anticipation': 0.030330402828117248, 'negative': 0.060837288169395744, 'anger': 0.02890071732022081, 'fear': 0.031261629992745864, 'joy': 0.028375476882945876, 'surprise': 0.023774036980385518, 'disgust': 0.019670905404486846, 'valid_tweet_count': 1890.0}\n",
      "Calculating... tifflovesoils.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "{'sadness': 0.03532454114917565, 'trust': 0.05709864432631461, 'anticipation': 0.0378341251673819, 'negative': 0.08038635383122221, 'anger': 0.038037040117660445, 'fear': 0.046387451273589356, 'joy': 0.040730459195583026, 'surprise': 0.033968888874726856, 'disgust': 0.02890548671889382, 'positive': 0.08298231135920432, 'valid_tweet_count': 21827.0}\n",
      "Calculating... jeffisbluenow.csv\n",
      "0\n",
      "1000\n",
      "{'positive': 0.08605729390561538, 'sadness': 0.02775252264174535, 'trust': 0.057042670704695174, 'anticipation': 0.041202463064906096, 'negative': 0.06881611246393524, 'anger': 0.03487497466412701, 'fear': 0.03451154786971981, 'joy': 0.034170271848404044, 'surprise': 0.029036446624594932, 'disgust': 0.028022463980459326, 'valid_tweet_count': 1686.0}\n",
      "Calculating... junebug1387.csv\n",
      "0\n",
      "1000\n",
      "{'sadness': 0.021372273964466358, 'anticipation': 0.033244774339449404, 'negative': 0.0421613760222772, 'anger': 0.02106276258578381, 'fear': 0.025537912297067554, 'surprise': 0.019105826307409653, 'disgust': 0.018185692135816254, 'positive': 0.08452758599013908, 'joy': 0.04536957161101223, 'trust': 0.04749761985456642, 'valid_tweet_count': 1503.0}\n",
      "Calculating... DanielH_DC.csv\n",
      "0\n",
      "{'sadness': 0.025126392899567338, 'trust': 0.0625901564940053, 'anticipation': 0.058985898343091064, 'negative': 0.043297635612894826, 'anger': 0.025155976711784645, 'fear': 0.015722210228504088, 'joy': 0.033093813008666886, 'surprise': 0.020225764017167438, 'disgust': 0.015337427280549567, 'positive': 0.10302157957184037, 'valid_tweet_count': 247.0}\n",
      "Calculating... MsSaltyGiggles.csv\n",
      "0\n",
      "1000\n",
      "{'sadness': 0.023759073418801478, 'trust': 0.03240005232491588, 'negative': 0.046353505058215796, 'anger': 0.023546968151021915, 'fear': 0.022705094547718126, 'surprise': 0.017607875861183835, 'disgust': 0.01962595985240626, 'positive': 0.06084089231718926, 'joy': 0.033107320162232654, 'anticipation': 0.03146462791818826, 'valid_tweet_count': 1633.0}\n",
      "Calculating... brianknoch.csv\n",
      "0\n",
      "{'sadness': 0.03691263073692772, 'anticipation': 0.053774789949130194, 'joy': 0.05785298283186851, 'surprise': 0.027278138469942932, 'disgust': 0.03894349955361487, 'trust': 0.06999589645823592, 'anger': 0.041531277435955104, 'negative': 0.08964660650973533, 'fear': 0.05266239024394146, 'positive': 0.09881986930933863, 'valid_tweet_count': 600.0}\n",
      "Calculating... jeff_schlapp.csv\n",
      "0\n",
      "1000\n",
      "{'positive': 0.12216211337434865, 'sadness': 0.019701041303601084, 'trust': 0.08586732709733239, 'anticipation': 0.05011175540908885, 'negative': 0.04840408338816433, 'anger': 0.021439593116327305, 'fear': 0.025767596886410563, 'joy': 0.07229169215133577, 'surprise': 0.018707840890606255, 'disgust': 0.01569975495438395, 'valid_tweet_count': 1332.0}\n",
      "Calculating... Adrienne_Acts.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "{'surprise': 0.02228867279139808, 'disgust': 0.020284470769867606, 'trust': 0.04786655596863358, 'positive': 0.08574596740370288, 'anger': 0.025688129889887223, 'fear': 0.02928416230648838, 'sadness': 0.026661201909082565, 'negative': 0.05236676609870994, 'joy': 0.04784260161788103, 'anticipation': 0.04911262079817241, 'valid_tweet_count': 3362.0}\n",
      "Calculating... TheRealFitzNYC.csv\n",
      "0\n",
      "{'anger': 0.015443360289795137, 'fear': 0.02414284277522157, 'disgust': 0.006903017456393182, 'sadness': 0.014128562652064997, 'negative': 0.0422038537299944, 'positive': 0.10991219489695983, 'joy': 0.030759343599124873, 'surprise': 0.020260017497197854, 'trust': 0.07519489457143463, 'anticipation': 0.044371650514412095, 'valid_tweet_count': 389.0}\n",
      "Calculating... leftwingcatmom.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "{'sadness': 0.013030781120364486, 'negative': 0.026647951308545186, 'anger': 0.016113103038878866, 'fear': 0.014537454598662524, 'disgust': 0.013778843873913475, 'positive': 0.07064446984095057, 'trust': 0.0345863855222578, 'anticipation': 0.023782950751381718, 'joy': 0.04434059661246274, 'surprise': 0.013050868879851782, 'valid_tweet_count': 6560.0}\n",
      "Calculating... hparichart.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "{'positive': 0.0029425756287511334, 'sadness': 0.000593912559295357, 'trust': 0.0020760752315759283, 'anticipation': 0.001598953920862189, 'negative': 0.0019235896953288258, 'anger': 0.0007868339390078521, 'fear': 0.0014320557329337554, 'joy': 0.001606868000448241, 'surprise': 0.0008070084452409595, 'disgust': 0.0011304375759716022, 'valid_tweet_count': 4232.0}\n",
      "Calculating... LynnJauregui.csv\n",
      "0\n",
      "{'sadness': 0.02953186442758358, 'negative': 0.05862731537932438, 'anger': 0.02598899870786161, 'fear': 0.031618015940362725, 'disgust': 0.027464850530935652, 'anticipation': 0.04067364974171897, 'positive': 0.09183020911900758, 'surprise': 0.0348401299063467, 'joy': 0.03371047079631599, 'trust': 0.055334149959367966, 'valid_tweet_count': 756.0}\n",
      "Calculating... StephanieTA_BAE.csv\n",
      "0\n",
      "{'positive': 0.1466969224513552, 'sadness': 0.008986088593951521, 'trust': 0.07615639987204326, 'anticipation': 0.061155043223567476, 'negative': 0.026439659472489205, 'anger': 0.013773843702766908, 'fear': 0.021151059687845822, 'joy': 0.05601893196483127, 'surprise': 0.021337540026475, 'disgust': 0.0037426998514839224, 'valid_tweet_count': 765.0}\n",
      "Calculating... EcyorRoycex.csv\n",
      "0\n",
      "{'positive': 0.024755534064044696, 'sadness': 0.008611955420466059, 'trust': 0.006501182033096926, 'anticipation': 0.0096757852077001, 'negative': 0.02912867274569402, 'anger': 0.025075987841945296, 'fear': 0.018996960486322188, 'joy': 0.017139479905437353, 'surprise': 0.004875886524822694, 'disgust': 0.010638297872340425, 'valid_tweet_count': 188.0}\n",
      "Calculating... iamdetashia.csv\n",
      "0\n",
      "1000\n",
      "{'positive': 0.18121763094016502, 'sadness': 0.012976644594248556, 'trust': 0.11240971979918613, 'anticipation': 0.0816859262479773, 'negative': 0.021673716932145863, 'anger': 0.008872481997944364, 'fear': 0.027248513284253203, 'joy': 0.10090735859493775, 'surprise': 0.030230908331700113, 'disgust': 0.00422987090776848, 'valid_tweet_count': 1484.0}\n",
      "Calculating... 1badmonkey.csv\n",
      "0\n",
      "{'sadness': 0.024867041685587593, 'trust': 0.07348951334381605, 'anticipation': 0.06011785002551425, 'negative': 0.0628354396486991, 'anger': 0.04327324147840186, 'fear': 0.039267774421019024, 'joy': 0.054889971794181064, 'surprise': 0.030976864898498862, 'disgust': 0.036237460956533366, 'positive': 0.13195844373529572, 'valid_tweet_count': 192.0}\n",
      "Calculating... WilliamNickerso.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "{'sadness': 0.01646940582437531, 'surprise': 0.014106991399912925, 'disgust': 0.015973995297861227, 'positive': 0.05944544749573271, 'trust': 0.04427778213684076, 'joy': 0.024058222327622527, 'anticipation': 0.025243426907029208, 'anger': 0.02284024930372795, 'fear': 0.022788248879351485, 'negative': 0.05545248093212532, 'valid_tweet_count': 2289.0}\n",
      "Calculating... MeVictorD.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "{'anger': 0.029481660188617406, 'sadness': 0.02894779456369477, 'disgust': 0.01646209061182636, 'negative': 0.05607853117457733, 'surprise': 0.02534030600033436, 'positive': 0.08900401683085082, 'trust': 0.057486197440127326, 'anticipation': 0.040765030817194715, 'fear': 0.03839178623147343, 'joy': 0.045687934567715624, 'valid_tweet_count': 11259.0}\n",
      "Calculating... JayskerHater.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "{'positive': 0.07761390048993339, 'sadness': 0.02839452224377271, 'trust': 0.05082127804192461, 'anticipation': 0.0476530979371536, 'anger': 0.033803684938105816, 'fear': 0.029904655502867146, 'joy': 0.04098841526696518, 'surprise': 0.02438592497301237, 'disgust': 0.024677811668151448, 'negative': 0.058432184018606184, 'valid_tweet_count': 4867.0}\n",
      "Calculating... OsbertUSMCVET.csv\n",
      "0\n",
      "1000\n",
      "{'trust': 0.07816644916693533, 'joy': 0.03591174355522483, 'surprise': 0.02362732218800323, 'disgust': 0.024801621207753942, 'anger': 0.03971790414951979, 'negative': 0.0807383564399527, 'fear': 0.0569277536813283, 'sadness': 0.03137242578703015, 'anticipation': 0.0460439388683574, 'positive': 0.10421596237856733, 'valid_tweet_count': 1412.0}\n",
      "Calculating... Sarango.csv\n",
      "0\n",
      "{'sadness': 0.009390586588317118, 'trust': 0.04223339882006899, 'anticipation': 0.02328365951686679, 'negative': 0.007131379627140684, 'anger': 0.005450273390797716, 'fear': 0.011991775452059775, 'joy': 0.015375356930071936, 'surprise': 0.018852511052850178, 'disgust': 0.0020229216459815126, 'positive': 0.06906099747824046, 'valid_tweet_count': 902.0}\n",
      "Calculating... thejoecardamone.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "{'sadness': 0.013665544954354287, 'anticipation': 0.042046653778601145, 'negative': 0.03433761560806755, 'anger': 0.01874128660287717, 'fear': 0.015916044358820495, 'surprise': 0.017139026881590733, 'disgust': 0.016040251775163467, 'positive': 0.0942238238904633, 'joy': 0.04878856783357831, 'trust': 0.054500522837720236, 'valid_tweet_count': 2282.0}\n",
      "Calculating... sordellini_ed.csv\n",
      "0\n",
      "{'sadness': 0.017261995542037244, 'trust': 0.07071701806365989, 'anticipation': 0.06470071511886616, 'negative': 0.03666910162370236, 'anger': 0.0162284633720032, 'fear': 0.022763342217682284, 'joy': 0.08618216880772282, 'surprise': 0.039802487845323864, 'disgust': 0.013173447048023462, 'positive': 0.105748132526089, 'valid_tweet_count': 677.0}\n",
      "Calculating... InSpaceXItrust.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "{'trust': 0.04156776500247513, 'joy': 0.033568130764633726, 'anticipation': 0.04573529338580758, 'disgust': 0.013561098911747598, 'negative': 0.03659856930292831, 'fear': 0.022217242177412687, 'sadness': 0.01723243277558589, 'anger': 0.019728599729086287, 'surprise': 0.019562045037789133, 'positive': 0.07820842820786206, 'valid_tweet_count': 4210.0}\n",
      "Calculating... LHQ_HUNK.csv\n",
      "0\n",
      "{'positive': 0.014079547409918833, 'sadness': 0.0014770057066129572, 'trust': 0.008382440772702013, 'anticipation': 0.007335194079462784, 'negative': 0.005613101232436579, 'anger': 0.0019349733851244423, 'fear': 0.005650308461753281, 'joy': 0.005206004034864885, 'surprise': 0.0034572078396496383, 'disgust': 0.002388145590562509, 'valid_tweet_count': 331.0}\n",
      "Calculating... twittylity.csv\n",
      "0\n",
      "{'sadness': 0.03869303237558429, 'disgust': 0.0220724806080189, 'positive': 0.09626853071193305, 'anger': 0.02250785309312891, 'negative': 0.06685310118498898, 'fear': 0.048838960514611826, 'trust': 0.06463906849009089, 'anticipation': 0.04072093251094028, 'joy': 0.039391068535235496, 'surprise': 0.029857189732099138, 'valid_tweet_count': 161.0}\n",
      "Calculating... geart66.csv\n",
      "0\n",
      "{'positive': 0.05223170965625344, 'trust': 0.03439341004878967, 'anticipation': 0.022119107814381058, 'anger': 0.02135924782328914, 'joy': 0.02543320043643723, 'surprise': 0.010302660165433132, 'disgust': 0.013832303727196113, 'fear': 0.034033688550722856, 'sadness': 0.020226962628648933, 'negative': 0.042559211293235616, 'valid_tweet_count': 752.0}\n",
      "Calculating... CNNValentine.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "{'positive': 0.08352086764112261, 'sadness': 0.02340154471491951, 'trust': 0.06102833298297613, 'anticipation': 0.03771542142612164, 'negative': 0.052521241513543114, 'anger': 0.025729451054672413, 'fear': 0.033158114500764, 'joy': 0.03709280646673627, 'surprise': 0.024977222160667358, 'disgust': 0.01857844122618076, 'valid_tweet_count': 3620.0}\n",
      "Calculating... RvaUnicorn.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "{'positive': 0.07772395024317254, 'sadness': 0.013439853510673812, 'trust': 0.04463742709137935, 'anticipation': 0.03524872064856987, 'negative': 0.028199525605438903, 'anger': 0.011746081752482037, 'fear': 0.01753870109353272, 'joy': 0.04104379528842138, 'surprise': 0.014620954739118047, 'disgust': 0.008705416411058653, 'valid_tweet_count': 3217.0}\n",
      "Calculating... DestinysFreedom.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "{'positive': 0.09407621577352633, 'sadness': 0.0429134726573576, 'trust': 0.07484065993624005, 'anticipation': 0.04450238588959119, 'negative': 0.09999419839116908, 'anger': 0.05766243486950666, 'fear': 0.05634390275663528, 'joy': 0.04869087642265425, 'surprise': 0.03083366736550528, 'disgust': 0.051428566842772645, 'valid_tweet_count': 3586.0}\n",
      "Calculating... ThibodeauBob.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "{'sadness': 0.018520265024500937, 'trust': 0.0388416395355161, 'anticipation': 0.03614430483110905, 'negative': 0.040543579534136384, 'anger': 0.020036479315676335, 'fear': 0.026275061736911492, 'joy': 0.026868035772179843, 'surprise': 0.019717598789502137, 'disgust': 0.010340001018098476, 'positive': 0.06416794130573478, 'valid_tweet_count': 7901.0}\n",
      "Calculating... kaelinlocker.csv\n",
      "0\n",
      "{'sadness': 0.0271702719295887, 'negative': 0.05016586969022405, 'anger': 0.01821870694051145, 'fear': 0.051002587950095775, 'surprise': 0.02459680842033783, 'disgust': 0.004905730234677603, 'positive': 0.07381857314962134, 'joy': 0.03571393203746145, 'anticipation': 0.06624648322218654, 'trust': 0.06582451694127942, 'valid_tweet_count': 84.0}\n",
      "Calculating... johnpaulredmond.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "{'positive': 0.0770984279047945, 'sadness': 0.042201905913298844, 'trust': 0.0689527541038777, 'anticipation': 0.03534367660454519, 'negative': 0.10412391907856673, 'anger': 0.06091372269350273, 'fear': 0.058705384624452385, 'joy': 0.025766956306024838, 'surprise': 0.022268852912400917, 'disgust': 0.0400481783430483, 'valid_tweet_count': 6418.0}\n",
      "Calculating... usma6679.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "{'positive': 0.09646988088593313, 'sadness': 0.029638888555702618, 'trust': 0.06672386248455243, 'anticipation': 0.042819156815366216, 'negative': 0.10345019693360814, 'anger': 0.03013170400261204, 'fear': 0.03521127459740463, 'joy': 0.04123776074989275, 'surprise': 0.024014175254353867, 'disgust': 0.04472433550175956, 'valid_tweet_count': 2642.0}\n",
      "Calculating... Survance.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "{'positive': 0.04205545732507795, 'sadness': 0.014692371238898362, 'trust': 0.03160770165996114, 'anticipation': 0.017141409928944105, 'negative': 0.0357958620212764, 'anger': 0.017094654888530385, 'fear': 0.019916738146680293, 'joy': 0.0167387090156143, 'surprise': 0.01261309440667693, 'disgust': 0.012877767670426157, 'valid_tweet_count': 2881.0}\n",
      "Calculating... ColdBudCash.csv\n",
      "0\n",
      "{'positive': 0.11942863050051632, 'sadness': 0.03396773991407177, 'trust': 0.083161914770458, 'anticipation': 0.04620728473677852, 'negative': 0.07606104280329912, 'anger': 0.0400271958953407, 'fear': 0.042010128392956606, 'joy': 0.064649060640951, 'surprise': 0.032752806479334345, 'disgust': 0.03230123332675084, 'valid_tweet_count': 677.0}\n",
      "Calculating... EllisBaumer.csv\n",
      "0\n",
      "1000\n",
      "{'positive': 0.12461083744850131, 'sadness': 0.009722895634230351, 'trust': 0.0369157826047658, 'anticipation': 0.025142946333794186, 'anger': 0.009177962513802505, 'fear': 0.014014718385698085, 'joy': 0.02444067050573075, 'surprise': 0.01115084525472696, 'disgust': 0.00794483751699921, 'negative': 0.023933351844919785, 'valid_tweet_count': 1507.0}\n",
      "Calculating... BrandonScott361.csv\n",
      "0\n",
      "1000\n",
      "{'positive': 0.06180831697768429, 'sadness': 0.03229871661247638, 'trust': 0.043508018353741566, 'anticipation': 0.02691219946999036, 'anger': 0.048728918791259, 'joy': 0.01881874412411957, 'surprise': 0.023960217102538487, 'disgust': 0.019486220136804924, 'fear': 0.061416179335064616, 'negative': 0.07982903489618934, 'valid_tweet_count': 1080.0}\n",
      "Calculating... gijunknw.csv\n",
      "0\n",
      "{'positive': 0.13132653400069547, 'sadness': 0.010112791050115977, 'trust': 0.07040100741841906, 'anticipation': 0.07836349082126973, 'negative': 0.047306582994363834, 'anger': 0.009769045484713332, 'fear': 0.012185797024805512, 'joy': 0.0874413398365166, 'surprise': 0.020817117889688222, 'disgust': 0.006134952625921898, 'valid_tweet_count': 420.0}\n",
      "Calculating... PaulDSmith9.csv\n",
      "0\n",
      "{'positive': 0.08628340837726799, 'trust': 0.05876425470963339, 'anticipation': 0.03714731524861796, 'anger': 0.04645649111783723, 'joy': 0.034059891087052686, 'surprise': 0.028841720584148824, 'fear': 0.05623302025486372, 'sadness': 0.039920618406074374, 'disgust': 0.041071384988800495, 'negative': 0.09109076777176839, 'valid_tweet_count': 957.0}\n",
      "Calculating... BottleBreacher.csv\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n"
     ]
    }
   ],
   "source": [
    "for soldierCSVFile in soldierCSVs:\n",
    "    if soldierCSVFile == 'cleaned_vet_tweet_df.csv': continue\n",
    "    print('Calculating... ' + soldierCSVFile)\n",
    "    \n",
    "    tempDF = pd.read_csv(os.getcwd() + \"/data/soldiers/\" + soldierCSVFile, encoding='utf8')\n",
    "    tempDF.dropna(subset=['tweet'], inplace=True) # clear empty tweets\n",
    "    tempDF.drop(uselessColumns, axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    singleResult = {}\n",
    "    count = 0.0\n",
    "    for id, row in tempDF.iterrows():\n",
    "        emo = calEmoForTweet(row['tweet'])\n",
    "        count += 1\n",
    "        if (id % 1000 ) == 0: print(id)\n",
    "#         if (soldierCSVFile == 'cNikonphoto.csv'): print(id)\n",
    "        singleResult = dict(Counter(emo) + Counter(singleResult))\n",
    "    \n",
    "    singleResult['valid_tweet_count'] = count\n",
    "    \n",
    "    for key in lexicon.keys():\n",
    "        if key in singleResult:\n",
    "            singleResult[key] = singleResult[key] / count\n",
    "        else:\n",
    "            singleResult[key] = 0.0\n",
    "    \n",
    "    soldierEmoDict[soldierCSVFile] = singleResult\n",
    "    print(singleResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(soldierEmoDict, orient=\"index\").to_csv(\"soldierEmo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('TextAnalytics': pipenv)",
   "language": "python",
   "name": "python37764bittextanalyticspipenvec0a72c8bc7e410ea9ad476aba2b0271"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
