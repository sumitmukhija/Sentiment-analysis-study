{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.tokenize.casual import TweetTokenizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from twitter_preprocessor import TwitterPreprocessor\n",
    "import os\n",
    "import glob\n",
    "# from textblob import TextBlob\n",
    "# from textblob import Blobber\n",
    "# from textblob.sentiments import NaiveBayesAnalyzer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/cary/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/cary/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package sentiwordnet to\n",
      "[nltk_data]     /Users/cary/nltk_data...\n",
      "[nltk_data]   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/cary/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# preperation\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('sentiwordnet')\n",
    "nltk.download('stopwords')\n",
    "stopset = set(stopwords.words('english'))\n",
    "# blobSenti = Blobber(analyzer = NaiveBayesAnalyzer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where stores the total data\n",
    "soldierCalDict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file list\n",
    "soldierCSVs = []\n",
    "files = os.listdir(os.getcwd() + \"/data/civilians\")\n",
    "for file in files:\n",
    "     if not os.path.isdir(file) and file.endswith(\".csv\"):\n",
    "            soldierCSVs.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useless columns for analyzing\n",
    "uselessColumns = [\n",
    "    \"id\",\n",
    "    \"conversation_id\",\n",
    "    \"place\",\n",
    "    \"photos\",\n",
    "    \"video\",\n",
    "    \"near\",\n",
    "    \"geo\",\n",
    "    \"source\",\n",
    "    \"user_rt_id\",\n",
    "    \"user_rt\",\n",
    "    \"retweet_id\",\n",
    "    \"reply_to\",\n",
    "    \"retweet_date\",\n",
    "    \"translate\",\n",
    "    \"trans_src\",\n",
    "    \"trans_dest\",\n",
    "    \"link\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert pos from nltk.pos_tag to SentiWordNet\n",
    "# n - NOUN \n",
    "# v - VERB \n",
    "# a - ADJECTIVE \n",
    "# s - ADJECTIVE SATELLITE \n",
    "# r - ADVERB\n",
    "# ' ' - others\n",
    "# a list of nltk tags is here:\n",
    "# https://www.techrepublic.com/article/the-6-laws-every-cloud-architect-should-know-according-to-werner-vogels/\n",
    "def sentiWordNetPOSconvetor(pos):\n",
    "    newtag = ''\n",
    "    if pos.startswith('NN'):\n",
    "        newtag='n'\n",
    "    elif pos.startswith('JJ'):\n",
    "        newtag='a'\n",
    "    elif pos.startswith('V'):\n",
    "        newtag='v'\n",
    "    elif pos.startswith('R'):\n",
    "        newtag='r'\n",
    "    return newtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word: single word\n",
    "# pos: part of speech from nltk.pos_tag\n",
    "def calSentiForWord(word, pos):\n",
    "    \n",
    "    sentis = list(swn.senti_synsets(word, sentiWordNetPOSconvetor(pos)))\n",
    "    \n",
    "    if len(sentis) <= 0:\n",
    "        return 0, 0, 0\n",
    "    \n",
    "    # Getting average of all possible sentiments\n",
    "    positive = 0.0\n",
    "    negative = 0.0\n",
    "    objective = 0.0\n",
    "    count = 0.0\n",
    "    \n",
    "    for senti in sentis :\n",
    "        positive += senti.pos_score()\n",
    "        negative += senti.neg_score()\n",
    "        objective += senti.obj_score()\n",
    "        count += 1\n",
    "        \n",
    "    if count <= 0.1:\n",
    "        return 0, 0, 0\n",
    "    \n",
    "    positive /= count\n",
    "    negative /= count\n",
    "    objective /= count\n",
    "    \n",
    "    return positive, negative, objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calSentiForTweet(tweet):\n",
    "    tempTweet = tweet\n",
    "    tempTweetCleaned = TwitterPreprocessor(tempTweet).remove_urls().remove_mentions().remove_hashtags().remove_twitter_reserved_words().remove_single_letter_words().remove_numbers(preserve_years=True).remove_blank_spaces().text\n",
    "    if len(tempTweetCleaned) <= 0:\n",
    "        return 0, 0, 0, 0\n",
    "    # miss spelling\n",
    "#     tempTweetCleaned = str(blobSenti(tempTweetCleaned).correct())\n",
    "    \n",
    "#     tempTokens = TweetTokenizer.tokenize(tempTweetCleaned)\n",
    "    tempTokens = nltk.word_tokenize(tempTweetCleaned)\n",
    "#     tempTokens = [tempToken.lower() for tempToken in tempTokens if len(tempToken)>2]\n",
    "#     tempTokens = [tempToken.lower() for tempToken in tempTokens if tempToken.lower() not in stopset and len(tempToken)>2]\n",
    "    tempTagged = nltk.pos_tag(tempTokens)\n",
    "    \n",
    "    positive = 0.0\n",
    "    negative = 0.0\n",
    "    objective = 0.0\n",
    "    count = 0.0\n",
    "    \n",
    "#     print(tempTagged)\n",
    "    \n",
    "    for w, p in tempTagged:\n",
    "        w = w.lower()\n",
    "        po, ne, ob = calSentiForWord(w, p)\n",
    "        positive += po\n",
    "        negative += ne\n",
    "        objective += ob\n",
    "        count += 1\n",
    "        \n",
    "    if count <= 0.1:\n",
    "        return 0, 0, 0, 0\n",
    "        \n",
    "    positive /= count\n",
    "    negative /= count\n",
    "    objective /= count\n",
    "    \n",
    "#     tb = blobSenti(tempTweetCleaned)\n",
    "    \n",
    "    return count, positive, negative, objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating... myrna99.csv\n",
      "0\n",
      ".csvulating... KBDeSalvo\n",
      "0\n",
      "Calculating... HTracyDavido.csv\n",
      "0\n",
      "2000\n",
      "Calculating... CenterdinOaklnd.csv\n",
      "0\n",
      "2000\n",
      "4000\n",
      "Calculating... satyanadella.csv\n",
      "0\n",
      "Calculating... jeffrreyford.csv\n",
      "0\n",
      "Calculating... CarolynRife.csv\n",
      "0\n",
      "Calculating... bexsmith2303.csv\n",
      "0\n",
      ".csvulating... VivianaLongo\n",
      "0\n",
      "Calculating... HanninenRaija.csv\n",
      "0\n",
      "Calculating... JoshPickett22_.csv\n",
      "0\n",
      "Calculating... sabema11_.csv\n",
      "0\n",
      "2000\n",
      "4000\n",
      "6000\n",
      "Calculating... msteGeorge_.csv\n",
      "0\n",
      "Calculating... amandasilveir.csv\n",
      "0\n",
      "Calculating... courageousgirl2_.csv\n",
      "0\n",
      "2000\n",
      "4000\n",
      "6000\n",
      "Calculating... ysik696_yesica.csv\n",
      "0\n",
      "Calculating... TheBagLadyBaySt.csv\n",
      "0\n",
      "Calculating... bootleg55_.csv\n",
      "0\n",
      ".csvulating... sventennis\n",
      "0\n",
      "2000\n",
      "4000\n",
      "6000\n",
      "8000\n",
      "Calculating... only1lovelylady_.csv\n",
      "0\n",
      "Calculating... Fold_Alot.csv\n",
      "0\n",
      "Calculating... srininad.csv\n",
      "0\n",
      "Calculating... dootsonlady.csv\n",
      "0\n",
      "Calculating... winecc.csv\n",
      "0\n",
      "Calculating... smodisette.csv\n",
      "0\n",
      "Calculating... poopthought.csv\n",
      "0\n",
      "Calculating... amityron112.csv\n",
      "0\n",
      "Calculating... ShowalterMG.csv\n",
      "0\n",
      ".csvulating... RobinRoberts\n",
      "0\n",
      "2000\n",
      "4000\n",
      "6000\n",
      "8000\n",
      "10000\n",
      "12000\n",
      "14000\n",
      "16000\n",
      "18000\n",
      "20000\n",
      "22000\n",
      "24000\n",
      "26000\n",
      "28000\n",
      "30000\n",
      "Calculating... eliza_laskowski.csv\n",
      "0\n",
      "Calculating... fly5962_.csv\n",
      "0\n",
      "Calculating... pwslive.csv\n",
      "0\n",
      "Calculating... AroundChiTown.csv\n",
      "0\n",
      "Calculating... CoachMattBLiTZ.csv\n",
      "0\n",
      "Calculating... MKBHD.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cary/.local/share/virtualenvs/TextAnalytics-9hFs7Vd6/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (9,21) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2000\n",
      "4000\n",
      "6000\n",
      "8000\n",
      "10000\n",
      "12000\n",
      "14000\n",
      "16000\n",
      "18000\n",
      "20000\n",
      "22000\n",
      "24000\n",
      "26000\n",
      "28000\n",
      "30000\n",
      "32000\n",
      "34000\n",
      "36000\n",
      "38000\n",
      "40000\n",
      "42000\n",
      "44000\n",
      "Calculating... lindseywasson.csv\n",
      "0\n",
      "2000\n",
      "4000\n",
      "6000\n",
      "8000\n",
      "10000\n",
      "12000\n",
      "Calculating... mattdoty.csv\n",
      "0\n",
      "Calculating... blessings4life.csv\n",
      "0\n",
      "Calculating... thedrillsgt_.csv\n",
      "0\n",
      "Calculating... mamalium.csv\n",
      "0\n",
      "Calculating... whatlisacooks.csv\n",
      "0\n",
      "2000\n",
      "Calculating... marissssa_mcbri.csv\n",
      "0\n",
      "Calculating... Forest_Theater_.csv\n",
      "0\n",
      "Calculating... Car_o_lina.csv\n",
      "0\n",
      "2000\n",
      "Calculating... Blargers.csv\n",
      "0\n",
      "Calculating... ChrisVossPodcas.csv\n",
      "0\n",
      "2000\n",
      "4000\n",
      "6000\n",
      "8000\n",
      "10000\n",
      "12000\n",
      "Calculating... thejoecardamone_.csv\n",
      "0\n",
      "Calculating... AlkieshaK.csv\n",
      "0\n",
      ".csvulating... jsoltero\n",
      "0\n",
      "2000\n",
      "4000\n",
      "Calculating... Tarraccas.csv\n",
      "0\n",
      "Calculating... LUVVAJ.csv\n",
      "0\n",
      "2000\n",
      "4000\n",
      "6000\n",
      "Calculating... GerrickB_.csv\n",
      "0\n",
      "Calculating... OldTomYoung_.csv\n",
      "0\n",
      "Calculating... nabe1.csv\n",
      "0\n",
      ".csvulating... HussnainMahroof\n",
      "0\n",
      "Calculating... justinbernier_.csv\n",
      "0\n",
      "Calculating... tomglanz.csv\n",
      "0\n",
      "2000\n",
      "4000\n",
      "Calculating... Cliu00.csv\n",
      "0\n",
      "Calculating... katiecoats.csv\n",
      "0\n",
      "Calculating... writerchelseam.csv\n",
      "0\n",
      "Calculating... Earth_Unity.csv\n",
      "0\n",
      "Calculating... JAJAjoe.csv\n",
      "0\n",
      ".csvulating... junkballjul\n",
      "0\n",
      "Calculating... dubliportal.csv\n",
      "0\n",
      "Calculating... chadmue11er_.csv\n",
      "0\n",
      "Calculating... TheOnlyNishant.csv\n",
      "0\n",
      "Calculating... Kiweez1_.csv\n",
      "0\n",
      "Calculating... FordeINC.csv\n",
      "0\n",
      "Calculating... VCooper51_.csv\n",
      "0\n",
      "Calculating... AragoneJC.csv\n",
      "0\n",
      "Calculating... Tpalmo1230Pam.csv\n",
      "0\n",
      "Calculating... ChiTownMaggie_.csv\n",
      "0\n",
      "Calculating... debl115.csv\n",
      "0\n",
      "2000\n",
      "Calculating... Kelley_Smith.csv\n",
      "0\n",
      "Calculating... michaelaholmber.csv\n",
      "0\n",
      "Calculating... Pharoe73_.csv\n",
      "0\n",
      "Calculating... CrazyMJsWife_.csv\n",
      "0\n",
      "Calculating... Mark_Viktor.csv\n",
      "0\n",
      "Calculating... RRStumpf.csv\n",
      "0\n",
      ".csvulating... krlanavarrete\n",
      "0\n",
      "Calculating... surfcosta.csv\n",
      "0\n",
      "Calculating... JerryBray.csv\n",
      "0\n",
      "Calculating... rahulvr0507.csv\n",
      "0\n",
      "Calculating... tonyutter_.csv\n",
      "0\n",
      "Calculating... soon2bking.csv\n",
      "0\n",
      "2000\n",
      "Calculating... trixa09.csv\n",
      "0\n",
      "Calculating... coni12thwoman.csv\n",
      "0\n",
      "Calculating... AlexCorretja74.csv\n",
      "0\n",
      "2000\n",
      "4000\n",
      "Calculating... NorCalBill.csv\n",
      "0\n",
      "Calculating... PathfinderVill.csv\n",
      "0\n",
      "Calculating... MyShanDairy.csv\n",
      "0\n",
      "Calculating... Martin3zz10.csv\n",
      "0\n",
      "2000\n",
      "4000\n",
      "6000\n",
      "8000\n",
      "10000\n",
      "12000\n",
      "Calculating... nealcapapas.csv\n",
      "0\n",
      "Calculating... cstapholz.csv\n",
      "0\n",
      "Calculating... ryanbello.csv\n",
      "0\n",
      "2000\n",
      "4000\n",
      "6000\n",
      "Calculating... mljoker93_.csv\n",
      "0\n",
      "Calculating... RebeccaMHowell_.csv\n",
      "0\n",
      ".csvulating... KiiKcreate\n",
      "0\n",
      "Calculating... LoriJulia_.csv\n",
      "0\n",
      "2000\n",
      "4000\n",
      "Calculating... glomob.csv\n",
      "0\n",
      "Calculating... carleton_snow.csv\n",
      "0\n",
      ".csvulating... stephengillett\n",
      "0\n",
      "2000\n",
      "Calculating... KTej13.csv\n",
      "0\n",
      "Calculating... marceliuzca.csv\n",
      "0\n",
      "Calculating... snakepitalehous.csv\n",
      "0\n",
      "Calculating... Oleblloyd_.csv\n",
      "0\n",
      ".csvulating... MrPhilHarrison\n",
      "0\n",
      "Calculating... Sequoioideae.csv\n",
      "0\n",
      "Calculating... sharkims.csv\n",
      "0\n",
      "2000\n",
      "Calculating... suzannetaub.csv\n",
      "0\n",
      "Calculating... tweetviaphoenix.csv\n",
      "0\n",
      "Calculating... federalli169_.csv\n",
      "0\n",
      "Calculating... rodneykeene_.csv\n",
      "0\n",
      "Calculating... JasminsTable.csv\n",
      "0\n",
      "Calculating... lileiguang.csv\n",
      "0\n",
      "Calculating... eilujkell.csv\n",
      "0\n",
      "Calculating... RobbinsGroupLLC_.csv\n",
      "0\n",
      "2000\n",
      "4000\n",
      "6000\n",
      "8000\n",
      "Calculating... Warrej_.csv\n",
      "0\n",
      "Calculating... chasselljones.csv\n",
      "0\n",
      "Calculating... qwikshower.csv\n",
      "0\n",
      "Calculating... ricinMD_.csv\n",
      "0\n",
      "Calculating... HumboldtMobile.csv\n",
      "0\n",
      "Calculating... TheBandTheYanks.csv\n",
      "0\n",
      "Calculating... JCitrolo.csv\n",
      "0\n",
      "Calculating... chesskillertips.csv\n",
      "0\n",
      "Calculating... GabriellaNY.csv\n",
      "0\n",
      "Calculating... vicki_hou.csv\n",
      "0\n",
      ".csvulating... ibjade\n",
      "0\n",
      "Calculating... Rajacenna.csv\n",
      "0\n",
      "Calculating... revjeffgrant.csv\n",
      "0\n",
      "2000\n",
      "4000\n",
      "6000\n",
      "8000\n",
      "Calculating... officership_.csv\n",
      "0\n",
      "2000\n",
      "4000\n",
      "Calculating... plagerisms.csv\n",
      "0\n",
      "Calculating... josephzhou.csv\n",
      "0\n",
      "Calculating... ronaldskelton.csv\n",
      "0\n",
      "2000\n",
      "4000\n",
      "Calculating... slamb63_.csv\n",
      "0\n",
      "Calculating... Daytrippr777.csv\n",
      "0\n",
      "Calculating... Allison0414.csv\n",
      "0\n",
      "Calculating... forginglory.csv\n",
      "0\n",
      "Calculating... VanessaShealy.csv\n",
      "0\n",
      "Calculating... JoesNoLimits.csv\n",
      "0\n",
      "Calculating... blpfunk_.csv\n",
      "0\n",
      ".csvulating... MarceloRios75\n",
      "0\n",
      "Calculating... duelly22_.csv\n",
      "0\n",
      "Calculating... MDG1972_.csv\n",
      "0\n",
      "2000\n",
      "Calculating... SalkMNLO.csv\n",
      "0\n",
      "Calculating... globulltrader_.csv\n",
      "0\n",
      "Calculating... 1SunRisen.csv\n",
      "0\n",
      "2000\n",
      "4000\n",
      "6000\n",
      "Calculating... princess_rah_12.csv\n",
      "0\n",
      "Calculating... eileengreenauth.csv\n",
      "0\n",
      ".csvulating... alexisohanian\n",
      "0\n",
      "2000\n",
      "4000\n",
      "Calculating... susanne1229_.csv\n",
      "0\n",
      "Calculating... DoLLyRach.csv\n",
      "0\n",
      "2000\n",
      "4000\n",
      "6000\n",
      "8000\n",
      "10000\n",
      "12000\n",
      "Calculating... VictoriaAnn841.csv\n",
      "0\n",
      "2000\n",
      "Calculating... mela0521.csv\n",
      "0\n",
      "2000\n",
      "Calculating... TNDVS_.csv\n",
      "0\n",
      "Calculating... Tassie206.csv\n",
      "0\n",
      "Calculating... Jakeweindling_.csv\n",
      "0\n",
      "2000\n",
      "4000\n",
      "6000\n",
      "8000\n",
      "Calculating... shipmeant2b_.csv\n",
      "0\n",
      "2000\n",
      "4000\n",
      "6000\n",
      "Calculating... alexnoodle.csv\n",
      "0\n",
      "2000\n",
      "4000\n",
      "Calculating... Killamanjaro85_.csv\n",
      "0\n",
      "Calculating... wayilong.csv\n",
      "0\n",
      "Calculating... DarylCerdinio.csv\n",
      "0\n",
      "Calculating... dirtteamgirl.csv\n",
      "0\n",
      "Calculating... MyDailyArmor.csv\n",
      "0\n",
      "Calculating... nikitamaloo.csv\n",
      "0\n",
      "Calculating... newstiger.csv\n",
      "0\n",
      "Calculating... AmyChoyne.csv\n",
      "0\n",
      "Calculating... ngonzales78.csv\n",
      "0\n",
      "2000\n",
      "Calculating... rajnish_samir.csv\n",
      "0\n",
      "Calculating... dtonseth.csv\n",
      "0\n",
      ".csvulating... mamoonha\n",
      "0\n",
      "Calculating... healthyfather.csv\n",
      "0\n",
      "Calculating... djones_weather.csv\n",
      "0\n",
      "Calculating... singlaank.csv\n",
      "0\n",
      "Calculating... PhillipTino.csv\n",
      "0\n",
      ".csvulating... karomuchova7\n",
      "0\n",
      "Calculating... NEF_LISC_.csv\n",
      "0\n",
      "Calculating... CharlieLance_.csv\n",
      "0\n",
      "Calculating... Orange_Papers.csv\n",
      "0\n",
      "Calculating... Paulinaqueensny.csv\n",
      "0\n",
      "Calculating... BigBoyCasey.csv\n",
      "0\n",
      "Calculating... GaryGwolson5227.csv\n",
      "0\n",
      "Calculating... latanyalucas101.csv\n",
      "0\n",
      "Calculating... calzgraphics_.csv\n",
      "0\n",
      "Calculating... TBrave.csv\n",
      "0\n",
      "Calculating... jtkstc_.csv\n",
      "0\n",
      "Calculating... SeattleSPU.csv\n",
      "0\n",
      "2000\n",
      "4000\n",
      "Calculating... TrulyDougTaylor.csv\n",
      "0\n",
      "2000\n",
      "4000\n",
      "6000\n",
      "8000\n",
      "10000\n",
      "12000\n",
      "14000\n",
      "Calculating... Okameister.csv\n",
      "0\n",
      "Calculating... MrsKaminski1_.csv\n",
      "0\n",
      "Calculating... therealsamuelc.csv\n",
      "0\n",
      "Calculating... murrdashewrote.csv\n",
      "0\n",
      "Calculating... wiredhigh.csv\n",
      "0\n",
      "Calculating... 206moose.csv\n",
      "0\n",
      "Calculating... Moogilu.csv\n",
      "0\n",
      "Calculating... smkee22.csv\n",
      "0\n",
      "Calculating... SmileAgainDDS.csv\n",
      "0\n",
      "Calculating... kenyankee_.csv\n",
      "0\n",
      "Calculating... enlightphoto.csv\n",
      "0\n",
      "2000\n",
      "4000\n",
      "6000\n",
      "8000\n",
      "10000\n",
      "12000\n",
      "Calculating... garjones.csv\n",
      "0\n",
      "Calculating... LeslieDTrew.csv\n",
      "0\n",
      "Calculating... jodawi.csv\n",
      "0\n",
      "Calculating... abubokor1993.csv\n",
      "0\n",
      ".csvulating... friedberg\n",
      "0\n",
      "Calculating... rmh056.csv\n",
      "0\n",
      "2000\n",
      "Calculating... danastephanie.csv\n",
      "0\n",
      "2000\n",
      "4000\n",
      "6000\n",
      "Calculating... AnnieNero.csv\n",
      "0\n",
      ".csvulating... tashems\n",
      "0\n",
      "Calculating... tracyqou.csv\n",
      "0\n",
      "Calculating... stanandtayna.csv\n",
      "0\n",
      "Calculating... pgrl29.csv\n",
      "0\n",
      "Calculating... IamChandgo.csv\n",
      "0\n",
      "Calculating... ePositiveVibe.csv\n",
      "0\n",
      "Calculating... BellevueDT.csv\n",
      "0\n",
      "2000\n",
      "4000\n",
      "Calculating... DManFWTX_.csv\n",
      "0\n",
      "2000\n",
      "Calculating... HempNews.csv\n",
      "0\n",
      "Calculating... gina702.csv\n",
      "0\n",
      "Calculating... Sheilabjeletich.csv\n",
      "0\n",
      "2000\n",
      "Calculating... haabanews.csv\n",
      "0\n",
      "Calculating... bhogleharsha.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cary/.local/share/virtualenvs/TextAnalytics-9hFs7Vd6/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (21) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2000\n",
      "4000\n",
      "6000\n",
      "8000\n",
      "10000\n",
      "12000\n",
      "14000\n",
      "16000\n",
      "18000\n",
      "20000\n",
      "22000\n",
      "24000\n",
      "26000\n",
      "28000\n",
      "30000\n",
      "32000\n",
      "34000\n",
      "36000\n",
      "38000\n",
      "40000\n",
      "Calculating... carioke.csv\n",
      "0\n",
      ".csvulating... williamready\n",
      "0\n",
      "Calculating... TahoeRCD.csv\n",
      "0\n",
      "Calculating... CArecycler.csv\n",
      "0\n",
      "Calculating... AleBritoFlores.csv\n",
      "0\n",
      "Calculating... hergus_.csv\n",
      "0\n",
      "Calculating... mizzslim5.csv\n",
      "0\n",
      "Calculating... UdiSch.csv\n",
      "0\n",
      "Calculating... renegoscinny.csv\n",
      "0\n",
      "Calculating... Christa_Belle.csv\n",
      "0\n",
      "Calculating... Gimmie18USC2381.csv\n",
      "0\n",
      "2000\n",
      "Calculating... JuanPierreBowly.csv\n",
      "0\n",
      "Calculating... lilgde90_.csv\n",
      "0\n",
      "2000\n",
      "Calculating... SpilledInkRepU.csv\n",
      "0\n",
      "Calculating... sundarpichai.csv\n",
      "0\n",
      "Calculating... mongabay.csv\n",
      "0\n",
      "2000\n",
      "4000\n",
      "6000\n",
      "8000\n",
      "Calculating... AmandaK0812.csv\n",
      "0\n",
      "Calculating... rajeshsawhney.csv\n",
      "0\n",
      "2000\n",
      "4000\n",
      "6000\n",
      "8000\n",
      "10000\n",
      "12000\n",
      "Calculating... jpaul237_.csv\n",
      "0\n",
      "2000\n",
      "Calculating... OCSportsXchange.csv\n",
      "0\n",
      "Calculating... BPositive104.csv\n",
      "0\n",
      "Calculating... dwalden0726.csv\n",
      "0\n",
      ".csvulating... DohertyShannen\n",
      "0\n",
      "2000\n",
      "4000\n",
      "6000\n",
      "8000\n",
      "Calculating... urbanchillage_.csv\n",
      "0\n",
      "2000\n",
      "Calculating... mayank7jan.csv\n",
      "0\n",
      "Calculating... Candi_CA.csv\n",
      "0\n",
      "2000\n",
      "4000\n",
      "Calculating... zack_kreish_.csv\n",
      "0\n",
      "Calculating... adamgeraldlight_.csv\n",
      "0\n",
      "Calculating... kierstenmh.csv\n",
      "0\n",
      "2000\n",
      "4000\n",
      "Calculating... tk63.csv\n",
      "0\n",
      ".csvulating... RyanSeacrest\n",
      "0\n",
      "2000\n",
      "Calculating... williger.csv\n",
      "0\n",
      "2000\n",
      "4000\n",
      "6000\n",
      "8000\n",
      "10000\n",
      "12000\n",
      "Calculating... mzshorter.csv\n",
      "0\n",
      "2000\n",
      "4000\n",
      "Calculating... CatGray.csv\n",
      "0\n",
      "Calculating... AlexRamel.csv\n",
      "0\n",
      "Calculating... GetFreeBooks.csv\n",
      "0\n",
      "Calculating... maracelyyy.csv\n",
      "0\n",
      "Calculating... IG_bybrookelle.csv\n",
      "0\n",
      "Calculating... egstorey_.csv\n",
      "0\n",
      "Calculating... michaelwhere.csv\n",
      "0\n",
      "Calculating... mps3mom.csv\n",
      "0\n",
      "Calculating... DebbyBRealtor.csv\n",
      "0\n",
      "Calculating... rmscrypto.csv\n",
      "0\n",
      "Calculating... 7GeorgeCostanza.csv\n",
      "0\n",
      "Calculating... dchiger22.csv\n",
      "0\n",
      "Calculating... ChuyBerumen1_.csv\n",
      "0\n",
      "Calculating... ycatsnonnac.csv\n",
      "0\n",
      "Calculating... WTW_WestCoast.csv\n",
      "0\n",
      "Calculating... K80LP_.csv\n",
      "0\n",
      "Calculating... Oakpnyc.csv\n",
      "0\n",
      "Calculating... paulwhitworth.csv\n",
      "0\n",
      "2000\n",
      "Calculating... CaliforniaCal.csv\n",
      "0\n",
      "Calculating... WeThePawns.csv\n",
      "0\n",
      "Calculating... IslamPaggio_.csv\n",
      "0\n",
      "Calculating... Swamy39.csv\n",
      "0\n",
      "2000\n",
      "4000\n",
      "6000\n",
      "8000\n",
      "10000\n",
      "12000\n",
      "14000\n",
      "16000\n",
      "18000\n",
      "20000\n",
      "22000\n",
      "24000\n",
      "26000\n",
      "28000\n",
      "30000\n",
      "32000\n",
      "34000\n",
      "36000\n",
      "38000\n",
      "Calculating... Starviewfarmvt.csv\n",
      "0\n",
      "Calculating... ethan_marketing.csv\n",
      "0\n",
      "Calculating... JerryTheTidd_.csv\n",
      "0\n",
      "2000\n",
      "4000\n",
      "6000\n",
      "8000\n",
      "Calculating... fourbags57.csv\n",
      "0\n",
      "Calculating... Chrisypoooh.csv\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "filecont = 0\n",
    "for soldierCSVFile in soldierCSVs:\n",
    "    if soldierCSVFile == 'cleaned_vet_tweet_df.csv': continue\n",
    "    if soldierCSVFile == 'combined_civilians.csv': continue\n",
    "\n",
    "    print('Calculating... ' + soldierCSVFile)\n",
    "    \n",
    "    tempDF = pd.read_csv(os.getcwd() + \"/data/civilians/\" + soldierCSVFile, encoding='utf8')\n",
    "    tempDF.dropna(subset=['tweet'], inplace=True) # clear empty tweets\n",
    "    tempDF.drop(uselessColumns, axis=1, inplace=True)\n",
    "    \n",
    "    positives = []\n",
    "    negatives = []\n",
    "    objectives = []\n",
    "#     polarities = []\n",
    "#     subjectivities = []\n",
    "    tweetCleanedLengths = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    for id, row in tempDF.iterrows():\n",
    "        tokens, po, ne, ob = calSentiForTweet(row['tweet'])\n",
    "        tweetCleanedLengths.append(tokens)\n",
    "        positives.append(po)\n",
    "        negatives.append(ne)\n",
    "        objectives.append(ob)\n",
    "#         polarities.append(pola)\n",
    "#         subjectivities.append(sub)\n",
    "        \n",
    "        if (id % 2000) == 0: print(id)\n",
    "#         if (soldierCSVFile == 'cNikonphoto.csv'): print(id)\n",
    "    \n",
    "    count = len(tweetCleanedLengths)\n",
    "    \n",
    "    # Computing the standard deviation in float64 is more accurate:\n",
    "    # np.std([1, 2, 3, 4], dtype=np.float64)\n",
    "    if count > 0:\n",
    "        result = {\n",
    "            'count': count,\n",
    "            'tweet cleaned length mean': np.mean(tweetCleanedLengths),\n",
    "            'tweet cleaned length std': np.std(tweetCleanedLengths, dtype=np.float64),\n",
    "            'positive mean': np.mean(positives),\n",
    "            'positive std': np.std(positives, dtype=np.float64),\n",
    "            'negative mean': np.mean(negatives),\n",
    "            'negative std': np.std(negatives, dtype=np.float64),\n",
    "            'objective mean': np.mean(objectives),\n",
    "            'objective std': np.std(objectives, dtype=np.float64),\n",
    "#             'polarity mean': np.mean(polarities),\n",
    "#             'polarity std': np.std(polarities, dtype=np.float64),\n",
    "#             'subjectivity mean': np.mean(subjectivities),\n",
    "#             'subjectivity std': np.std(subjectivities, dtype=np.float64),\n",
    "        }\n",
    "    else:\n",
    "        result = {\n",
    "            'count': 0,\n",
    "            'tweet cleaned length mean': 0,\n",
    "            'tweet cleaned length std': 0,\n",
    "            'positive mean': 0,\n",
    "            'positive std': 0,\n",
    "            'negative mean': 0,\n",
    "            'negative std': 0,\n",
    "            'objective mean': 0,\n",
    "            'objective std': 0,\n",
    "#             'polarity mean': 0,\n",
    "#             'polarity std': 0,\n",
    "#             'subjectivity mean': 0,\n",
    "#             'subjectivity std': 0\n",
    "        }\n",
    "    \n",
    "    soldierCalDict[filecont] = result\n",
    "    filecont += 1\n",
    "#     print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame.from_dict(soldierCalDict, orient=\"index\").to_csv(\"soldierCal.csv\")\n",
    "pd.DataFrame.from_dict(soldierCalDict, orient=\"index\").to_csv(\"civilianCal.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
